{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7f6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c192d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf1a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n",
      "<torch.cuda.device object at 0x7f8b3c79ca60>\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff733115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 250\n",
    "channel = 128\n",
    "min_CNN = 200\n",
    "n_classes = 4\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b68db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if platform == \"linux\" or platform == \"linux2\":\n",
    "#     torch_models_dir = r\"/media/titan/AI Research1/Data/CVPR2017\"\n",
    "# elif platform == \"win32\":\n",
    "#     torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "# block_splits_all, block_splits_single, eeg_14_70, eeg_55_95, eeg_5_95, eeg_raw = os.listdir(torch_models_dir)\n",
    "# print(os.listdir(torch_models_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc401c6-e7e3-4163-9a3e-fa0aea23551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_dataset = '/media/mountHDD1/LanxHuyen/high_gamma_dataset.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd3ad4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_dataset = os.path.join(torch_models_dir, eeg_5_95)\n",
    "# splits_all_path = os.path.join(torch_models_dir, block_splits_all)\n",
    "# splits_single_path = os.path.join(torch_models_dir, block_splits_single)\n",
    "# # splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "# print(eeg_dataset,'\\n', splits_all_path, '\\n', splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "659d4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits_all = torch.load(splits_all_path)\n",
    "# splits_single = torch.load(splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f3ef344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(splits_all['splits']))\n",
    "# print(len(splits_all['splits'][0]))\n",
    "\n",
    "# print(len(splits_all['splits'][5]['train']))\n",
    "# print(len(splits_all['splits'][5]['val']))\n",
    "# print(len(splits_all['splits'][5]['test']))\n",
    "# print(splits_all['splits'][0]['train'][:40])\n",
    "# print(splits_all['splits'][1]['train'][:40])\n",
    "# print(splits_all['splits'][2]['train'][:10])\n",
    "# print(splits_all['splits'][3]['train'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b27b3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(splits_single)\n",
    "# print(len(splits_single['splits'][0]['train']))\n",
    "# print(len(splits_single['splits'][0]['val']))\n",
    "# print(len(splits_single['splits'][0]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed58c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_loaded = torch.load(eeg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a637c6f-a7c4-4689-9036-0b1f0089ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(eeg_loaded)))\n",
    "random.shuffle(list(range(len(eeg_loaded))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "682d14b3-76a3-456e-99eb-bf75d423c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(eeg_loaded))\n",
    "val_size = int(0.1 * len(eeg_loaded))\n",
    "test_size = len(eeg_loaded) - (train_size + val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6cd3e5f-d47b-4cb4-ad42-1f46608eb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size+val_size]\n",
    "test_indices = indices[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3026ea-0a7a-4031-9a3d-e3e3540254f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_splits = {\"train\": train_indices, \"val\": val_indices, \"test\": test_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89460bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26968\n",
      "26968\n"
     ]
    }
   ],
   "source": [
    "print(len(eeg_loaded))\n",
    "# print(eeg_loaded.keys())\n",
    "eeg = [eeg_loaded[i][\"eeg\"] for i in range (len(eeg_loaded))]\n",
    "print(len(eeg))\n",
    "# for dataset_idx in range (len(eeg_loaded)): \n",
    "#     eeg, label = [eeg_loaded[dataset_idx][key] for key in ['eeg', 'label']]\n",
    "# print((label))\n",
    "# print(len(eeg))\n",
    "# # print(len(dataset))\n",
    "\n",
    "# # print(labels)\n",
    "# # print(images[0])\n",
    "# print(eeg['eeg'][0].shape)\n",
    "# print(eeg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d20c958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "#     \"iv\": \"image\",\n",
    "#     \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    #\"subject\": 0,\n",
    "    \"time_low\": 20,\n",
    "    \"time_high\": 270,\n",
    "#     \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"model_type\": \"model10\",\n",
    "    #\"splits_path\": splits_all_path,\n",
    "    #\"split_num\": 0,\n",
    "    \"split_name\": \"train\",\n",
    "#     \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 64,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 1,\n",
    "    \"kind\":\"from-scratch\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.time_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce8d6e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "# from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from data_loader_HGD import EEGDataset, Splitter\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a5b475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "#              offset,\n",
    "             eeg_dataset,\n",
    "             #splits_path,\n",
    "             #split_num, # (0-5) - 6 fold cross validation\n",
    "             split_name,\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             kind=\"from-scratch\"):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(opt, eeg_dataset)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "#     # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "#     if kind==\"from-scratch\":\n",
    "#         relabel = False\n",
    "#     if kind==\"incremental\":\n",
    "#         relabel = False\n",
    "#     if kind==\"no-model-file\":\n",
    "#         relabel = True\n",
    "    splitter = {split: Splitter(dataset,\n",
    "                    #splits_path,\n",
    "                    #split_num,\n",
    "                    split_name = split) \n",
    "                for split in [\"train\", \"val\", \"test\"]\n",
    "                                }\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a242cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "opt.classifier = \"EEGNet\"\n",
    "opt.batch_size = 64\n",
    "# opt.kind = \"from-scratch\"\n",
    "# opt.run = \"imagenet40-1000\"\n",
    "# opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "633488a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(\n",
    "#              offset,\n",
    "             opt.eeg_dataset,\n",
    "             #opt.splits_path,\n",
    "             #opt.split_num, # (0-5) - 6 fold cross validation\n",
    "             opt.split_name,\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             opt.batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e99fc973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader_HGD.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [338, 43, 43]\n",
      "1: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "2: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "3: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "4: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "5: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "6: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "7: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "8: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "9: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "10: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "11: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "12: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "13: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "14: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "15: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "16: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "17: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "18: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "19: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "20: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 8000 idx, val: 2000 idx, test: 2000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250 idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i, (input, target) in enumerate(loaders[\"train\"]):\n",
    "    if i<20:\n",
    "        print(f\"{i+1}: Target size: {target.size()}; input size: {input.size()}\")\n",
    "# for i in range(0, 40):\n",
    "#     eeg, label_val = splitter[\"val\"][i]\n",
    "#     eeg, label_train = splitter[\"train\"][i]\n",
    "#     print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39a07cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_EEGNet(\n",
      "  (network): Sequential(\n",
      "    (0): ZeroPad2d((62, 61, 0, 0))\n",
      "    (1): Conv2d(1, 8, kernel_size=(1, 125), stride=(1, 1))\n",
      "    (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Conv2d(8, 16, kernel_size=(128, 1), stride=(1, 1), groups=8)\n",
      "    (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ELU(alpha=1.0)\n",
      "    (6): AvgPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): ZeroPad2d((8, 7, 0, 0))\n",
      "    (9): Conv2d(16, 16, kernel_size=(1, 16), stride=(1, 1), groups=8)\n",
      "    (10): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (11): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ELU(alpha=1.0)\n",
      "    (13): AvgPool2d(kernel_size=(1, 8), stride=(1, 8), padding=0)\n",
      "    (14): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (fc): Linear(in_features=112, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_EEGNet                        [1, 4]                    --\n",
       "├─Sequential: 1-1                        [1, 16, 1, 7]             --\n",
       "│    └─ZeroPad2d: 2-1                    [1, 1, 128, 373]          --\n",
       "│    └─Conv2d: 2-2                       [1, 8, 128, 249]          1,008\n",
       "│    └─BatchNorm2d: 2-3                  [1, 8, 128, 249]          16\n",
       "│    └─Conv2d: 2-4                       [1, 16, 1, 249]           2,064\n",
       "│    └─BatchNorm2d: 2-5                  [1, 16, 1, 249]           32\n",
       "│    └─ELU: 2-6                          [1, 16, 1, 249]           --\n",
       "│    └─AvgPool2d: 2-7                    [1, 16, 1, 62]            --\n",
       "│    └─Dropout: 2-8                      [1, 16, 1, 62]            --\n",
       "│    └─ZeroPad2d: 2-9                    [1, 16, 1, 77]            --\n",
       "│    └─Conv2d: 2-10                      [1, 16, 1, 62]            528\n",
       "│    └─Conv2d: 2-11                      [1, 16, 1, 62]            272\n",
       "│    └─BatchNorm2d: 2-12                 [1, 16, 1, 62]            32\n",
       "│    └─ELU: 2-13                         [1, 16, 1, 62]            --\n",
       "│    └─AvgPool2d: 2-14                   [1, 16, 1, 7]             --\n",
       "│    └─Dropout: 2-15                     [1, 16, 1, 7]             --\n",
       "├─Linear: 1-2                            [1, 4]                    452\n",
       "==========================================================================================\n",
       "Total params: 4,404\n",
       "Trainable params: 4,404\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 32.69\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 4.17\n",
       "Params size (MB): 0.02\n",
       "Estimated Total Size (MB): 4.31\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1,128, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a8d6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGNetHGD\n",
      "results_EEGNetHGD\n"
     ]
    }
   ],
   "source": [
    "model_path = (   opt.classifier+\n",
    "                  \"HGD\" )\n",
    "results_path = (  \"results_\"+ opt.classifier+\n",
    "                  \"HGD\"  )\n",
    "print(model_path)\n",
    "print(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4b753db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(results_file='results.pkl', time_low=20, time_high=270, eeg_dataset='/media/mountHDD1/LanxHuyen/high_gamma_dataset.pth', model_type='model10', split_name='train', batch_size=64, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=1, kind='from-scratch', no_cuda=False, classifier='EEGNet')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5334cb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Batch 100 (every 100 batch): Loss=1.1831; accuracy=0.3541\n",
      "Train Batch 200 (every 100 batch): Loss=1.2021; accuracy=0.3920\n",
      "Train Batch 300 (every 100 batch): Loss=1.1445; accuracy=0.4196\n",
      "Epoch 1 summary: train_loss: 1.2364 | train_acc: 0.4268 | val_loss: 1.2019 | val_acc: 0.4575\n",
      "Epoch 2\n",
      "Train Batch 100 (every 100 batch): Loss=1.2173; accuracy=0.4988\n",
      "Train Batch 200 (every 100 batch): Loss=1.0758; accuracy=0.5048\n",
      "Train Batch 300 (every 100 batch): Loss=1.1289; accuracy=0.5117\n",
      "Epoch 2 summary: train_loss: 1.1134 | train_acc: 0.5131 | val_loss: 1.1197 | val_acc: 0.5004\n",
      "Epoch 3\n",
      "Train Batch 100 (every 100 batch): Loss=1.0745; accuracy=0.5172\n",
      "Train Batch 200 (every 100 batch): Loss=1.0171; accuracy=0.5230\n",
      "Train Batch 300 (every 100 batch): Loss=1.1144; accuracy=0.5301\n",
      "Epoch 3 summary: train_loss: 1.0861 | train_acc: 0.5313 | val_loss: 1.1540 | val_acc: 0.4920\n",
      "Epoch 4\n",
      "Train Batch 100 (every 100 batch): Loss=1.0989; accuracy=0.5389\n",
      "Train Batch 200 (every 100 batch): Loss=1.1388; accuracy=0.5375\n",
      "Train Batch 300 (every 100 batch): Loss=0.9710; accuracy=0.5408\n",
      "Epoch 4 summary: train_loss: 1.0639 | train_acc: 0.5443 | val_loss: 1.1546 | val_acc: 0.4964\n",
      "Epoch 5\n",
      "Train Batch 100 (every 100 batch): Loss=0.9902; accuracy=0.5594\n",
      "Train Batch 200 (every 100 batch): Loss=1.0250; accuracy=0.5562\n",
      "Train Batch 300 (every 100 batch): Loss=1.0194; accuracy=0.5527\n",
      "Epoch 5 summary: train_loss: 1.0503 | train_acc: 0.5523 | val_loss: 1.1060 | val_acc: 0.5120\n",
      "Epoch 6\n",
      "Train Batch 100 (every 100 batch): Loss=1.0757; accuracy=0.5664\n",
      "Train Batch 200 (every 100 batch): Loss=1.1600; accuracy=0.5584\n",
      "Train Batch 300 (every 100 batch): Loss=1.1004; accuracy=0.5620\n",
      "Epoch 6 summary: train_loss: 1.0420 | train_acc: 0.5606 | val_loss: 1.1088 | val_acc: 0.5113\n",
      "Epoch 7\n",
      "Train Batch 100 (every 100 batch): Loss=1.2040; accuracy=0.5539\n",
      "Train Batch 200 (every 100 batch): Loss=1.0845; accuracy=0.5609\n",
      "Train Batch 300 (every 100 batch): Loss=1.2039; accuracy=0.5640\n",
      "Epoch 7 summary: train_loss: 1.0327 | train_acc: 0.5650 | val_loss: 1.0920 | val_acc: 0.5218\n",
      "Epoch 8\n",
      "Train Batch 100 (every 100 batch): Loss=1.2210; accuracy=0.5670\n",
      "Train Batch 200 (every 100 batch): Loss=1.0016; accuracy=0.5603\n",
      "Train Batch 300 (every 100 batch): Loss=1.2468; accuracy=0.5640\n",
      "Epoch 8 summary: train_loss: 1.0296 | train_acc: 0.5636 | val_loss: 1.1170 | val_acc: 0.5167\n",
      "Epoch 9\n",
      "Train Batch 100 (every 100 batch): Loss=0.9197; accuracy=0.5839\n",
      "Train Batch 200 (every 100 batch): Loss=1.1570; accuracy=0.5728\n",
      "Train Batch 300 (every 100 batch): Loss=0.9185; accuracy=0.5731\n",
      "Epoch 9 summary: train_loss: 1.0160 | train_acc: 0.5745 | val_loss: 1.1115 | val_acc: 0.5214\n",
      "Epoch 10\n",
      "Train Batch 100 (every 100 batch): Loss=1.2046; accuracy=0.5789\n",
      "Train Batch 200 (every 100 batch): Loss=0.9948; accuracy=0.5862\n",
      "Train Batch 300 (every 100 batch): Loss=0.9275; accuracy=0.5794\n",
      "Epoch 10 summary: train_loss: 1.0067 | train_acc: 0.5766 | val_loss: 1.0883 | val_acc: 0.5258\n",
      "Epoch 11\n",
      "Train Batch 100 (every 100 batch): Loss=1.0931; accuracy=0.5833\n",
      "Train Batch 200 (every 100 batch): Loss=0.9780; accuracy=0.5781\n",
      "Train Batch 300 (every 100 batch): Loss=1.0011; accuracy=0.5798\n",
      "Epoch 11 summary: train_loss: 1.0024 | train_acc: 0.5802 | val_loss: 1.0877 | val_acc: 0.5262\n",
      "Epoch 12\n",
      "Train Batch 100 (every 100 batch): Loss=1.0121; accuracy=0.5795\n",
      "Train Batch 200 (every 100 batch): Loss=0.8937; accuracy=0.5785\n",
      "Train Batch 300 (every 100 batch): Loss=1.0125; accuracy=0.5808\n",
      "Epoch 12 summary: train_loss: 0.9966 | train_acc: 0.5827 | val_loss: 1.0702 | val_acc: 0.5352\n",
      "Epoch 13\n",
      "Train Batch 100 (every 100 batch): Loss=1.0175; accuracy=0.5802\n",
      "Train Batch 200 (every 100 batch): Loss=1.0977; accuracy=0.5809\n",
      "Train Batch 300 (every 100 batch): Loss=1.0705; accuracy=0.5854\n",
      "Epoch 13 summary: train_loss: 0.9926 | train_acc: 0.5840 | val_loss: 1.0904 | val_acc: 0.5225\n",
      "Epoch 14\n",
      "Train Batch 100 (every 100 batch): Loss=1.1137; accuracy=0.5995\n",
      "Train Batch 200 (every 100 batch): Loss=1.1067; accuracy=0.5971\n",
      "Train Batch 300 (every 100 batch): Loss=0.8751; accuracy=0.5936\n",
      "Epoch 14 summary: train_loss: 0.9811 | train_acc: 0.5923 | val_loss: 1.0906 | val_acc: 0.5280\n",
      "Epoch 15\n",
      "Train Batch 100 (every 100 batch): Loss=0.9030; accuracy=0.5934\n",
      "Train Batch 200 (every 100 batch): Loss=1.0905; accuracy=0.5950\n",
      "Train Batch 300 (every 100 batch): Loss=0.8979; accuracy=0.5918\n",
      "Epoch 15 summary: train_loss: 0.9788 | train_acc: 0.5917 | val_loss: 1.1139 | val_acc: 0.5178\n",
      "Epoch 16\n",
      "Train Batch 100 (every 100 batch): Loss=1.1809; accuracy=0.5977\n",
      "Train Batch 200 (every 100 batch): Loss=0.9175; accuracy=0.6002\n",
      "Train Batch 300 (every 100 batch): Loss=1.0033; accuracy=0.5958\n",
      "Epoch 16 summary: train_loss: 0.9743 | train_acc: 0.5961 | val_loss: 1.0953 | val_acc: 0.5331\n",
      "Epoch 17\n",
      "Train Batch 100 (every 100 batch): Loss=1.0432; accuracy=0.5997\n",
      "Train Batch 200 (every 100 batch): Loss=1.0625; accuracy=0.6052\n",
      "Train Batch 300 (every 100 batch): Loss=0.8687; accuracy=0.6041\n",
      "Epoch 17 summary: train_loss: 0.9574 | train_acc: 0.6049 | val_loss: 1.0764 | val_acc: 0.5512\n",
      "Epoch 18\n",
      "Train Batch 100 (every 100 batch): Loss=0.9417; accuracy=0.6094\n",
      "Train Batch 200 (every 100 batch): Loss=1.0144; accuracy=0.6073\n",
      "Train Batch 300 (every 100 batch): Loss=0.9877; accuracy=0.6091\n",
      "Epoch 18 summary: train_loss: 0.9604 | train_acc: 0.6064 | val_loss: 1.0905 | val_acc: 0.5265\n",
      "Epoch 19\n",
      "Train Batch 100 (every 100 batch): Loss=1.3049; accuracy=0.6083\n",
      "Train Batch 200 (every 100 batch): Loss=1.0634; accuracy=0.6045\n",
      "Train Batch 300 (every 100 batch): Loss=0.8176; accuracy=0.6122\n",
      "Epoch 19 summary: train_loss: 0.9507 | train_acc: 0.6113 | val_loss: 1.1046 | val_acc: 0.5382\n",
      "Epoch 20\n",
      "Train Batch 100 (every 100 batch): Loss=0.9592; accuracy=0.6177\n",
      "Train Batch 200 (every 100 batch): Loss=1.0576; accuracy=0.6091\n",
      "Train Batch 300 (every 100 batch): Loss=0.8249; accuracy=0.6110\n",
      "Epoch 20 summary: train_loss: 0.9483 | train_acc: 0.6116 | val_loss: 1.0761 | val_acc: 0.5494\n",
      "Epoch 21\n",
      "Train Batch 100 (every 100 batch): Loss=0.9094; accuracy=0.6194\n",
      "Train Batch 200 (every 100 batch): Loss=0.9997; accuracy=0.6177\n",
      "Train Batch 300 (every 100 batch): Loss=0.8827; accuracy=0.6177\n",
      "Epoch 21 summary: train_loss: 0.9407 | train_acc: 0.6156 | val_loss: 1.1246 | val_acc: 0.5312\n",
      "Epoch 22\n",
      "Train Batch 100 (every 100 batch): Loss=0.7910; accuracy=0.6169\n",
      "Train Batch 200 (every 100 batch): Loss=1.1400; accuracy=0.6205\n",
      "Train Batch 300 (every 100 batch): Loss=1.0964; accuracy=0.6168\n",
      "Epoch 22 summary: train_loss: 0.9436 | train_acc: 0.6184 | val_loss: 1.0433 | val_acc: 0.5531\n",
      "Epoch 23\n",
      "Train Batch 100 (every 100 batch): Loss=0.9391; accuracy=0.6202\n",
      "Train Batch 200 (every 100 batch): Loss=1.0305; accuracy=0.6160\n",
      "Train Batch 300 (every 100 batch): Loss=0.8625; accuracy=0.6173\n",
      "Epoch 23 summary: train_loss: 0.9355 | train_acc: 0.6170 | val_loss: 1.0536 | val_acc: 0.5538\n",
      "Epoch 24\n",
      "Train Batch 100 (every 100 batch): Loss=0.9202; accuracy=0.6228\n",
      "Train Batch 200 (every 100 batch): Loss=0.9977; accuracy=0.6190\n",
      "Train Batch 300 (every 100 batch): Loss=0.8789; accuracy=0.6223\n",
      "Epoch 24 summary: train_loss: 0.9306 | train_acc: 0.6219 | val_loss: 1.0262 | val_acc: 0.5541\n",
      "Epoch 25\n",
      "Train Batch 100 (every 100 batch): Loss=1.1317; accuracy=0.6153\n",
      "Train Batch 200 (every 100 batch): Loss=0.9192; accuracy=0.6204\n",
      "Train Batch 300 (every 100 batch): Loss=0.7511; accuracy=0.6231\n",
      "Epoch 25 summary: train_loss: 0.9293 | train_acc: 0.6253 | val_loss: 1.0512 | val_acc: 0.5676\n",
      "Epoch 26\n",
      "Train Batch 100 (every 100 batch): Loss=1.0239; accuracy=0.6278\n",
      "Train Batch 200 (every 100 batch): Loss=0.8645; accuracy=0.6251\n",
      "Train Batch 300 (every 100 batch): Loss=1.0097; accuracy=0.6223\n",
      "Epoch 26 summary: train_loss: 0.9243 | train_acc: 0.6238 | val_loss: 1.0303 | val_acc: 0.5690\n",
      "Epoch 27\n",
      "Train Batch 100 (every 100 batch): Loss=0.9265; accuracy=0.6269\n",
      "Train Batch 200 (every 100 batch): Loss=1.0344; accuracy=0.6244\n",
      "Train Batch 300 (every 100 batch): Loss=1.0719; accuracy=0.6249\n",
      "Epoch 27 summary: train_loss: 0.9254 | train_acc: 0.6254 | val_loss: 1.0220 | val_acc: 0.5698\n",
      "Epoch 28\n",
      "Train Batch 100 (every 100 batch): Loss=0.8803; accuracy=0.6172\n",
      "Train Batch 200 (every 100 batch): Loss=0.8927; accuracy=0.6248\n",
      "Train Batch 300 (every 100 batch): Loss=1.0108; accuracy=0.6239\n",
      "Epoch 28 summary: train_loss: 0.9229 | train_acc: 0.6258 | val_loss: 1.0658 | val_acc: 0.5549\n",
      "Epoch 29\n",
      "Train Batch 100 (every 100 batch): Loss=1.0824; accuracy=0.6228\n",
      "Train Batch 200 (every 100 batch): Loss=1.0049; accuracy=0.6240\n",
      "Train Batch 300 (every 100 batch): Loss=0.8600; accuracy=0.6260\n",
      "Epoch 29 summary: train_loss: 0.9149 | train_acc: 0.6260 | val_loss: 1.0356 | val_acc: 0.5661\n",
      "Epoch 30\n",
      "Train Batch 100 (every 100 batch): Loss=0.9950; accuracy=0.6248\n",
      "Train Batch 200 (every 100 batch): Loss=0.9224; accuracy=0.6284\n",
      "Train Batch 300 (every 100 batch): Loss=0.9813; accuracy=0.6297\n",
      "Epoch 30 summary: train_loss: 0.9148 | train_acc: 0.6283 | val_loss: 1.1041 | val_acc: 0.5512\n",
      "Epoch 31\n",
      "Train Batch 100 (every 100 batch): Loss=0.8902; accuracy=0.6300\n",
      "Train Batch 200 (every 100 batch): Loss=0.8611; accuracy=0.6299\n",
      "Train Batch 300 (every 100 batch): Loss=0.9467; accuracy=0.6323\n",
      "Epoch 31 summary: train_loss: 0.9071 | train_acc: 0.6328 | val_loss: 1.0397 | val_acc: 0.5683\n",
      "Epoch 32\n",
      "Train Batch 100 (every 100 batch): Loss=1.0166; accuracy=0.6244\n",
      "Train Batch 200 (every 100 batch): Loss=0.9968; accuracy=0.6288\n",
      "Train Batch 300 (every 100 batch): Loss=0.9658; accuracy=0.6310\n",
      "Epoch 32 summary: train_loss: 0.9097 | train_acc: 0.6307 | val_loss: 1.0648 | val_acc: 0.5683\n",
      "Epoch 33\n",
      "Train Batch 100 (every 100 batch): Loss=0.7997; accuracy=0.6311\n",
      "Train Batch 200 (every 100 batch): Loss=0.9739; accuracy=0.6321\n",
      "Train Batch 300 (every 100 batch): Loss=0.8219; accuracy=0.6328\n",
      "Epoch 33 summary: train_loss: 0.9094 | train_acc: 0.6316 | val_loss: 1.0160 | val_acc: 0.5734\n",
      "Epoch 34\n",
      "Train Batch 100 (every 100 batch): Loss=0.9229; accuracy=0.6270\n",
      "Train Batch 200 (every 100 batch): Loss=0.9487; accuracy=0.6271\n",
      "Train Batch 300 (every 100 batch): Loss=0.8027; accuracy=0.6294\n",
      "Epoch 34 summary: train_loss: 0.9041 | train_acc: 0.6307 | val_loss: 1.0136 | val_acc: 0.5767\n",
      "Epoch 35\n",
      "Train Batch 100 (every 100 batch): Loss=0.9316; accuracy=0.6345\n",
      "Train Batch 200 (every 100 batch): Loss=0.8368; accuracy=0.6333\n",
      "Train Batch 300 (every 100 batch): Loss=0.9197; accuracy=0.6314\n",
      "Epoch 35 summary: train_loss: 0.9050 | train_acc: 0.6312 | val_loss: 1.0432 | val_acc: 0.5767\n",
      "Epoch 36\n",
      "Train Batch 100 (every 100 batch): Loss=0.7375; accuracy=0.6337\n",
      "Train Batch 200 (every 100 batch): Loss=1.0342; accuracy=0.6366\n",
      "Train Batch 300 (every 100 batch): Loss=0.8615; accuracy=0.6361\n",
      "Epoch 36 summary: train_loss: 0.8999 | train_acc: 0.6389 | val_loss: 1.0036 | val_acc: 0.5778\n",
      "Epoch 37\n",
      "Train Batch 100 (every 100 batch): Loss=1.1151; accuracy=0.6333\n",
      "Train Batch 200 (every 100 batch): Loss=0.8112; accuracy=0.6378\n",
      "Train Batch 300 (every 100 batch): Loss=1.0197; accuracy=0.6370\n",
      "Epoch 37 summary: train_loss: 0.8972 | train_acc: 0.6383 | val_loss: 1.0754 | val_acc: 0.5610\n",
      "Epoch 38\n",
      "Train Batch 100 (every 100 batch): Loss=0.8709; accuracy=0.6383\n",
      "Train Batch 200 (every 100 batch): Loss=0.9026; accuracy=0.6353\n",
      "Train Batch 300 (every 100 batch): Loss=0.9707; accuracy=0.6335\n",
      "Epoch 38 summary: train_loss: 0.8995 | train_acc: 0.6362 | val_loss: 1.0641 | val_acc: 0.5592\n",
      "Epoch 39\n",
      "Train Batch 100 (every 100 batch): Loss=0.7251; accuracy=0.6366\n",
      "Train Batch 200 (every 100 batch): Loss=0.9233; accuracy=0.6382\n",
      "Train Batch 300 (every 100 batch): Loss=0.8725; accuracy=0.6384\n",
      "Epoch 39 summary: train_loss: 0.8999 | train_acc: 0.6360 | val_loss: 1.0154 | val_acc: 0.5789\n",
      "Epoch 40\n",
      "Train Batch 100 (every 100 batch): Loss=0.9211; accuracy=0.6356\n",
      "Train Batch 200 (every 100 batch): Loss=0.9663; accuracy=0.6387\n",
      "Train Batch 300 (every 100 batch): Loss=0.8344; accuracy=0.6372\n",
      "Epoch 40 summary: train_loss: 0.8979 | train_acc: 0.6372 | val_loss: 1.0148 | val_acc: 0.5767\n",
      "Epoch 41\n",
      "Train Batch 100 (every 100 batch): Loss=0.8919; accuracy=0.6458\n",
      "Train Batch 200 (every 100 batch): Loss=0.9124; accuracy=0.6384\n",
      "Train Batch 300 (every 100 batch): Loss=0.8897; accuracy=0.6409\n",
      "Epoch 41 summary: train_loss: 0.8907 | train_acc: 0.6412 | val_loss: 1.0457 | val_acc: 0.5752\n",
      "Epoch 42\n",
      "Train Batch 100 (every 100 batch): Loss=0.8458; accuracy=0.6433\n",
      "Train Batch 200 (every 100 batch): Loss=0.8361; accuracy=0.6445\n",
      "Train Batch 300 (every 100 batch): Loss=0.8837; accuracy=0.6432\n",
      "Epoch 42 summary: train_loss: 0.8920 | train_acc: 0.6428 | val_loss: 1.0321 | val_acc: 0.5785\n",
      "Epoch 43\n",
      "Train Batch 100 (every 100 batch): Loss=0.8487; accuracy=0.6495\n",
      "Train Batch 200 (every 100 batch): Loss=1.0487; accuracy=0.6407\n",
      "Train Batch 300 (every 100 batch): Loss=0.9160; accuracy=0.6391\n",
      "Epoch 43 summary: train_loss: 0.8922 | train_acc: 0.6402 | val_loss: 1.0259 | val_acc: 0.5763\n",
      "Epoch 44\n",
      "Train Batch 100 (every 100 batch): Loss=0.7801; accuracy=0.6475\n",
      "Train Batch 200 (every 100 batch): Loss=0.9760; accuracy=0.6486\n",
      "Train Batch 300 (every 100 batch): Loss=1.0216; accuracy=0.6468\n",
      "Epoch 44 summary: train_loss: 0.8880 | train_acc: 0.6460 | val_loss: 1.0243 | val_acc: 0.5781\n",
      "Epoch 45\n",
      "Train Batch 100 (every 100 batch): Loss=0.9669; accuracy=0.6348\n",
      "Train Batch 200 (every 100 batch): Loss=0.7018; accuracy=0.6391\n",
      "Train Batch 300 (every 100 batch): Loss=0.8167; accuracy=0.6394\n",
      "Epoch 45 summary: train_loss: 0.8891 | train_acc: 0.6409 | val_loss: 1.0259 | val_acc: 0.5828\n",
      "Epoch 46\n",
      "Train Batch 100 (every 100 batch): Loss=0.7475; accuracy=0.6389\n",
      "Train Batch 200 (every 100 batch): Loss=0.8282; accuracy=0.6393\n",
      "Train Batch 300 (every 100 batch): Loss=0.8364; accuracy=0.6396\n",
      "Epoch 46 summary: train_loss: 0.8882 | train_acc: 0.6398 | val_loss: 1.0195 | val_acc: 0.5912\n",
      "Epoch 47\n",
      "Train Batch 100 (every 100 batch): Loss=1.1250; accuracy=0.6314\n",
      "Train Batch 200 (every 100 batch): Loss=1.0238; accuracy=0.6383\n",
      "Train Batch 300 (every 100 batch): Loss=0.8434; accuracy=0.6436\n",
      "Epoch 47 summary: train_loss: 0.8869 | train_acc: 0.6444 | val_loss: 1.0304 | val_acc: 0.5839\n",
      "Epoch 48\n",
      "Train Batch 100 (every 100 batch): Loss=0.8632; accuracy=0.6525\n",
      "Train Batch 200 (every 100 batch): Loss=0.8343; accuracy=0.6473\n",
      "Train Batch 300 (every 100 batch): Loss=0.9243; accuracy=0.6477\n",
      "Epoch 48 summary: train_loss: 0.8796 | train_acc: 0.6481 | val_loss: 1.0213 | val_acc: 0.5749\n",
      "Epoch 49\n",
      "Train Batch 100 (every 100 batch): Loss=0.8310; accuracy=0.6425\n",
      "Train Batch 200 (every 100 batch): Loss=0.7567; accuracy=0.6421\n",
      "Train Batch 300 (every 100 batch): Loss=0.9693; accuracy=0.6430\n",
      "Epoch 49 summary: train_loss: 0.8812 | train_acc: 0.6438 | val_loss: 1.0456 | val_acc: 0.5759\n",
      "Epoch 50\n",
      "Train Batch 100 (every 100 batch): Loss=0.8885; accuracy=0.6448\n",
      "Train Batch 200 (every 100 batch): Loss=0.7811; accuracy=0.6426\n",
      "Train Batch 300 (every 100 batch): Loss=0.9095; accuracy=0.6431\n",
      "Epoch 50 summary: train_loss: 0.8855 | train_acc: 0.6432 | val_loss: 1.0055 | val_acc: 0.5810\n",
      "Epoch 51\n",
      "Train Batch 100 (every 100 batch): Loss=0.9278; accuracy=0.6445\n",
      "Train Batch 200 (every 100 batch): Loss=0.8443; accuracy=0.6480\n",
      "Train Batch 300 (every 100 batch): Loss=0.7897; accuracy=0.6473\n",
      "Epoch 51 summary: train_loss: 0.8784 | train_acc: 0.6479 | val_loss: 1.0088 | val_acc: 0.5963\n",
      "Epoch 52\n",
      "Train Batch 100 (every 100 batch): Loss=0.8256; accuracy=0.6463\n",
      "Train Batch 200 (every 100 batch): Loss=0.8163; accuracy=0.6462\n",
      "Train Batch 300 (every 100 batch): Loss=0.8457; accuracy=0.6485\n",
      "Epoch 52 summary: train_loss: 0.8818 | train_acc: 0.6495 | val_loss: 1.0315 | val_acc: 0.5785\n",
      "Epoch 53\n",
      "Train Batch 100 (every 100 batch): Loss=0.9262; accuracy=0.6581\n",
      "Train Batch 200 (every 100 batch): Loss=0.9252; accuracy=0.6550\n",
      "Train Batch 300 (every 100 batch): Loss=1.0916; accuracy=0.6504\n",
      "Epoch 53 summary: train_loss: 0.8758 | train_acc: 0.6507 | val_loss: 0.9926 | val_acc: 0.5868\n",
      "Epoch 54\n",
      "Train Batch 100 (every 100 batch): Loss=0.6663; accuracy=0.6480\n",
      "Train Batch 200 (every 100 batch): Loss=0.9267; accuracy=0.6432\n",
      "Train Batch 300 (every 100 batch): Loss=0.9898; accuracy=0.6449\n",
      "Epoch 54 summary: train_loss: 0.8801 | train_acc: 0.6464 | val_loss: 1.0646 | val_acc: 0.5727\n",
      "Epoch 55\n",
      "Train Batch 100 (every 100 batch): Loss=0.8384; accuracy=0.6480\n",
      "Train Batch 200 (every 100 batch): Loss=0.9480; accuracy=0.6441\n",
      "Train Batch 300 (every 100 batch): Loss=0.8577; accuracy=0.6444\n",
      "Epoch 55 summary: train_loss: 0.8836 | train_acc: 0.6431 | val_loss: 1.0051 | val_acc: 0.5799\n",
      "Epoch 56\n",
      "Train Batch 100 (every 100 batch): Loss=0.8498; accuracy=0.6455\n",
      "Train Batch 200 (every 100 batch): Loss=0.8241; accuracy=0.6470\n",
      "Train Batch 300 (every 100 batch): Loss=0.8560; accuracy=0.6457\n",
      "Epoch 56 summary: train_loss: 0.8757 | train_acc: 0.6472 | val_loss: 1.0154 | val_acc: 0.5865\n",
      "Epoch 57\n",
      "Train Batch 100 (every 100 batch): Loss=0.8439; accuracy=0.6453\n",
      "Train Batch 200 (every 100 batch): Loss=0.8188; accuracy=0.6491\n",
      "Train Batch 300 (every 100 batch): Loss=0.9486; accuracy=0.6491\n",
      "Epoch 57 summary: train_loss: 0.8798 | train_acc: 0.6479 | val_loss: 1.0256 | val_acc: 0.5839\n",
      "Epoch 58\n",
      "Train Batch 100 (every 100 batch): Loss=0.8972; accuracy=0.6480\n",
      "Train Batch 200 (every 100 batch): Loss=0.9935; accuracy=0.6443\n",
      "Train Batch 300 (every 100 batch): Loss=0.7669; accuracy=0.6460\n",
      "Epoch 58 summary: train_loss: 0.8782 | train_acc: 0.6460 | val_loss: 1.0133 | val_acc: 0.5807\n",
      "Epoch 59\n",
      "Train Batch 100 (every 100 batch): Loss=0.8754; accuracy=0.6580\n",
      "Train Batch 200 (every 100 batch): Loss=1.1537; accuracy=0.6545\n",
      "Train Batch 300 (every 100 batch): Loss=0.8652; accuracy=0.6535\n",
      "Epoch 59 summary: train_loss: 0.8700 | train_acc: 0.6528 | val_loss: 1.0358 | val_acc: 0.5803\n",
      "Epoch 60\n",
      "Train Batch 100 (every 100 batch): Loss=0.8350; accuracy=0.6364\n",
      "Train Batch 200 (every 100 batch): Loss=0.8458; accuracy=0.6403\n",
      "Train Batch 300 (every 100 batch): Loss=0.8949; accuracy=0.6424\n",
      "Epoch 60 summary: train_loss: 0.8717 | train_acc: 0.6426 | val_loss: 1.0096 | val_acc: 0.5858\n",
      "Epoch 61\n",
      "Train Batch 100 (every 100 batch): Loss=0.9915; accuracy=0.6469\n",
      "Train Batch 200 (every 100 batch): Loss=0.7111; accuracy=0.6521\n",
      "Train Batch 300 (every 100 batch): Loss=0.7984; accuracy=0.6527\n",
      "Epoch 61 summary: train_loss: 0.8691 | train_acc: 0.6504 | val_loss: 1.0544 | val_acc: 0.5694\n",
      "Epoch 62\n",
      "Train Batch 100 (every 100 batch): Loss=0.7035; accuracy=0.6516\n",
      "Train Batch 200 (every 100 batch): Loss=1.0486; accuracy=0.6572\n",
      "Train Batch 300 (every 100 batch): Loss=0.6945; accuracy=0.6546\n",
      "Epoch 62 summary: train_loss: 0.8665 | train_acc: 0.6540 | val_loss: 1.0887 | val_acc: 0.5574\n",
      "Epoch 63\n",
      "Train Batch 100 (every 100 batch): Loss=0.8142; accuracy=0.6438\n",
      "Train Batch 200 (every 100 batch): Loss=0.7497; accuracy=0.6473\n",
      "Train Batch 300 (every 100 batch): Loss=0.9727; accuracy=0.6492\n",
      "Epoch 63 summary: train_loss: 0.8726 | train_acc: 0.6503 | val_loss: 1.0751 | val_acc: 0.5625\n",
      "Epoch 64\n",
      "Train Batch 100 (every 100 batch): Loss=0.8257; accuracy=0.6484\n",
      "Train Batch 200 (every 100 batch): Loss=0.9525; accuracy=0.6481\n",
      "Train Batch 300 (every 100 batch): Loss=0.9652; accuracy=0.6503\n",
      "Epoch 64 summary: train_loss: 0.8687 | train_acc: 0.6518 | val_loss: 1.0146 | val_acc: 0.5883\n",
      "Epoch 65\n",
      "Train Batch 100 (every 100 batch): Loss=0.8358; accuracy=0.6500\n",
      "Train Batch 200 (every 100 batch): Loss=0.9827; accuracy=0.6548\n",
      "Train Batch 300 (every 100 batch): Loss=0.9078; accuracy=0.6524\n",
      "Epoch 65 summary: train_loss: 0.8677 | train_acc: 0.6527 | val_loss: 1.0233 | val_acc: 0.5847\n",
      "Epoch 66\n",
      "Train Batch 100 (every 100 batch): Loss=0.6582; accuracy=0.6566\n",
      "Train Batch 200 (every 100 batch): Loss=0.8820; accuracy=0.6540\n",
      "Train Batch 300 (every 100 batch): Loss=1.0351; accuracy=0.6523\n",
      "Epoch 66 summary: train_loss: 0.8701 | train_acc: 0.6505 | val_loss: 1.0029 | val_acc: 0.5847\n",
      "Epoch 67\n",
      "Train Batch 100 (every 100 batch): Loss=0.8928; accuracy=0.6567\n",
      "Train Batch 200 (every 100 batch): Loss=0.9483; accuracy=0.6548\n",
      "Train Batch 300 (every 100 batch): Loss=0.9885; accuracy=0.6575\n",
      "Epoch 67 summary: train_loss: 0.8640 | train_acc: 0.6571 | val_loss: 0.9972 | val_acc: 0.6007\n",
      "Epoch 68\n",
      "Train Batch 100 (every 100 batch): Loss=0.7891; accuracy=0.6498\n",
      "Train Batch 200 (every 100 batch): Loss=1.1723; accuracy=0.6519\n",
      "Train Batch 300 (every 100 batch): Loss=1.0215; accuracy=0.6498\n",
      "Epoch 68 summary: train_loss: 0.8696 | train_acc: 0.6500 | val_loss: 1.0701 | val_acc: 0.5650\n",
      "Epoch 69\n",
      "Train Batch 100 (every 100 batch): Loss=0.9223; accuracy=0.6622\n",
      "Train Batch 200 (every 100 batch): Loss=0.6419; accuracy=0.6554\n",
      "Train Batch 300 (every 100 batch): Loss=0.8744; accuracy=0.6519\n",
      "Epoch 69 summary: train_loss: 0.8638 | train_acc: 0.6525 | val_loss: 1.0583 | val_acc: 0.5676\n",
      "Epoch 70\n",
      "Train Batch 100 (every 100 batch): Loss=0.8327; accuracy=0.6513\n",
      "Train Batch 200 (every 100 batch): Loss=0.8702; accuracy=0.6572\n",
      "Train Batch 300 (every 100 batch): Loss=0.9023; accuracy=0.6541\n",
      "Epoch 70 summary: train_loss: 0.8666 | train_acc: 0.6527 | val_loss: 1.0275 | val_acc: 0.5778\n",
      "Epoch 71\n",
      "Train Batch 100 (every 100 batch): Loss=0.7536; accuracy=0.6494\n",
      "Train Batch 200 (every 100 batch): Loss=0.8275; accuracy=0.6504\n",
      "Train Batch 300 (every 100 batch): Loss=0.8706; accuracy=0.6531\n",
      "Epoch 71 summary: train_loss: 0.8668 | train_acc: 0.6550 | val_loss: 1.0539 | val_acc: 0.5763\n",
      "Epoch 72\n",
      "Train Batch 100 (every 100 batch): Loss=0.9344; accuracy=0.6486\n",
      "Train Batch 200 (every 100 batch): Loss=0.7524; accuracy=0.6573\n",
      "Train Batch 300 (every 100 batch): Loss=0.7518; accuracy=0.6578\n",
      "Epoch 72 summary: train_loss: 0.8570 | train_acc: 0.6580 | val_loss: 1.0785 | val_acc: 0.5650\n",
      "Epoch 73\n",
      "Train Batch 100 (every 100 batch): Loss=1.0591; accuracy=0.6570\n",
      "Train Batch 200 (every 100 batch): Loss=1.0546; accuracy=0.6559\n",
      "Train Batch 300 (every 100 batch): Loss=0.7362; accuracy=0.6559\n",
      "Epoch 73 summary: train_loss: 0.8637 | train_acc: 0.6553 | val_loss: 1.0400 | val_acc: 0.5727\n",
      "Epoch 74\n",
      "Train Batch 100 (every 100 batch): Loss=0.9101; accuracy=0.6558\n",
      "Train Batch 200 (every 100 batch): Loss=0.9457; accuracy=0.6537\n",
      "Train Batch 300 (every 100 batch): Loss=0.7509; accuracy=0.6571\n",
      "Epoch 74 summary: train_loss: 0.8640 | train_acc: 0.6557 | val_loss: 1.1005 | val_acc: 0.5683\n",
      "Epoch 75\n",
      "Train Batch 100 (every 100 batch): Loss=0.8942; accuracy=0.6578\n",
      "Train Batch 200 (every 100 batch): Loss=0.8613; accuracy=0.6520\n",
      "Train Batch 300 (every 100 batch): Loss=0.8109; accuracy=0.6559\n",
      "Epoch 75 summary: train_loss: 0.8601 | train_acc: 0.6554 | val_loss: 1.0245 | val_acc: 0.5876\n",
      "Epoch 76\n",
      "Train Batch 100 (every 100 batch): Loss=0.9499; accuracy=0.6503\n",
      "Train Batch 200 (every 100 batch): Loss=0.9829; accuracy=0.6553\n",
      "Train Batch 300 (every 100 batch): Loss=0.9951; accuracy=0.6577\n",
      "Epoch 76 summary: train_loss: 0.8591 | train_acc: 0.6581 | val_loss: 1.0157 | val_acc: 0.5847\n",
      "Epoch 77\n",
      "Train Batch 100 (every 100 batch): Loss=0.8958; accuracy=0.6528\n",
      "Train Batch 200 (every 100 batch): Loss=0.8323; accuracy=0.6534\n",
      "Train Batch 300 (every 100 batch): Loss=0.7977; accuracy=0.6564\n",
      "Epoch 77 summary: train_loss: 0.8588 | train_acc: 0.6535 | val_loss: 1.0151 | val_acc: 0.5785\n",
      "Epoch 78\n",
      "Train Batch 100 (every 100 batch): Loss=0.6984; accuracy=0.6655\n",
      "Train Batch 200 (every 100 batch): Loss=0.7653; accuracy=0.6595\n",
      "Train Batch 300 (every 100 batch): Loss=0.9261; accuracy=0.6583\n",
      "Epoch 78 summary: train_loss: 0.8587 | train_acc: 0.6567 | val_loss: 1.0424 | val_acc: 0.5778\n",
      "Epoch 79\n",
      "Train Batch 100 (every 100 batch): Loss=0.6465; accuracy=0.6580\n",
      "Train Batch 200 (every 100 batch): Loss=0.9953; accuracy=0.6584\n",
      "Train Batch 300 (every 100 batch): Loss=1.0472; accuracy=0.6557\n",
      "Epoch 79 summary: train_loss: 0.8580 | train_acc: 0.6561 | val_loss: 1.0303 | val_acc: 0.5810\n",
      "Epoch 80\n",
      "Train Batch 100 (every 100 batch): Loss=0.9215; accuracy=0.6544\n",
      "Train Batch 200 (every 100 batch): Loss=0.6791; accuracy=0.6638\n",
      "Train Batch 300 (every 100 batch): Loss=0.8103; accuracy=0.6595\n",
      "Epoch 80 summary: train_loss: 0.8538 | train_acc: 0.6597 | val_loss: 1.0204 | val_acc: 0.5785\n",
      "Epoch 81\n",
      "Train Batch 100 (every 100 batch): Loss=0.7492; accuracy=0.6572\n",
      "Train Batch 200 (every 100 batch): Loss=0.8667; accuracy=0.6590\n",
      "Train Batch 300 (every 100 batch): Loss=0.7542; accuracy=0.6561\n",
      "Epoch 81 summary: train_loss: 0.8539 | train_acc: 0.6563 | val_loss: 1.1151 | val_acc: 0.5610\n",
      "Epoch 82\n",
      "Train Batch 100 (every 100 batch): Loss=0.8833; accuracy=0.6528\n",
      "Train Batch 200 (every 100 batch): Loss=0.9479; accuracy=0.6555\n",
      "Train Batch 300 (every 100 batch): Loss=0.9956; accuracy=0.6595\n",
      "Epoch 82 summary: train_loss: 0.8539 | train_acc: 0.6583 | val_loss: 1.0182 | val_acc: 0.5887\n",
      "Epoch 83\n",
      "Train Batch 100 (every 100 batch): Loss=0.8690; accuracy=0.6650\n",
      "Train Batch 200 (every 100 batch): Loss=0.8704; accuracy=0.6629\n",
      "Train Batch 300 (every 100 batch): Loss=0.9768; accuracy=0.6585\n",
      "Epoch 83 summary: train_loss: 0.8559 | train_acc: 0.6576 | val_loss: 1.0173 | val_acc: 0.5930\n",
      "Epoch 84\n",
      "Train Batch 100 (every 100 batch): Loss=0.8004; accuracy=0.6644\n",
      "Train Batch 200 (every 100 batch): Loss=0.9344; accuracy=0.6620\n",
      "Train Batch 300 (every 100 batch): Loss=0.9307; accuracy=0.6578\n",
      "Epoch 84 summary: train_loss: 0.8587 | train_acc: 0.6570 | val_loss: 1.0437 | val_acc: 0.5730\n",
      "Epoch 85\n",
      "Train Batch 100 (every 100 batch): Loss=0.8290; accuracy=0.6538\n",
      "Train Batch 200 (every 100 batch): Loss=0.8695; accuracy=0.6534\n",
      "Train Batch 300 (every 100 batch): Loss=0.8205; accuracy=0.6506\n",
      "Epoch 85 summary: train_loss: 0.8600 | train_acc: 0.6532 | val_loss: 1.0233 | val_acc: 0.5905\n",
      "Epoch 86\n",
      "Train Batch 100 (every 100 batch): Loss=0.8613; accuracy=0.6566\n",
      "Train Batch 200 (every 100 batch): Loss=0.8994; accuracy=0.6542\n",
      "Train Batch 300 (every 100 batch): Loss=0.7631; accuracy=0.6612\n",
      "Epoch 86 summary: train_loss: 0.8515 | train_acc: 0.6605 | val_loss: 1.0162 | val_acc: 0.5948\n",
      "Epoch 87\n",
      "Train Batch 100 (every 100 batch): Loss=0.7371; accuracy=0.6642\n",
      "Train Batch 200 (every 100 batch): Loss=0.8935; accuracy=0.6578\n",
      "Train Batch 300 (every 100 batch): Loss=0.8213; accuracy=0.6555\n",
      "Epoch 87 summary: train_loss: 0.8594 | train_acc: 0.6540 | val_loss: 1.0369 | val_acc: 0.5814\n",
      "Epoch 88\n",
      "Train Batch 100 (every 100 batch): Loss=0.8957; accuracy=0.6652\n",
      "Train Batch 200 (every 100 batch): Loss=0.8334; accuracy=0.6630\n",
      "Train Batch 300 (every 100 batch): Loss=0.8054; accuracy=0.6617\n",
      "Epoch 88 summary: train_loss: 0.8541 | train_acc: 0.6611 | val_loss: 1.0416 | val_acc: 0.5745\n",
      "Epoch 89\n",
      "Train Batch 100 (every 100 batch): Loss=1.0103; accuracy=0.6634\n",
      "Train Batch 200 (every 100 batch): Loss=0.8601; accuracy=0.6655\n",
      "Train Batch 300 (every 100 batch): Loss=1.0023; accuracy=0.6618\n",
      "Epoch 89 summary: train_loss: 0.8535 | train_acc: 0.6616 | val_loss: 1.0144 | val_acc: 0.5901\n",
      "Epoch 90\n",
      "Train Batch 100 (every 100 batch): Loss=0.8423; accuracy=0.6616\n",
      "Train Batch 200 (every 100 batch): Loss=0.7195; accuracy=0.6625\n",
      "Train Batch 300 (every 100 batch): Loss=0.7057; accuracy=0.6602\n",
      "Epoch 90 summary: train_loss: 0.8469 | train_acc: 0.6621 | val_loss: 1.0536 | val_acc: 0.5778\n",
      "Epoch 91\n",
      "Train Batch 100 (every 100 batch): Loss=1.0277; accuracy=0.6730\n",
      "Train Batch 200 (every 100 batch): Loss=0.9504; accuracy=0.6618\n",
      "Train Batch 300 (every 100 batch): Loss=0.9720; accuracy=0.6572\n",
      "Epoch 91 summary: train_loss: 0.8524 | train_acc: 0.6585 | val_loss: 1.0114 | val_acc: 0.5785\n",
      "Epoch 92\n",
      "Train Batch 100 (every 100 batch): Loss=0.6592; accuracy=0.6730\n",
      "Train Batch 200 (every 100 batch): Loss=0.9690; accuracy=0.6659\n",
      "Train Batch 300 (every 100 batch): Loss=0.8233; accuracy=0.6649\n",
      "Epoch 92 summary: train_loss: 0.8511 | train_acc: 0.6642 | val_loss: 1.0430 | val_acc: 0.5734\n",
      "Epoch 93\n",
      "Train Batch 100 (every 100 batch): Loss=0.8014; accuracy=0.6622\n",
      "Train Batch 200 (every 100 batch): Loss=0.7928; accuracy=0.6644\n",
      "Train Batch 300 (every 100 batch): Loss=0.8598; accuracy=0.6621\n",
      "Epoch 93 summary: train_loss: 0.8491 | train_acc: 0.6601 | val_loss: 1.0489 | val_acc: 0.5719\n",
      "Epoch 94\n",
      "Train Batch 100 (every 100 batch): Loss=0.7550; accuracy=0.6589\n",
      "Train Batch 200 (every 100 batch): Loss=0.7781; accuracy=0.6600\n",
      "Train Batch 300 (every 100 batch): Loss=0.9554; accuracy=0.6621\n",
      "Epoch 94 summary: train_loss: 0.8519 | train_acc: 0.6631 | val_loss: 1.0489 | val_acc: 0.5785\n",
      "Epoch 95\n",
      "Train Batch 100 (every 100 batch): Loss=0.7750; accuracy=0.6700\n",
      "Train Batch 200 (every 100 batch): Loss=0.7446; accuracy=0.6653\n",
      "Train Batch 300 (every 100 batch): Loss=0.8207; accuracy=0.6634\n",
      "Epoch 95 summary: train_loss: 0.8523 | train_acc: 0.6596 | val_loss: 1.0015 | val_acc: 0.5988\n",
      "Epoch 96\n",
      "Train Batch 100 (every 100 batch): Loss=0.8883; accuracy=0.6525\n",
      "Train Batch 200 (every 100 batch): Loss=0.8233; accuracy=0.6549\n",
      "Train Batch 300 (every 100 batch): Loss=0.7571; accuracy=0.6594\n",
      "Epoch 96 summary: train_loss: 0.8494 | train_acc: 0.6578 | val_loss: 1.0585 | val_acc: 0.5738\n",
      "Epoch 97\n",
      "Train Batch 100 (every 100 batch): Loss=0.8936; accuracy=0.6678\n",
      "Train Batch 200 (every 100 batch): Loss=0.8385; accuracy=0.6679\n",
      "Train Batch 300 (every 100 batch): Loss=1.0653; accuracy=0.6626\n",
      "Epoch 97 summary: train_loss: 0.8501 | train_acc: 0.6620 | val_loss: 0.9998 | val_acc: 0.5959\n",
      "Epoch 98\n",
      "Train Batch 100 (every 100 batch): Loss=0.8511; accuracy=0.6592\n",
      "Train Batch 200 (every 100 batch): Loss=0.8458; accuracy=0.6591\n",
      "Train Batch 300 (every 100 batch): Loss=0.8599; accuracy=0.6628\n",
      "Epoch 98 summary: train_loss: 0.8494 | train_acc: 0.6612 | val_loss: 1.0743 | val_acc: 0.5785\n",
      "Epoch 99\n",
      "Train Batch 100 (every 100 batch): Loss=0.7151; accuracy=0.6652\n",
      "Train Batch 200 (every 100 batch): Loss=0.6293; accuracy=0.6623\n",
      "Train Batch 300 (every 100 batch): Loss=0.7941; accuracy=0.6636\n",
      "Epoch 99 summary: train_loss: 0.8502 | train_acc: 0.6632 | val_loss: 1.0121 | val_acc: 0.5836\n",
      "Epoch 100\n",
      "Train Batch 100 (every 100 batch): Loss=0.8015; accuracy=0.6641\n",
      "Train Batch 200 (every 100 batch): Loss=0.8640; accuracy=0.6648\n",
      "Train Batch 300 (every 100 batch): Loss=0.7008; accuracy=0.6609\n",
      "Epoch 100 summary: train_loss: 0.8471 | train_acc: 0.6630 | val_loss: 1.0323 | val_acc: 0.5763\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class 'EEG_Encoder.EEGNet.classifier_EEGNet'>: it's not the same object as EEG_Encoder.EEGNet.classifier_EEGNet",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m non_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mkind\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom-scratch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mnet_trainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchannel_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnonclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/Experiment/EEG_Encoder/net_trainer.py:127\u001b[0m, in \u001b[0;36mnet_trainer\u001b[0;34m(net, loaders, opt, channel_idx, nonclasses, pretrain, train, save, print_every_train, print_every_val)\u001b[0m\n\u001b[1;32m    125\u001b[0m         results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(val_acc)\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m save \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     results \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/.env/lib/python3.10/site-packages/torch/serialization.py:441\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 441\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/GithubClonedRepo/EEG-Research/.env/lib/python3.10/site-packages/torch/serialization.py:653\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    651\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m    652\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m--> 653\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    654\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    655\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mPicklingError\u001b[0m: Can't pickle <class 'EEG_Encoder.EEGNet.classifier_EEGNet'>: it's not the same object as EEG_Encoder.EEGNet.classifier_EEGNet"
     ]
    }
   ],
   "source": [
    "channel_idx=None\n",
    "non_classes=None\n",
    "if opt.kind==\"from-scratch\":\n",
    "    results = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0199dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val =accuracy_val\n",
    "# test = accuracy_test\n",
    "\n",
    "# print(\"Validation accuracy: \", val)\n",
    "# print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(results, results_path+'.obj')\n",
    "loaded_results = torch.load(results_path+'.obj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89f19f5-15b8-42f8-a942-4cb82e95d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = loaded_results['train_loss']\n",
    "val_values = loaded_results['val_loss']\n",
    "print(len(train_values))\n",
    "print(len(val_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 101)\n",
    "print(len(epochs))\n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, train_values, label='Training Loss')\n",
    "plt.plot(epochs, val_values, label='Validation Loss')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, 101, 10))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b02c66-313e-44c9-8a39-dac61f759ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_values = torch.stack(loaded_results['train_acc']).tolist()\n",
    "val_acc_values = torch.stack(loaded_results['val_acc']).tolist()\n",
    "print(len(train_acc_values))\n",
    "print(len(val_acc_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a7d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, 101)\n",
    "print(len(epochs))\n",
    "# Plot and label the training and validation loss values\n",
    "plt.plot(epochs, train_acc_values, label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc_values, label='Validation Accuracy')\n",
    " \n",
    "# Add in a title and axes labels\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    " \n",
    "# Set the tick locations\n",
    "plt.xticks(np.arange(0, 101, 10))\n",
    " \n",
    "# Display the plot\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2334ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b77fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080e706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17823cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b650c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb911b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b43930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28237288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ded073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcbdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fb11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b75470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8939417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5c258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597563e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d74a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db30ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1544e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
