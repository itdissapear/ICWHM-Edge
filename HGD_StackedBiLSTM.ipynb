{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7f6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c192d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf1a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n",
      "<torch.cuda.device object at 0x7f50f20c3670>\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff733115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "# length = 440\n",
    "# channel = 128\n",
    "# min_CNN = 200\n",
    "n_classes = 4\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b68db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if platform == \"linux\" or platform == \"linux2\":\n",
    "#     torch_models_dir = r\"/media/titan/AI Research1/Data/CVPR2017\"\n",
    "# elif platform == \"win32\":\n",
    "#     torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "# block_splits_all, block_splits_single, eeg_14_70, eeg_55_95, eeg_5_95, eeg_raw = os.listdir(torch_models_dir)\n",
    "# print(os.listdir(torch_models_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bc401c6-e7e3-4163-9a3e-fa0aea23551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_dataset = '/media/mountHDD1/LanxHuyen/high_gamma_dataset.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3ad4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_dataset = os.path.join(torch_models_dir, eeg_5_95)\n",
    "# splits_all_path = os.path.join(torch_models_dir, block_splits_all)\n",
    "# splits_single_path = os.path.join(torch_models_dir, block_splits_single)\n",
    "# # splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "# print(eeg_dataset,'\\n', splits_all_path, '\\n', splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659d4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits_all = torch.load(splits_all_path)\n",
    "# splits_single = torch.load(splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3ef344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(splits_all['splits']))\n",
    "# print(len(splits_all['splits'][0]))\n",
    "\n",
    "# print(len(splits_all['splits'][5]['train']))\n",
    "# print(len(splits_all['splits'][5]['val']))\n",
    "# print(len(splits_all['splits'][5]['test']))\n",
    "# print(splits_all['splits'][0]['train'][:40])\n",
    "# print(splits_all['splits'][1]['train'][:40])\n",
    "# print(splits_all['splits'][2]['train'][:10])\n",
    "# print(splits_all['splits'][3]['train'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27b3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(splits_single)\n",
    "# print(len(splits_single['splits'][0]['train']))\n",
    "# print(len(splits_single['splits'][0]['val']))\n",
    "# print(len(splits_single['splits'][0]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed58c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_loaded = torch.load(eeg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a637c6f-a7c4-4689-9036-0b1f0089ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(eeg_loaded)))\n",
    "random.shuffle(list(range(len(eeg_loaded))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "682d14b3-76a3-456e-99eb-bf75d423c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(eeg_loaded))\n",
    "val_size = int(0.1 * len(eeg_loaded))\n",
    "test_size = len(eeg_loaded) - (train_size + val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6cd3e5f-d47b-4cb4-ad42-1f46608eb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size+val_size]\n",
    "test_indices = indices[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f3026ea-0a7a-4031-9a3d-e3e3540254f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_splits = {\"train\": train_indices, \"val\": val_indices, \"test\": test_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89460bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26968\n",
      "26968\n"
     ]
    }
   ],
   "source": [
    "print(len(eeg_loaded))\n",
    "# print(eeg_loaded.keys())\n",
    "eeg = [eeg_loaded[i][\"eeg\"] for i in range (len(eeg_loaded))]\n",
    "print(len(eeg))\n",
    "# for dataset_idx in range (len(eeg_loaded)): \n",
    "#     eeg, label = [eeg_loaded[dataset_idx][key] for key in ['eeg', 'label']]\n",
    "# print((label))\n",
    "# print(len(eeg))\n",
    "# # print(len(dataset))\n",
    "\n",
    "# # print(labels)\n",
    "# # print(images[0])\n",
    "# print(eeg['eeg'][0].shape)\n",
    "# print(eeg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d20c958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "#     \"iv\": \"image\",\n",
    "#     \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    #\"subject\": 0,\n",
    "    \"time_low\": 20,\n",
    "    \"time_high\": 270,\n",
    "#     \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"model_type\": \"model10\",\n",
    "    #\"splits_path\": splits_all_path,\n",
    "    #\"split_num\": 0,\n",
    "    \"split_name\": \"train\",\n",
    "#     \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 64,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"from-scratch\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.time_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ce8d6e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "# from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from data_loader_HGD import EEGDataset, Splitter\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a5b475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "#              offset,\n",
    "             eeg_dataset,\n",
    "             #splits_path,\n",
    "             #split_num, # (0-5) - 6 fold cross validation\n",
    "             split_name,\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             kind=\"from-scratch\"):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(opt, eeg_dataset)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "#     # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "#     if kind==\"from-scratch\":\n",
    "#         relabel = False\n",
    "#     if kind==\"incremental\":\n",
    "#         relabel = False\n",
    "#     if kind==\"no-model-file\":\n",
    "#         relabel = True\n",
    "    splitter = {split: Splitter(dataset,\n",
    "                    #splits_path,\n",
    "                    #split_num,\n",
    "                    split_name = split) \n",
    "                for split in [\"train\", \"val\", \"test\"]\n",
    "                                }\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a242cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "opt.classifier = \"Stacked_BiLSTM\"\n",
    "opt.batch_size = 64\n",
    "# opt.kind = \"from-scratch\"\n",
    "# opt.run = \"imagenet40-1000\"\n",
    "# opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "633488a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(\n",
    "#              offset,\n",
    "             opt.eeg_dataset,\n",
    "             #opt.splits_path,\n",
    "             #opt.split_num, # (0-5) - 6 fold cross validation\n",
    "             opt.split_name,\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             opt.batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e99fc973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader_HGD.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [338, 43, 43]\n",
      "1: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "2: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "3: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "4: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "5: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "6: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "7: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "8: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "9: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "10: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "11: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "12: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "13: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "14: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "15: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "16: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "17: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "18: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "19: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "20: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 8000 idx, val: 2000 idx, test: 2000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250 idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i, (input, target) in enumerate(loaders[\"train\"]):\n",
    "    if i<20:\n",
    "        print(f\"{i+1}: Target size: {target.size()}; input size: {input.size()}\")\n",
    "# for i in range(0, 40):\n",
    "#     eeg, label_val = splitter[\"val\"][i]\n",
    "#     eeg, label_train = splitter[\"train\"][i]\n",
    "#     print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "39a07cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_Stacked_BiLSTM(\n",
      "  (stacked_bilstm): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (output1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output2): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_Stacked_BiLSTM                [1, 4]                    --\n",
       "├─LSTM: 1-1                              [1, 250, 256]             659,456\n",
       "├─Linear: 1-2                            [1, 128]                  32,896\n",
       "├─ReLU: 1-3                              [1, 128]                  --\n",
       "├─Linear: 1-4                            [1, 4]                    516\n",
       "==========================================================================================\n",
       "Total params: 692,868\n",
       "Trainable params: 692,868\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 164.90\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 0.51\n",
       "Params size (MB): 2.77\n",
       "Estimated Total Size (MB): 3.41\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1,128, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8a8d6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked_BiLSTM -HGD\n"
     ]
    }
   ],
   "source": [
    "model_path = (   opt.classifier+\n",
    "                  \" -\" + \"HGD\" )\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4b753db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(results_file='results.pkl', time_low=20, time_high=270, eeg_dataset='/media/mountHDD1/LanxHuyen/high_gamma_dataset.pth', model_type='model10', split_name='train', batch_size=64, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='Stacked_BiLSTM')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5334cb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Batch 100 (every 100 batch): Loss=1.2256; accuracy=0.3878\n",
      "Train Batch 200 (every 100 batch): Loss=1.2851; accuracy=0.4137\n",
      "Train Batch 300 (every 100 batch): Loss=1.0662; accuracy=0.4363\n",
      "Epoch 1 summary: train_loss: 1.2106 | train_acc: 0.4380 | val_loss: 1.1737 | val_acc: 0.4597\n",
      "Epoch 2\n",
      "Train Batch 100 (every 100 batch): Loss=1.1608; accuracy=0.5080\n",
      "Train Batch 200 (every 100 batch): Loss=1.0791; accuracy=0.5094\n",
      "Train Batch 300 (every 100 batch): Loss=1.0534; accuracy=0.5053\n",
      "Epoch 2 summary: train_loss: 1.1242 | train_acc: 0.5038 | val_loss: 1.2152 | val_acc: 0.4320\n",
      "Epoch 3\n",
      "Train Batch 100 (every 100 batch): Loss=0.9907; accuracy=0.5300\n",
      "Train Batch 200 (every 100 batch): Loss=0.8937; accuracy=0.5387\n",
      "Train Batch 300 (every 100 batch): Loss=1.0857; accuracy=0.5389\n",
      "Epoch 3 summary: train_loss: 1.0645 | train_acc: 0.5417 | val_loss: 1.2098 | val_acc: 0.4742\n",
      "Epoch 4\n",
      "Train Batch 100 (every 100 batch): Loss=0.9391; accuracy=0.5622\n",
      "Train Batch 200 (every 100 batch): Loss=1.1105; accuracy=0.5721\n",
      "Train Batch 300 (every 100 batch): Loss=0.7222; accuracy=0.5761\n",
      "Epoch 4 summary: train_loss: 1.0026 | train_acc: 0.5772 | val_loss: 1.2338 | val_acc: 0.4738\n",
      "Epoch 5\n",
      "Train Batch 100 (every 100 batch): Loss=1.1152; accuracy=0.6058\n",
      "Train Batch 200 (every 100 batch): Loss=0.9069; accuracy=0.6080\n",
      "Train Batch 300 (every 100 batch): Loss=1.1293; accuracy=0.6137\n",
      "Epoch 5 summary: train_loss: 0.9364 | train_acc: 0.6146 | val_loss: 1.2699 | val_acc: 0.4669\n",
      "Epoch 6\n",
      "Train Batch 100 (every 100 batch): Loss=0.9623; accuracy=0.6417\n",
      "Train Batch 200 (every 100 batch): Loss=0.8978; accuracy=0.6436\n",
      "Train Batch 300 (every 100 batch): Loss=1.0173; accuracy=0.6491\n",
      "Epoch 6 summary: train_loss: 0.8723 | train_acc: 0.6492 | val_loss: 1.2203 | val_acc: 0.4906\n",
      "Epoch 7\n",
      "Train Batch 100 (every 100 batch): Loss=0.8251; accuracy=0.6784\n",
      "Train Batch 200 (every 100 batch): Loss=0.7280; accuracy=0.6777\n",
      "Train Batch 300 (every 100 batch): Loss=0.6630; accuracy=0.6797\n",
      "Epoch 7 summary: train_loss: 0.7972 | train_acc: 0.6803 | val_loss: 1.3223 | val_acc: 0.5015\n",
      "Epoch 8\n",
      "Train Batch 100 (every 100 batch): Loss=0.6313; accuracy=0.7177\n",
      "Train Batch 200 (every 100 batch): Loss=0.5823; accuracy=0.7084\n",
      "Train Batch 300 (every 100 batch): Loss=0.7590; accuracy=0.7111\n",
      "Epoch 8 summary: train_loss: 0.7273 | train_acc: 0.7132 | val_loss: 1.3939 | val_acc: 0.4862\n",
      "Epoch 9\n",
      "Train Batch 100 (every 100 batch): Loss=0.6355; accuracy=0.7394\n",
      "Train Batch 200 (every 100 batch): Loss=0.6485; accuracy=0.7406\n",
      "Train Batch 300 (every 100 batch): Loss=0.6310; accuracy=0.7419\n",
      "Epoch 9 summary: train_loss: 0.6608 | train_acc: 0.7431 | val_loss: 1.4588 | val_acc: 0.4757\n",
      "Epoch 10\n",
      "Train Batch 100 (every 100 batch): Loss=0.5243; accuracy=0.7864\n",
      "Train Batch 200 (every 100 batch): Loss=0.6323; accuracy=0.7737\n",
      "Train Batch 300 (every 100 batch): Loss=0.6462; accuracy=0.7673\n",
      "Epoch 10 summary: train_loss: 0.6002 | train_acc: 0.7649 | val_loss: 1.4130 | val_acc: 0.5058\n",
      "Epoch 11\n",
      "Train Batch 100 (every 100 batch): Loss=0.5713; accuracy=0.8098\n",
      "Train Batch 200 (every 100 batch): Loss=0.7149; accuracy=0.8036\n",
      "Train Batch 300 (every 100 batch): Loss=0.5584; accuracy=0.8007\n",
      "Epoch 11 summary: train_loss: 0.5203 | train_acc: 0.7992 | val_loss: 1.6931 | val_acc: 0.4855\n",
      "Epoch 12\n",
      "Train Batch 100 (every 100 batch): Loss=0.4422; accuracy=0.8216\n",
      "Train Batch 200 (every 100 batch): Loss=0.4488; accuracy=0.8218\n",
      "Train Batch 300 (every 100 batch): Loss=0.3501; accuracy=0.8185\n",
      "Epoch 12 summary: train_loss: 0.4719 | train_acc: 0.8181 | val_loss: 1.6594 | val_acc: 0.4927\n",
      "Epoch 13\n",
      "Train Batch 100 (every 100 batch): Loss=0.5338; accuracy=0.8533\n",
      "Train Batch 200 (every 100 batch): Loss=0.3006; accuracy=0.8493\n",
      "Train Batch 300 (every 100 batch): Loss=0.4472; accuracy=0.8441\n",
      "Epoch 13 summary: train_loss: 0.4066 | train_acc: 0.8426 | val_loss: 1.7823 | val_acc: 0.5047\n",
      "Epoch 14\n",
      "Train Batch 100 (every 100 batch): Loss=0.3562; accuracy=0.8678\n",
      "Train Batch 200 (every 100 batch): Loss=0.3158; accuracy=0.8660\n",
      "Train Batch 300 (every 100 batch): Loss=0.2511; accuracy=0.8656\n",
      "Epoch 14 summary: train_loss: 0.3502 | train_acc: 0.8650 | val_loss: 2.0659 | val_acc: 0.4800\n",
      "Epoch 15\n",
      "Train Batch 100 (every 100 batch): Loss=0.1814; accuracy=0.9116\n",
      "Train Batch 200 (every 100 batch): Loss=0.2963; accuracy=0.9067\n",
      "Train Batch 300 (every 100 batch): Loss=0.3360; accuracy=0.9000\n",
      "Epoch 15 summary: train_loss: 0.2749 | train_acc: 0.8977 | val_loss: 2.1655 | val_acc: 0.4815\n",
      "Epoch 16\n",
      "Train Batch 100 (every 100 batch): Loss=0.2452; accuracy=0.9230\n",
      "Train Batch 200 (every 100 batch): Loss=0.2287; accuracy=0.9156\n",
      "Train Batch 300 (every 100 batch): Loss=0.3036; accuracy=0.9114\n",
      "Epoch 16 summary: train_loss: 0.2375 | train_acc: 0.9107 | val_loss: 2.4137 | val_acc: 0.4709\n",
      "Epoch 17\n",
      "Train Batch 100 (every 100 batch): Loss=0.1581; accuracy=0.9369\n",
      "Train Batch 200 (every 100 batch): Loss=0.2700; accuracy=0.9284\n",
      "Train Batch 300 (every 100 batch): Loss=0.2246; accuracy=0.9235\n",
      "Epoch 17 summary: train_loss: 0.2155 | train_acc: 0.9208 | val_loss: 2.3303 | val_acc: 0.4753\n",
      "Epoch 18\n",
      "Train Batch 100 (every 100 batch): Loss=0.1174; accuracy=0.9405\n",
      "Train Batch 200 (every 100 batch): Loss=0.1129; accuracy=0.9388\n",
      "Train Batch 300 (every 100 batch): Loss=0.2163; accuracy=0.9364\n",
      "Epoch 18 summary: train_loss: 0.1790 | train_acc: 0.9343 | val_loss: 2.4566 | val_acc: 0.4927\n",
      "Epoch 19\n",
      "Train Batch 100 (every 100 batch): Loss=0.1014; accuracy=0.9470\n",
      "Train Batch 200 (every 100 batch): Loss=0.1275; accuracy=0.9491\n",
      "Train Batch 300 (every 100 batch): Loss=0.0659; accuracy=0.9490\n",
      "Epoch 19 summary: train_loss: 0.1448 | train_acc: 0.9479 | val_loss: 2.8608 | val_acc: 0.4797\n",
      "Epoch 20\n",
      "Train Batch 100 (every 100 batch): Loss=0.1592; accuracy=0.9603\n",
      "Train Batch 200 (every 100 batch): Loss=0.0712; accuracy=0.9598\n",
      "Train Batch 300 (every 100 batch): Loss=0.3420; accuracy=0.9487\n",
      "Epoch 20 summary: train_loss: 0.1507 | train_acc: 0.9457 | val_loss: 2.6865 | val_acc: 0.4782\n",
      "Epoch 21\n",
      "Train Batch 100 (every 100 batch): Loss=0.1144; accuracy=0.9478\n",
      "Train Batch 200 (every 100 batch): Loss=0.1317; accuracy=0.9487\n",
      "Train Batch 300 (every 100 batch): Loss=0.1296; accuracy=0.9477\n",
      "Epoch 21 summary: train_loss: 0.1462 | train_acc: 0.9472 | val_loss: 2.6956 | val_acc: 0.4869\n",
      "Epoch 22\n",
      "Train Batch 100 (every 100 batch): Loss=0.0605; accuracy=0.9652\n",
      "Train Batch 200 (every 100 batch): Loss=0.0770; accuracy=0.9656\n",
      "Train Batch 300 (every 100 batch): Loss=0.2062; accuracy=0.9644\n",
      "Epoch 22 summary: train_loss: 0.1033 | train_acc: 0.9631 | val_loss: 3.0988 | val_acc: 0.4731\n",
      "Epoch 23\n",
      "Train Batch 100 (every 100 batch): Loss=0.0197; accuracy=0.9766\n",
      "Train Batch 200 (every 100 batch): Loss=0.0810; accuracy=0.9764\n",
      "Train Batch 300 (every 100 batch): Loss=0.2244; accuracy=0.9701\n",
      "Epoch 23 summary: train_loss: 0.0932 | train_acc: 0.9674 | val_loss: 3.1007 | val_acc: 0.4916\n",
      "Epoch 24\n",
      "Train Batch 100 (every 100 batch): Loss=0.0663; accuracy=0.9686\n",
      "Train Batch 200 (every 100 batch): Loss=0.0572; accuracy=0.9705\n",
      "Train Batch 300 (every 100 batch): Loss=0.0307; accuracy=0.9654\n",
      "Epoch 24 summary: train_loss: 0.1009 | train_acc: 0.9635 | val_loss: 3.2423 | val_acc: 0.4735\n",
      "Epoch 25\n",
      "Train Batch 100 (every 100 batch): Loss=0.1086; accuracy=0.9745\n",
      "Train Batch 200 (every 100 batch): Loss=0.0524; accuracy=0.9719\n",
      "Train Batch 300 (every 100 batch): Loss=0.0510; accuracy=0.9715\n",
      "Epoch 25 summary: train_loss: 0.0813 | train_acc: 0.9719 | val_loss: 3.3306 | val_acc: 0.4862\n",
      "Epoch 26\n",
      "Train Batch 100 (every 100 batch): Loss=0.0153; accuracy=0.9748\n",
      "Train Batch 200 (every 100 batch): Loss=0.0741; accuracy=0.9669\n",
      "Train Batch 300 (every 100 batch): Loss=0.1224; accuracy=0.9676\n",
      "Epoch 26 summary: train_loss: 0.0951 | train_acc: 0.9679 | val_loss: 3.3078 | val_acc: 0.4927\n",
      "Epoch 27\n",
      "Train Batch 100 (every 100 batch): Loss=0.0377; accuracy=0.9822\n",
      "Train Batch 200 (every 100 batch): Loss=0.1080; accuracy=0.9808\n",
      "Train Batch 300 (every 100 batch): Loss=0.1308; accuracy=0.9746\n",
      "Epoch 27 summary: train_loss: 0.0754 | train_acc: 0.9738 | val_loss: 3.0860 | val_acc: 0.4826\n",
      "Epoch 28\n",
      "Train Batch 100 (every 100 batch): Loss=0.0141; accuracy=0.9802\n",
      "Train Batch 200 (every 100 batch): Loss=0.0664; accuracy=0.9785\n",
      "Train Batch 300 (every 100 batch): Loss=0.1578; accuracy=0.9777\n",
      "Epoch 28 summary: train_loss: 0.0628 | train_acc: 0.9783 | val_loss: 3.6166 | val_acc: 0.4811\n",
      "Epoch 29\n",
      "Train Batch 100 (every 100 batch): Loss=0.1514; accuracy=0.9830\n",
      "Train Batch 200 (every 100 batch): Loss=0.0673; accuracy=0.9806\n",
      "Train Batch 300 (every 100 batch): Loss=0.0848; accuracy=0.9798\n",
      "Epoch 29 summary: train_loss: 0.0584 | train_acc: 0.9794 | val_loss: 3.6146 | val_acc: 0.4644\n",
      "Epoch 30\n",
      "Train Batch 100 (every 100 batch): Loss=0.1174; accuracy=0.9816\n",
      "Train Batch 200 (every 100 batch): Loss=0.1858; accuracy=0.9795\n",
      "Train Batch 300 (every 100 batch): Loss=0.0649; accuracy=0.9767\n",
      "Epoch 30 summary: train_loss: 0.0676 | train_acc: 0.9768 | val_loss: 3.6747 | val_acc: 0.4847\n",
      "Epoch 31\n",
      "Train Batch 100 (every 100 batch): Loss=0.0730; accuracy=0.9759\n",
      "Train Batch 200 (every 100 batch): Loss=0.0803; accuracy=0.9781\n",
      "Train Batch 300 (every 100 batch): Loss=0.0459; accuracy=0.9774\n",
      "Epoch 31 summary: train_loss: 0.0646 | train_acc: 0.9776 | val_loss: 3.6209 | val_acc: 0.4807\n",
      "Epoch 32\n",
      "Train Batch 100 (every 100 batch): Loss=0.0213; accuracy=0.9833\n",
      "Train Batch 200 (every 100 batch): Loss=0.1829; accuracy=0.9806\n",
      "Train Batch 300 (every 100 batch): Loss=0.0576; accuracy=0.9799\n",
      "Epoch 32 summary: train_loss: 0.0592 | train_acc: 0.9798 | val_loss: 3.8078 | val_acc: 0.4826\n",
      "Epoch 33\n",
      "Train Batch 100 (every 100 batch): Loss=0.0274; accuracy=0.9778\n",
      "Train Batch 200 (every 100 batch): Loss=0.1057; accuracy=0.9793\n",
      "Train Batch 300 (every 100 batch): Loss=0.0735; accuracy=0.9779\n",
      "Epoch 33 summary: train_loss: 0.0630 | train_acc: 0.9780 | val_loss: 3.6782 | val_acc: 0.4833\n",
      "Epoch 34\n",
      "Train Batch 100 (every 100 batch): Loss=0.0512; accuracy=0.9872\n",
      "Train Batch 200 (every 100 batch): Loss=0.1149; accuracy=0.9859\n",
      "Train Batch 300 (every 100 batch): Loss=0.0716; accuracy=0.9814\n",
      "Epoch 34 summary: train_loss: 0.0558 | train_acc: 0.9807 | val_loss: 3.6311 | val_acc: 0.4807\n",
      "Epoch 35\n",
      "Train Batch 100 (every 100 batch): Loss=0.0196; accuracy=0.9869\n",
      "Train Batch 200 (every 100 batch): Loss=0.0371; accuracy=0.9827\n",
      "Train Batch 300 (every 100 batch): Loss=0.2291; accuracy=0.9770\n",
      "Epoch 35 summary: train_loss: 0.0699 | train_acc: 0.9758 | val_loss: 3.5044 | val_acc: 0.4673\n",
      "Epoch 36\n",
      "Train Batch 100 (every 100 batch): Loss=0.0605; accuracy=0.9717\n",
      "Train Batch 200 (every 100 batch): Loss=0.1286; accuracy=0.9751\n",
      "Train Batch 300 (every 100 batch): Loss=0.0530; accuracy=0.9767\n",
      "Epoch 36 summary: train_loss: 0.0658 | train_acc: 0.9773 | val_loss: 3.6152 | val_acc: 0.4757\n",
      "Epoch 37\n",
      "Train Batch 100 (every 100 batch): Loss=0.0259; accuracy=0.9923\n",
      "Train Batch 200 (every 100 batch): Loss=0.0027; accuracy=0.9931\n",
      "Train Batch 300 (every 100 batch): Loss=0.0850; accuracy=0.9914\n",
      "Epoch 37 summary: train_loss: 0.0291 | train_acc: 0.9902 | val_loss: 3.9638 | val_acc: 0.4909\n",
      "Epoch 38\n",
      "Train Batch 100 (every 100 batch): Loss=0.0213; accuracy=0.9820\n",
      "Train Batch 200 (every 100 batch): Loss=0.0190; accuracy=0.9806\n",
      "Train Batch 300 (every 100 batch): Loss=0.1455; accuracy=0.9796\n",
      "Epoch 38 summary: train_loss: 0.0612 | train_acc: 0.9794 | val_loss: 3.6431 | val_acc: 0.4688\n",
      "Epoch 39\n",
      "Train Batch 100 (every 100 batch): Loss=0.0245; accuracy=0.9827\n",
      "Train Batch 200 (every 100 batch): Loss=0.0434; accuracy=0.9828\n",
      "Train Batch 300 (every 100 batch): Loss=0.3343; accuracy=0.9826\n",
      "Epoch 39 summary: train_loss: 0.0581 | train_acc: 0.9812 | val_loss: 3.6323 | val_acc: 0.4898\n",
      "Epoch 40\n",
      "Train Batch 100 (every 100 batch): Loss=0.0099; accuracy=0.9841\n",
      "Train Batch 200 (every 100 batch): Loss=0.0981; accuracy=0.9859\n",
      "Train Batch 300 (every 100 batch): Loss=0.0990; accuracy=0.9876\n",
      "Epoch 40 summary: train_loss: 0.0381 | train_acc: 0.9881 | val_loss: 4.0125 | val_acc: 0.4760\n",
      "Epoch 41\n",
      "Train Batch 100 (every 100 batch): Loss=0.0574; accuracy=0.9923\n",
      "Train Batch 200 (every 100 batch): Loss=0.0078; accuracy=0.9891\n",
      "Train Batch 300 (every 100 batch): Loss=0.0755; accuracy=0.9868\n",
      "Epoch 41 summary: train_loss: 0.0460 | train_acc: 0.9853 | val_loss: 3.9455 | val_acc: 0.4629\n",
      "Epoch 42\n",
      "Train Batch 100 (every 100 batch): Loss=0.0472; accuracy=0.9609\n",
      "Train Batch 200 (every 100 batch): Loss=0.0256; accuracy=0.9680\n",
      "Train Batch 300 (every 100 batch): Loss=0.0993; accuracy=0.9721\n",
      "Epoch 42 summary: train_loss: 0.0800 | train_acc: 0.9731 | val_loss: 3.4894 | val_acc: 0.4782\n",
      "Epoch 43\n",
      "Train Batch 100 (every 100 batch): Loss=0.0117; accuracy=0.9934\n",
      "Train Batch 200 (every 100 batch): Loss=0.0128; accuracy=0.9927\n",
      "Train Batch 300 (every 100 batch): Loss=0.0060; accuracy=0.9921\n",
      "Epoch 43 summary: train_loss: 0.0244 | train_acc: 0.9917 | val_loss: 4.2810 | val_acc: 0.4804\n",
      "Epoch 44\n",
      "Train Batch 100 (every 100 batch): Loss=0.0282; accuracy=0.9748\n",
      "Train Batch 200 (every 100 batch): Loss=0.0413; accuracy=0.9815\n",
      "Train Batch 300 (every 100 batch): Loss=0.0301; accuracy=0.9817\n",
      "Epoch 44 summary: train_loss: 0.0531 | train_acc: 0.9819 | val_loss: 4.0040 | val_acc: 0.4640\n",
      "Epoch 45\n",
      "Train Batch 100 (every 100 batch): Loss=0.0038; accuracy=0.9920\n",
      "Train Batch 200 (every 100 batch): Loss=0.0109; accuracy=0.9911\n",
      "Train Batch 300 (every 100 batch): Loss=0.1164; accuracy=0.9894\n",
      "Epoch 45 summary: train_loss: 0.0355 | train_acc: 0.9881 | val_loss: 4.0849 | val_acc: 0.4855\n",
      "Epoch 46\n",
      "Train Batch 100 (every 100 batch): Loss=0.0570; accuracy=0.9861\n",
      "Train Batch 200 (every 100 batch): Loss=0.0164; accuracy=0.9860\n",
      "Train Batch 300 (every 100 batch): Loss=0.0382; accuracy=0.9851\n",
      "Epoch 46 summary: train_loss: 0.0449 | train_acc: 0.9848 | val_loss: 3.6811 | val_acc: 0.4717\n",
      "Epoch 47\n",
      "Train Batch 100 (every 100 batch): Loss=0.0534; accuracy=0.9830\n",
      "Train Batch 200 (every 100 batch): Loss=0.0571; accuracy=0.9836\n",
      "Train Batch 300 (every 100 batch): Loss=0.0083; accuracy=0.9844\n",
      "Epoch 47 summary: train_loss: 0.0428 | train_acc: 0.9847 | val_loss: 3.9991 | val_acc: 0.4688\n",
      "Epoch 48\n",
      "Train Batch 100 (every 100 batch): Loss=0.0376; accuracy=0.9933\n",
      "Train Batch 200 (every 100 batch): Loss=0.0247; accuracy=0.9911\n",
      "Train Batch 300 (every 100 batch): Loss=0.0642; accuracy=0.9908\n",
      "Epoch 48 summary: train_loss: 0.0281 | train_acc: 0.9906 | val_loss: 4.2917 | val_acc: 0.4717\n",
      "Epoch 49\n",
      "Train Batch 100 (every 100 batch): Loss=0.0011; accuracy=0.9933\n",
      "Train Batch 200 (every 100 batch): Loss=0.0118; accuracy=0.9894\n",
      "Train Batch 300 (every 100 batch): Loss=0.0050; accuracy=0.9877\n",
      "Epoch 49 summary: train_loss: 0.0419 | train_acc: 0.9860 | val_loss: 4.1558 | val_acc: 0.4546\n",
      "Epoch 50\n",
      "Train Batch 100 (every 100 batch): Loss=0.0731; accuracy=0.9803\n",
      "Train Batch 200 (every 100 batch): Loss=0.0194; accuracy=0.9841\n",
      "Train Batch 300 (every 100 batch): Loss=0.0482; accuracy=0.9843\n",
      "Epoch 50 summary: train_loss: 0.0482 | train_acc: 0.9840 | val_loss: 3.6836 | val_acc: 0.4866\n",
      "Epoch 51\n",
      "Train Batch 100 (every 100 batch): Loss=0.0160; accuracy=0.9920\n",
      "Train Batch 200 (every 100 batch): Loss=0.0263; accuracy=0.9902\n",
      "Train Batch 300 (every 100 batch): Loss=0.1199; accuracy=0.9858\n",
      "Epoch 51 summary: train_loss: 0.0454 | train_acc: 0.9850 | val_loss: 3.7558 | val_acc: 0.4640\n",
      "Epoch 52\n",
      "Train Batch 100 (every 100 batch): Loss=0.0664; accuracy=0.9900\n",
      "Train Batch 200 (every 100 batch): Loss=0.0165; accuracy=0.9902\n",
      "Train Batch 300 (every 100 batch): Loss=0.0418; accuracy=0.9897\n",
      "Epoch 52 summary: train_loss: 0.0326 | train_acc: 0.9893 | val_loss: 3.9196 | val_acc: 0.4706\n",
      "Epoch 53\n",
      "Train Batch 100 (every 100 batch): Loss=0.0070; accuracy=0.9920\n",
      "Train Batch 200 (every 100 batch): Loss=0.0627; accuracy=0.9907\n",
      "Train Batch 300 (every 100 batch): Loss=0.0485; accuracy=0.9881\n",
      "Epoch 53 summary: train_loss: 0.0367 | train_acc: 0.9879 | val_loss: 3.9900 | val_acc: 0.4844\n",
      "Epoch 54\n",
      "Train Batch 100 (every 100 batch): Loss=0.0113; accuracy=0.9902\n",
      "Train Batch 200 (every 100 batch): Loss=0.0963; accuracy=0.9889\n",
      "Train Batch 300 (every 100 batch): Loss=0.0172; accuracy=0.9875\n",
      "Epoch 54 summary: train_loss: 0.0372 | train_acc: 0.9875 | val_loss: 4.0464 | val_acc: 0.4695\n",
      "Epoch 55\n",
      "Train Batch 100 (every 100 batch): Loss=0.0405; accuracy=0.9875\n",
      "Train Batch 200 (every 100 batch): Loss=0.0069; accuracy=0.9861\n",
      "Train Batch 300 (every 100 batch): Loss=0.0645; accuracy=0.9853\n",
      "Epoch 55 summary: train_loss: 0.0445 | train_acc: 0.9850 | val_loss: 3.9435 | val_acc: 0.4724\n",
      "Epoch 56\n",
      "Train Batch 100 (every 100 batch): Loss=0.0110; accuracy=0.9892\n",
      "Train Batch 200 (every 100 batch): Loss=0.0177; accuracy=0.9909\n",
      "Train Batch 300 (every 100 batch): Loss=0.0242; accuracy=0.9913\n",
      "Epoch 56 summary: train_loss: 0.0256 | train_acc: 0.9912 | val_loss: 4.2337 | val_acc: 0.4680\n",
      "Epoch 57\n",
      "Train Batch 100 (every 100 batch): Loss=0.0328; accuracy=0.9961\n",
      "Train Batch 200 (every 100 batch): Loss=0.0205; accuracy=0.9959\n",
      "Train Batch 300 (every 100 batch): Loss=0.0226; accuracy=0.9919\n",
      "Epoch 57 summary: train_loss: 0.0305 | train_acc: 0.9902 | val_loss: 4.0220 | val_acc: 0.4742\n",
      "Epoch 58\n",
      "Train Batch 100 (every 100 batch): Loss=0.0108; accuracy=0.9827\n",
      "Train Batch 200 (every 100 batch): Loss=0.0110; accuracy=0.9856\n",
      "Train Batch 300 (every 100 batch): Loss=0.0514; accuracy=0.9870\n",
      "Epoch 58 summary: train_loss: 0.0410 | train_acc: 0.9868 | val_loss: 3.9866 | val_acc: 0.4560\n",
      "Epoch 59\n",
      "Train Batch 100 (every 100 batch): Loss=0.0102; accuracy=0.9902\n",
      "Train Batch 200 (every 100 batch): Loss=0.0169; accuracy=0.9904\n",
      "Train Batch 300 (every 100 batch): Loss=0.0557; accuracy=0.9911\n",
      "Epoch 59 summary: train_loss: 0.0292 | train_acc: 0.9908 | val_loss: 4.3002 | val_acc: 0.4735\n",
      "Epoch 60\n",
      "Train Batch 100 (every 100 batch): Loss=0.0684; accuracy=0.9894\n",
      "Train Batch 200 (every 100 batch): Loss=0.0180; accuracy=0.9884\n",
      "Train Batch 300 (every 100 batch): Loss=0.0194; accuracy=0.9851\n",
      "Epoch 60 summary: train_loss: 0.0428 | train_acc: 0.9851 | val_loss: 4.0293 | val_acc: 0.4673\n",
      "Epoch 61\n",
      "Train Batch 100 (every 100 batch): Loss=0.0178; accuracy=0.9920\n",
      "Train Batch 200 (every 100 batch): Loss=0.0712; accuracy=0.9922\n",
      "Train Batch 300 (every 100 batch): Loss=0.0303; accuracy=0.9911\n",
      "Epoch 61 summary: train_loss: 0.0290 | train_acc: 0.9900 | val_loss: 4.1946 | val_acc: 0.4644\n",
      "Epoch 62\n",
      "Train Batch 100 (every 100 batch): Loss=0.0062; accuracy=0.9875\n",
      "Train Batch 200 (every 100 batch): Loss=0.0049; accuracy=0.9883\n",
      "Train Batch 300 (every 100 batch): Loss=0.0170; accuracy=0.9881\n",
      "Epoch 62 summary: train_loss: 0.0347 | train_acc: 0.9881 | val_loss: 4.2165 | val_acc: 0.4629\n",
      "Epoch 63\n",
      "Train Batch 100 (every 100 batch): Loss=0.0653; accuracy=0.9914\n",
      "Train Batch 200 (every 100 batch): Loss=0.0281; accuracy=0.9923\n",
      "Train Batch 300 (every 100 batch): Loss=0.0089; accuracy=0.9908\n",
      "Epoch 63 summary: train_loss: 0.0287 | train_acc: 0.9904 | val_loss: 4.1564 | val_acc: 0.4669\n",
      "Epoch 64\n",
      "Train Batch 100 (every 100 batch): Loss=0.0090; accuracy=0.9945\n",
      "Train Batch 200 (every 100 batch): Loss=0.0861; accuracy=0.9936\n",
      "Train Batch 300 (every 100 batch): Loss=0.0351; accuracy=0.9928\n",
      "Epoch 64 summary: train_loss: 0.0218 | train_acc: 0.9926 | val_loss: 4.3858 | val_acc: 0.4677\n",
      "Epoch 65\n",
      "Train Batch 100 (every 100 batch): Loss=0.0020; accuracy=0.9927\n",
      "Train Batch 200 (every 100 batch): Loss=0.0240; accuracy=0.9933\n",
      "Train Batch 300 (every 100 batch): Loss=0.0723; accuracy=0.9929\n",
      "Epoch 65 summary: train_loss: 0.0240 | train_acc: 0.9928 | val_loss: 4.4368 | val_acc: 0.4764\n",
      "Epoch 66\n",
      "Train Batch 100 (every 100 batch): Loss=0.0863; accuracy=0.9912\n",
      "Train Batch 200 (every 100 batch): Loss=0.0526; accuracy=0.9877\n",
      "Train Batch 300 (every 100 batch): Loss=0.0282; accuracy=0.9851\n",
      "Epoch 66 summary: train_loss: 0.0426 | train_acc: 0.9847 | val_loss: 4.1976 | val_acc: 0.4644\n",
      "Epoch 67\n",
      "Train Batch 100 (every 100 batch): Loss=0.0041; accuracy=0.9866\n",
      "Train Batch 200 (every 100 batch): Loss=0.0057; accuracy=0.9898\n",
      "Train Batch 300 (every 100 batch): Loss=0.0093; accuracy=0.9891\n",
      "Epoch 67 summary: train_loss: 0.0356 | train_acc: 0.9885 | val_loss: 4.4149 | val_acc: 0.4662\n",
      "Epoch 68\n",
      "Train Batch 100 (every 100 batch): Loss=0.0066; accuracy=0.9917\n",
      "Train Batch 200 (every 100 batch): Loss=0.0012; accuracy=0.9919\n",
      "Train Batch 300 (every 100 batch): Loss=0.0037; accuracy=0.9908\n",
      "Epoch 68 summary: train_loss: 0.0305 | train_acc: 0.9902 | val_loss: 4.2097 | val_acc: 0.4622\n",
      "Epoch 69\n",
      "Train Batch 100 (every 100 batch): Loss=0.0411; accuracy=0.9944\n",
      "Train Batch 200 (every 100 batch): Loss=0.0074; accuracy=0.9927\n",
      "Train Batch 300 (every 100 batch): Loss=0.0055; accuracy=0.9913\n",
      "Epoch 69 summary: train_loss: 0.0295 | train_acc: 0.9899 | val_loss: 4.0297 | val_acc: 0.4626\n",
      "Epoch 70\n",
      "Train Batch 100 (every 100 batch): Loss=0.1060; accuracy=0.9866\n",
      "Train Batch 200 (every 100 batch): Loss=0.0421; accuracy=0.9873\n",
      "Train Batch 300 (every 100 batch): Loss=0.0573; accuracy=0.9881\n",
      "Epoch 70 summary: train_loss: 0.0336 | train_acc: 0.9884 | val_loss: 4.0587 | val_acc: 0.4887\n",
      "Epoch 71\n",
      "Train Batch 100 (every 100 batch): Loss=0.0056; accuracy=0.9934\n",
      "Train Batch 200 (every 100 batch): Loss=0.0043; accuracy=0.9941\n",
      "Train Batch 300 (every 100 batch): Loss=0.0242; accuracy=0.9936\n",
      "Epoch 71 summary: train_loss: 0.0213 | train_acc: 0.9929 | val_loss: 4.5504 | val_acc: 0.4706\n",
      "Epoch 72\n",
      "Train Batch 100 (every 100 batch): Loss=0.0058; accuracy=0.9958\n",
      "Train Batch 200 (every 100 batch): Loss=0.0898; accuracy=0.9933\n",
      "Train Batch 300 (every 100 batch): Loss=0.0401; accuracy=0.9912\n",
      "Epoch 72 summary: train_loss: 0.0264 | train_acc: 0.9910 | val_loss: 4.1838 | val_acc: 0.4938\n",
      "Epoch 73\n",
      "Train Batch 100 (every 100 batch): Loss=0.0782; accuracy=0.9894\n",
      "Train Batch 200 (every 100 batch): Loss=0.0045; accuracy=0.9872\n",
      "Train Batch 300 (every 100 batch): Loss=0.0088; accuracy=0.9884\n",
      "Epoch 73 summary: train_loss: 0.0322 | train_acc: 0.9887 | val_loss: 4.5339 | val_acc: 0.4688\n",
      "Epoch 74\n",
      "Train Batch 100 (every 100 batch): Loss=0.0623; accuracy=0.9950\n",
      "Train Batch 200 (every 100 batch): Loss=0.0335; accuracy=0.9933\n",
      "Train Batch 300 (every 100 batch): Loss=0.1403; accuracy=0.9922\n",
      "Epoch 74 summary: train_loss: 0.0244 | train_acc: 0.9920 | val_loss: 4.4221 | val_acc: 0.4637\n",
      "Epoch 75\n",
      "Train Batch 100 (every 100 batch): Loss=0.0080; accuracy=0.9945\n",
      "Train Batch 200 (every 100 batch): Loss=0.0559; accuracy=0.9927\n",
      "Train Batch 300 (every 100 batch): Loss=0.0419; accuracy=0.9895\n",
      "Epoch 75 summary: train_loss: 0.0338 | train_acc: 0.9887 | val_loss: 4.0394 | val_acc: 0.4749\n",
      "Epoch 76\n",
      "Train Batch 100 (every 100 batch): Loss=0.0636; accuracy=0.9902\n",
      "Train Batch 200 (every 100 batch): Loss=0.0520; accuracy=0.9898\n",
      "Train Batch 300 (every 100 batch): Loss=0.0127; accuracy=0.9900\n",
      "Epoch 76 summary: train_loss: 0.0293 | train_acc: 0.9900 | val_loss: 4.1005 | val_acc: 0.4793\n",
      "Epoch 77\n",
      "Train Batch 100 (every 100 batch): Loss=0.0079; accuracy=0.9967\n",
      "Train Batch 200 (every 100 batch): Loss=0.0091; accuracy=0.9966\n",
      "Train Batch 300 (every 100 batch): Loss=0.0187; accuracy=0.9950\n",
      "Epoch 77 summary: train_loss: 0.0171 | train_acc: 0.9945 | val_loss: 4.5137 | val_acc: 0.4698\n",
      "Epoch 78\n",
      "Train Batch 100 (every 100 batch): Loss=0.0108; accuracy=0.9937\n",
      "Train Batch 200 (every 100 batch): Loss=0.0155; accuracy=0.9911\n",
      "Train Batch 300 (every 100 batch): Loss=0.0568; accuracy=0.9883\n",
      "Epoch 78 summary: train_loss: 0.0359 | train_acc: 0.9883 | val_loss: 4.3070 | val_acc: 0.4775\n",
      "Epoch 79\n",
      "Train Batch 100 (every 100 batch): Loss=0.0444; accuracy=0.9920\n",
      "Train Batch 200 (every 100 batch): Loss=0.0357; accuracy=0.9916\n",
      "Train Batch 300 (every 100 batch): Loss=0.0886; accuracy=0.9921\n",
      "Epoch 79 summary: train_loss: 0.0222 | train_acc: 0.9924 | val_loss: 4.3629 | val_acc: 0.4811\n",
      "Epoch 80\n",
      "Train Batch 100 (every 100 batch): Loss=0.0063; accuracy=0.9967\n",
      "Train Batch 200 (every 100 batch): Loss=0.0286; accuracy=0.9959\n",
      "Train Batch 300 (every 100 batch): Loss=0.0014; accuracy=0.9935\n",
      "Epoch 80 summary: train_loss: 0.0205 | train_acc: 0.9926 | val_loss: 4.6879 | val_acc: 0.4644\n",
      "Epoch 81\n",
      "Train Batch 100 (every 100 batch): Loss=0.0261; accuracy=0.9877\n",
      "Train Batch 200 (every 100 batch): Loss=0.0336; accuracy=0.9857\n",
      "Train Batch 300 (every 100 batch): Loss=0.0627; accuracy=0.9859\n",
      "Epoch 81 summary: train_loss: 0.0426 | train_acc: 0.9856 | val_loss: 4.0890 | val_acc: 0.4920\n",
      "Epoch 82\n",
      "Train Batch 100 (every 100 batch): Loss=0.0312; accuracy=0.9900\n",
      "Train Batch 200 (every 100 batch): Loss=0.0346; accuracy=0.9898\n",
      "Train Batch 300 (every 100 batch): Loss=0.0295; accuracy=0.9903\n",
      "Epoch 82 summary: train_loss: 0.0286 | train_acc: 0.9903 | val_loss: 4.1812 | val_acc: 0.4891\n",
      "Epoch 83\n",
      "Train Batch 100 (every 100 batch): Loss=0.0035; accuracy=0.9952\n",
      "Train Batch 200 (every 100 batch): Loss=0.0008; accuracy=0.9966\n",
      "Train Batch 300 (every 100 batch): Loss=0.0231; accuracy=0.9959\n",
      "Epoch 83 summary: train_loss: 0.0136 | train_acc: 0.9955 | val_loss: 4.5683 | val_acc: 0.4967\n",
      "Epoch 84\n",
      "Train Batch 100 (every 100 batch): Loss=0.0058; accuracy=0.9972\n",
      "Train Batch 200 (every 100 batch): Loss=0.0052; accuracy=0.9945\n",
      "Train Batch 300 (every 100 batch): Loss=0.0295; accuracy=0.9931\n",
      "Epoch 84 summary: train_loss: 0.0245 | train_acc: 0.9926 | val_loss: 4.3873 | val_acc: 0.4760\n",
      "Epoch 85\n",
      "Train Batch 100 (every 100 batch): Loss=0.0012; accuracy=0.9934\n",
      "Train Batch 200 (every 100 batch): Loss=0.0168; accuracy=0.9928\n",
      "Train Batch 300 (every 100 batch): Loss=0.0202; accuracy=0.9930\n",
      "Epoch 85 summary: train_loss: 0.0217 | train_acc: 0.9929 | val_loss: 4.7866 | val_acc: 0.4778\n",
      "Epoch 86\n",
      "Train Batch 100 (every 100 batch): Loss=0.0371; accuracy=0.9933\n",
      "Train Batch 200 (every 100 batch): Loss=0.0176; accuracy=0.9935\n",
      "Train Batch 300 (every 100 batch): Loss=0.0058; accuracy=0.9926\n",
      "Epoch 86 summary: train_loss: 0.0267 | train_acc: 0.9916 | val_loss: 4.2420 | val_acc: 0.4738\n",
      "Epoch 87\n",
      "Train Batch 100 (every 100 batch): Loss=0.0550; accuracy=0.9845\n",
      "Train Batch 200 (every 100 batch): Loss=0.0317; accuracy=0.9858\n",
      "Train Batch 300 (every 100 batch): Loss=0.0013; accuracy=0.9863\n",
      "Epoch 87 summary: train_loss: 0.0375 | train_acc: 0.9870 | val_loss: 4.3165 | val_acc: 0.4815\n",
      "Epoch 88\n",
      "Train Batch 100 (every 100 batch): Loss=0.1050; accuracy=0.9955\n",
      "Train Batch 200 (every 100 batch): Loss=0.0016; accuracy=0.9953\n",
      "Train Batch 300 (every 100 batch): Loss=0.0078; accuracy=0.9950\n",
      "Epoch 88 summary: train_loss: 0.0162 | train_acc: 0.9949 | val_loss: 4.8071 | val_acc: 0.4778\n",
      "Epoch 89\n",
      "Train Batch 100 (every 100 batch): Loss=0.0022; accuracy=0.9953\n",
      "Train Batch 200 (every 100 batch): Loss=0.0429; accuracy=0.9940\n",
      "Train Batch 300 (every 100 batch): Loss=0.0072; accuracy=0.9918\n",
      "Epoch 89 summary: train_loss: 0.0283 | train_acc: 0.9904 | val_loss: 4.5429 | val_acc: 0.4608\n",
      "Epoch 90\n",
      "Train Batch 100 (every 100 batch): Loss=0.0072; accuracy=0.9884\n",
      "Train Batch 200 (every 100 batch): Loss=0.0052; accuracy=0.9897\n",
      "Train Batch 300 (every 100 batch): Loss=0.0123; accuracy=0.9900\n",
      "Epoch 90 summary: train_loss: 0.0319 | train_acc: 0.9895 | val_loss: 4.3496 | val_acc: 0.4604\n",
      "Epoch 91\n",
      "Train Batch 100 (every 100 batch): Loss=0.0367; accuracy=0.9855\n",
      "Train Batch 200 (every 100 batch): Loss=0.0337; accuracy=0.9877\n",
      "Train Batch 300 (every 100 batch): Loss=0.0030; accuracy=0.9899\n",
      "Epoch 91 summary: train_loss: 0.0300 | train_acc: 0.9903 | val_loss: 4.5252 | val_acc: 0.4684\n",
      "Epoch 92\n",
      "Train Batch 100 (every 100 batch): Loss=0.0028; accuracy=0.9986\n",
      "Train Batch 200 (every 100 batch): Loss=0.0179; accuracy=0.9975\n",
      "Train Batch 300 (every 100 batch): Loss=0.0683; accuracy=0.9964\n",
      "Epoch 92 summary: train_loss: 0.0120 | train_acc: 0.9959 | val_loss: 4.7582 | val_acc: 0.4833\n",
      "Epoch 93\n",
      "Train Batch 100 (every 100 batch): Loss=0.0146; accuracy=0.9917\n",
      "Train Batch 200 (every 100 batch): Loss=0.0070; accuracy=0.9917\n",
      "Train Batch 300 (every 100 batch): Loss=0.0159; accuracy=0.9914\n",
      "Epoch 93 summary: train_loss: 0.0261 | train_acc: 0.9913 | val_loss: 4.4395 | val_acc: 0.4720\n",
      "Epoch 94\n",
      "Train Batch 100 (every 100 batch): Loss=0.0043; accuracy=0.9908\n",
      "Train Batch 200 (every 100 batch): Loss=0.0581; accuracy=0.9905\n",
      "Train Batch 300 (every 100 batch): Loss=0.0170; accuracy=0.9903\n",
      "Epoch 94 summary: train_loss: 0.0286 | train_acc: 0.9905 | val_loss: 4.5001 | val_acc: 0.4775\n",
      "Epoch 95\n",
      "Train Batch 100 (every 100 batch): Loss=0.0285; accuracy=0.9948\n",
      "Train Batch 200 (every 100 batch): Loss=0.0067; accuracy=0.9949\n",
      "Train Batch 300 (every 100 batch): Loss=0.0232; accuracy=0.9937\n",
      "Epoch 95 summary: train_loss: 0.0224 | train_acc: 0.9933 | val_loss: 4.3547 | val_acc: 0.4836\n",
      "Epoch 96\n",
      "Train Batch 100 (every 100 batch): Loss=0.0045; accuracy=0.9959\n",
      "Train Batch 200 (every 100 batch): Loss=0.0465; accuracy=0.9949\n",
      "Train Batch 300 (every 100 batch): Loss=0.0100; accuracy=0.9935\n",
      "Epoch 96 summary: train_loss: 0.0203 | train_acc: 0.9931 | val_loss: 4.2959 | val_acc: 0.4753\n",
      "Epoch 97\n",
      "Train Batch 100 (every 100 batch): Loss=0.0332; accuracy=0.9947\n",
      "Train Batch 200 (every 100 batch): Loss=0.0087; accuracy=0.9940\n",
      "Train Batch 300 (every 100 batch): Loss=0.0046; accuracy=0.9933\n",
      "Epoch 97 summary: train_loss: 0.0225 | train_acc: 0.9931 | val_loss: 4.3437 | val_acc: 0.4858\n",
      "Epoch 98\n",
      "Train Batch 100 (every 100 batch): Loss=0.0039; accuracy=0.9975\n",
      "Train Batch 200 (every 100 batch): Loss=0.0602; accuracy=0.9935\n",
      "Train Batch 300 (every 100 batch): Loss=0.0151; accuracy=0.9906\n",
      "Epoch 98 summary: train_loss: 0.0294 | train_acc: 0.9901 | val_loss: 4.1723 | val_acc: 0.4688\n",
      "Epoch 99\n",
      "Train Batch 100 (every 100 batch): Loss=0.0262; accuracy=0.9906\n",
      "Train Batch 200 (every 100 batch): Loss=0.0016; accuracy=0.9923\n",
      "Train Batch 300 (every 100 batch): Loss=0.0234; accuracy=0.9915\n",
      "Epoch 99 summary: train_loss: 0.0264 | train_acc: 0.9915 | val_loss: 4.2835 | val_acc: 0.4851\n",
      "Epoch 100\n",
      "Train Batch 100 (every 100 batch): Loss=0.0005; accuracy=0.9962\n",
      "Train Batch 200 (every 100 batch): Loss=0.0150; accuracy=0.9971\n",
      "Train Batch 300 (every 100 batch): Loss=0.0219; accuracy=0.9966\n",
      "Epoch 100 summary: train_loss: 0.0126 | train_acc: 0.9963 | val_loss: 4.6664 | val_acc: 0.4782\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m non_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mkind\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom-scratch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     loss_history, accuracy_val, accuracy_test \u001b[38;5;241m=\u001b[39m net_trainer(\n\u001b[1;32m      5\u001b[0m             net,\n\u001b[1;32m      6\u001b[0m             loaders,\n\u001b[1;32m      7\u001b[0m             opt,\n\u001b[1;32m      8\u001b[0m             channel_idx,\n\u001b[1;32m      9\u001b[0m             nonclasses,\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m             model_path)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "channel_idx=None\n",
    "non_classes=None\n",
    "if opt.kind==\"from-scratch\":\n",
    "    loss_history, accuracy_val, accuracy_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0199dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val =accuracy_val\n",
    "# test = accuracy_test\n",
    "\n",
    "# print(\"Validation accuracy: \", val)\n",
    "# print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f370e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a7d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2334ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b77fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080e706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17823cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b650c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb911b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b43930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28237288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ded073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcbdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fb11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b75470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8939417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5c258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597563e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d74a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db30ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1544e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
