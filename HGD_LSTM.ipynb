{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7f6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c192d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf1a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n",
      "<torch.cuda.device object at 0x7f6c0f874a60>\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff733115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 250\n",
    "channel = 128\n",
    "min_CNN = 200\n",
    "n_classes = 4\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b68db2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if platform == \"linux\" or platform == \"linux2\":\n",
    "#     torch_models_dir = r\"/media/titan/AI Research1/Data/CVPR2017\"\n",
    "# elif platform == \"win32\":\n",
    "#     torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "# block_splits_all, block_splits_single, eeg_14_70, eeg_55_95, eeg_5_95, eeg_raw = os.listdir(torch_models_dir)\n",
    "# print(os.listdir(torch_models_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bc401c6-e7e3-4163-9a3e-fa0aea23551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_dataset = '/media/mountHDD1/LanxHuyen/high_gamma_dataset.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd3ad4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eeg_dataset = os.path.join(torch_models_dir, eeg_5_95)\n",
    "# splits_all_path = os.path.join(torch_models_dir, block_splits_all)\n",
    "# splits_single_path = os.path.join(torch_models_dir, block_splits_single)\n",
    "# # splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "# print(eeg_dataset,'\\n', splits_all_path, '\\n', splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659d4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits_all = torch.load(splits_all_path)\n",
    "# splits_single = torch.load(splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f3ef344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(splits_all['splits']))\n",
    "# print(len(splits_all['splits'][0]))\n",
    "\n",
    "# print(len(splits_all['splits'][5]['train']))\n",
    "# print(len(splits_all['splits'][5]['val']))\n",
    "# print(len(splits_all['splits'][5]['test']))\n",
    "# print(splits_all['splits'][0]['train'][:40])\n",
    "# print(splits_all['splits'][1]['train'][:40])\n",
    "# print(splits_all['splits'][2]['train'][:10])\n",
    "# print(splits_all['splits'][3]['train'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27b3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(splits_single)\n",
    "# print(len(splits_single['splits'][0]['train']))\n",
    "# print(len(splits_single['splits'][0]['val']))\n",
    "# print(len(splits_single['splits'][0]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed58c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_loaded = torch.load(eeg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a637c6f-a7c4-4689-9036-0b1f0089ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(eeg_loaded)))\n",
    "random.shuffle(list(range(len(eeg_loaded))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "682d14b3-76a3-456e-99eb-bf75d423c19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(eeg_loaded))\n",
    "val_size = int(0.1 * len(eeg_loaded))\n",
    "test_size = len(eeg_loaded) - (train_size + val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6cd3e5f-d47b-4cb4-ad42-1f46608eb077",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size+val_size]\n",
    "test_indices = indices[train_size+val_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f3026ea-0a7a-4031-9a3d-e3e3540254f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_splits = {\"train\": train_indices, \"val\": val_indices, \"test\": test_indices}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89460bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26968\n",
      "26968\n"
     ]
    }
   ],
   "source": [
    "print(len(eeg_loaded))\n",
    "# print(eeg_loaded.keys())\n",
    "eeg = [eeg_loaded[i][\"eeg\"] for i in range (len(eeg_loaded))]\n",
    "print(len(eeg))\n",
    "# for dataset_idx in range (len(eeg_loaded)): \n",
    "#     eeg, label = [eeg_loaded[dataset_idx][key] for key in ['eeg', 'label']]\n",
    "# print((label))\n",
    "# print(len(eeg))\n",
    "# # print(len(dataset))\n",
    "\n",
    "# # print(labels)\n",
    "# # print(images[0])\n",
    "# print(eeg['eeg'][0].shape)\n",
    "# print(eeg[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d20c958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "#     \"iv\": \"image\",\n",
    "#     \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    #\"subject\": 0,\n",
    "    \"time_low\": 20,\n",
    "    \"time_high\": 270,\n",
    "#     \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"model_type\": \"model10\",\n",
    "    #\"splits_path\": splits_all_path,\n",
    "    #\"split_num\": 0,\n",
    "    \"split_name\": \"train\",\n",
    "#     \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 64,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"from-scratch\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.time_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce8d6e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "# from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from data_loader_HGD import EEGDataset, Splitter\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a5b475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "#              offset,\n",
    "             eeg_dataset,\n",
    "             #splits_path,\n",
    "             #split_num, # (0-5) - 6 fold cross validation\n",
    "             split_name,\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             kind=\"from-scratch\"):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(opt, eeg_dataset)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "#     # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "#     if kind==\"from-scratch\":\n",
    "#         relabel = False\n",
    "#     if kind==\"incremental\":\n",
    "#         relabel = False\n",
    "#     if kind==\"no-model-file\":\n",
    "#         relabel = True\n",
    "    splitter = {split: Splitter(dataset,\n",
    "                    #splits_path,\n",
    "                    #split_num,\n",
    "                    split_name = split) \n",
    "                for split in [\"train\", \"val\", \"test\"]\n",
    "                                }\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a242cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "opt.classifier = \"LSTM4\"\n",
    "opt.batch_size = 64\n",
    "# opt.kind = \"from-scratch\"\n",
    "# opt.run = \"imagenet40-1000\"\n",
    "# opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633488a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(\n",
    "#              offset,\n",
    "             opt.eeg_dataset,\n",
    "             #opt.splits_path,\n",
    "             #opt.split_num, # (0-5) - 6 fold cross validation\n",
    "             opt.split_name,\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             opt.batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e99fc973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader_HGD.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [338, 43, 43]\n",
      "1: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "2: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "3: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "4: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "5: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "6: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "7: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "8: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "9: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "10: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "11: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "12: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "13: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "14: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "15: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "16: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "17: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "18: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "19: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n",
      "20: Target size: torch.Size([64]); input size: torch.Size([64, 128, 250])\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 8000 idx, val: 2000 idx, test: 2000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250 idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i, (input, target) in enumerate(loaders[\"train\"]):\n",
    "    if i<20:\n",
    "        print(f\"{i+1}: Target size: {target.size()}; input size: {input.size()}\")\n",
    "# for i in range(0, 40):\n",
    "#     eeg, label_val = splitter[\"val\"][i]\n",
    "#     eeg, label_train = splitter[\"train\"][i]\n",
    "#     print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39a07cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_LSTM(\n",
      "  (lstm): LSTM(128, 128, batch_first=True)\n",
      "  (output1): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output2): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_LSTM                          [1, 4]                    --\n",
       "├─LSTM: 1-1                              [1, 250, 128]             132,096\n",
       "├─Linear: 1-2                            [1, 128]                  16,512\n",
       "├─ReLU: 1-3                              [1, 128]                  --\n",
       "├─Linear: 1-4                            [1, 4]                    516\n",
       "==========================================================================================\n",
       "Total params: 149,124\n",
       "Trainable params: 149,124\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 33.04\n",
       "==========================================================================================\n",
       "Input size (MB): 0.13\n",
       "Forward/backward pass size (MB): 0.26\n",
       "Params size (MB): 0.60\n",
       "Estimated Total Size (MB): 0.98\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1,128, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a8d6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM4 -HGD\n"
     ]
    }
   ],
   "source": [
    "model_path = (   opt.classifier+\n",
    "                  \" -\" + \"HGD\" )\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b753db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(results_file='results.pkl', time_low=20, time_high=270, eeg_dataset='/media/mountHDD1/LanxHuyen/high_gamma_dataset.pth', model_type='model10', split_name='train', batch_size=64, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='LSTM4')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5334cb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Batch 100 (every 100 batch): Loss=1.2298; accuracy=0.3948\n",
      "Train Batch 200 (every 100 batch): Loss=1.2076; accuracy=0.4248\n",
      "Train Batch 300 (every 100 batch): Loss=1.0434; accuracy=0.4429\n",
      "Epoch 1 summary: train_loss: 1.2020 | train_acc: 0.4476 | val_loss: 1.3066 | val_acc: 0.3921\n",
      "Epoch 2\n",
      "Train Batch 100 (every 100 batch): Loss=1.0772; accuracy=0.4881\n",
      "Train Batch 200 (every 100 batch): Loss=1.1073; accuracy=0.4987\n",
      "Train Batch 300 (every 100 batch): Loss=1.3118; accuracy=0.5039\n",
      "Epoch 2 summary: train_loss: 1.1141 | train_acc: 0.5084 | val_loss: 1.2255 | val_acc: 0.4560\n",
      "Epoch 3\n",
      "Train Batch 100 (every 100 batch): Loss=1.2000; accuracy=0.5528\n",
      "Train Batch 200 (every 100 batch): Loss=0.9269; accuracy=0.5454\n",
      "Train Batch 300 (every 100 batch): Loss=1.1750; accuracy=0.5469\n",
      "Epoch 3 summary: train_loss: 1.0658 | train_acc: 0.5461 | val_loss: 1.2254 | val_acc: 0.4509\n",
      "Epoch 4\n",
      "Train Batch 100 (every 100 batch): Loss=1.0318; accuracy=0.5455\n",
      "Train Batch 200 (every 100 batch): Loss=1.0063; accuracy=0.5505\n",
      "Train Batch 300 (every 100 batch): Loss=1.1233; accuracy=0.5540\n",
      "Epoch 4 summary: train_loss: 1.0380 | train_acc: 0.5552 | val_loss: 1.2057 | val_acc: 0.4618\n",
      "Epoch 5\n",
      "Train Batch 100 (every 100 batch): Loss=0.8162; accuracy=0.5836\n",
      "Train Batch 200 (every 100 batch): Loss=0.7777; accuracy=0.5880\n",
      "Train Batch 300 (every 100 batch): Loss=0.9073; accuracy=0.5837\n",
      "Epoch 5 summary: train_loss: 0.9943 | train_acc: 0.5834 | val_loss: 1.2735 | val_acc: 0.4586\n",
      "Epoch 6\n",
      "Train Batch 100 (every 100 batch): Loss=0.9874; accuracy=0.5969\n",
      "Train Batch 200 (every 100 batch): Loss=0.9655; accuracy=0.6045\n",
      "Train Batch 300 (every 100 batch): Loss=0.9108; accuracy=0.6053\n",
      "Epoch 6 summary: train_loss: 0.9475 | train_acc: 0.6046 | val_loss: 1.1928 | val_acc: 0.5018\n",
      "Epoch 7\n",
      "Train Batch 100 (every 100 batch): Loss=1.0144; accuracy=0.6252\n",
      "Train Batch 200 (every 100 batch): Loss=0.9760; accuracy=0.6252\n",
      "Train Batch 300 (every 100 batch): Loss=0.8390; accuracy=0.6225\n",
      "Epoch 7 summary: train_loss: 0.9249 | train_acc: 0.6183 | val_loss: 1.1936 | val_acc: 0.4862\n",
      "Epoch 8\n",
      "Train Batch 100 (every 100 batch): Loss=0.9267; accuracy=0.6423\n",
      "Train Batch 200 (every 100 batch): Loss=0.7939; accuracy=0.6416\n",
      "Train Batch 300 (every 100 batch): Loss=0.8031; accuracy=0.6428\n",
      "Epoch 8 summary: train_loss: 0.8801 | train_acc: 0.6434 | val_loss: 1.2713 | val_acc: 0.4753\n",
      "Epoch 9\n",
      "Train Batch 100 (every 100 batch): Loss=1.0565; accuracy=0.6612\n",
      "Train Batch 200 (every 100 batch): Loss=0.9562; accuracy=0.6558\n",
      "Train Batch 300 (every 100 batch): Loss=0.8544; accuracy=0.6553\n",
      "Epoch 9 summary: train_loss: 0.8525 | train_acc: 0.6553 | val_loss: 1.3298 | val_acc: 0.4644\n",
      "Epoch 10\n",
      "Train Batch 100 (every 100 batch): Loss=0.7142; accuracy=0.6681\n",
      "Train Batch 200 (every 100 batch): Loss=0.7107; accuracy=0.6701\n",
      "Train Batch 300 (every 100 batch): Loss=0.7728; accuracy=0.6732\n",
      "Epoch 10 summary: train_loss: 0.8090 | train_acc: 0.6728 | val_loss: 1.3177 | val_acc: 0.4767\n",
      "Epoch 11\n",
      "Train Batch 100 (every 100 batch): Loss=0.7926; accuracy=0.7061\n",
      "Train Batch 200 (every 100 batch): Loss=0.8177; accuracy=0.6978\n",
      "Train Batch 300 (every 100 batch): Loss=0.6881; accuracy=0.6985\n",
      "Epoch 11 summary: train_loss: 0.7574 | train_acc: 0.6977 | val_loss: 1.3208 | val_acc: 0.5044\n",
      "Epoch 12\n",
      "Train Batch 100 (every 100 batch): Loss=0.7218; accuracy=0.7147\n",
      "Train Batch 200 (every 100 batch): Loss=0.7261; accuracy=0.7088\n",
      "Train Batch 300 (every 100 batch): Loss=0.8301; accuracy=0.7086\n",
      "Epoch 12 summary: train_loss: 0.7311 | train_acc: 0.7090 | val_loss: 1.4727 | val_acc: 0.4720\n",
      "Epoch 13\n",
      "Train Batch 100 (every 100 batch): Loss=0.9264; accuracy=0.7092\n",
      "Train Batch 200 (every 100 batch): Loss=0.6140; accuracy=0.7073\n",
      "Train Batch 300 (every 100 batch): Loss=0.7690; accuracy=0.7106\n",
      "Epoch 13 summary: train_loss: 0.7230 | train_acc: 0.7107 | val_loss: 1.4031 | val_acc: 0.4836\n",
      "Epoch 14\n",
      "Train Batch 100 (every 100 batch): Loss=0.5941; accuracy=0.7492\n",
      "Train Batch 200 (every 100 batch): Loss=0.6311; accuracy=0.7439\n",
      "Train Batch 300 (every 100 batch): Loss=0.6543; accuracy=0.7323\n",
      "Epoch 14 summary: train_loss: 0.6826 | train_acc: 0.7308 | val_loss: 1.4160 | val_acc: 0.5047\n",
      "Epoch 15\n",
      "Train Batch 100 (every 100 batch): Loss=0.5946; accuracy=0.7570\n",
      "Train Batch 200 (every 100 batch): Loss=0.7527; accuracy=0.7561\n",
      "Train Batch 300 (every 100 batch): Loss=0.6841; accuracy=0.7535\n",
      "Epoch 15 summary: train_loss: 0.6284 | train_acc: 0.7523 | val_loss: 1.5310 | val_acc: 0.4789\n",
      "Epoch 16\n",
      "Train Batch 100 (every 100 batch): Loss=0.5559; accuracy=0.7792\n",
      "Train Batch 200 (every 100 batch): Loss=0.6834; accuracy=0.7622\n",
      "Train Batch 300 (every 100 batch): Loss=0.7847; accuracy=0.7592\n",
      "Epoch 16 summary: train_loss: 0.6137 | train_acc: 0.7591 | val_loss: 1.5264 | val_acc: 0.5007\n",
      "Epoch 17\n",
      "Train Batch 100 (every 100 batch): Loss=0.6108; accuracy=0.7880\n",
      "Train Batch 200 (every 100 batch): Loss=0.5887; accuracy=0.7807\n",
      "Train Batch 300 (every 100 batch): Loss=0.5037; accuracy=0.7805\n",
      "Epoch 17 summary: train_loss: 0.5642 | train_acc: 0.7788 | val_loss: 1.5744 | val_acc: 0.4866\n",
      "Epoch 18\n",
      "Train Batch 100 (every 100 batch): Loss=0.5216; accuracy=0.8164\n",
      "Train Batch 200 (every 100 batch): Loss=0.3859; accuracy=0.8107\n",
      "Train Batch 300 (every 100 batch): Loss=0.5792; accuracy=0.8027\n",
      "Epoch 18 summary: train_loss: 0.5060 | train_acc: 0.8015 | val_loss: 1.7293 | val_acc: 0.4895\n",
      "Epoch 19\n",
      "Train Batch 100 (every 100 batch): Loss=0.2916; accuracy=0.8155\n",
      "Train Batch 200 (every 100 batch): Loss=0.4458; accuracy=0.8183\n",
      "Train Batch 300 (every 100 batch): Loss=0.3873; accuracy=0.8145\n",
      "Epoch 19 summary: train_loss: 0.4794 | train_acc: 0.8142 | val_loss: 1.7839 | val_acc: 0.4840\n",
      "Epoch 20\n",
      "Train Batch 100 (every 100 batch): Loss=0.5126; accuracy=0.8436\n",
      "Train Batch 200 (every 100 batch): Loss=0.4678; accuracy=0.8359\n",
      "Train Batch 300 (every 100 batch): Loss=0.5358; accuracy=0.8273\n",
      "Epoch 20 summary: train_loss: 0.4546 | train_acc: 0.8284 | val_loss: 1.7952 | val_acc: 0.4702\n",
      "Epoch 21\n",
      "Train Batch 100 (every 100 batch): Loss=0.4483; accuracy=0.8605\n",
      "Train Batch 200 (every 100 batch): Loss=0.6277; accuracy=0.8527\n",
      "Train Batch 300 (every 100 batch): Loss=0.3401; accuracy=0.8420\n",
      "Epoch 21 summary: train_loss: 0.4113 | train_acc: 0.8424 | val_loss: 1.9218 | val_acc: 0.4742\n",
      "Epoch 22\n",
      "Train Batch 100 (every 100 batch): Loss=0.3214; accuracy=0.8697\n",
      "Train Batch 200 (every 100 batch): Loss=0.2923; accuracy=0.8645\n",
      "Train Batch 300 (every 100 batch): Loss=0.2897; accuracy=0.8640\n",
      "Epoch 22 summary: train_loss: 0.3665 | train_acc: 0.8630 | val_loss: 2.1835 | val_acc: 0.4673\n",
      "Epoch 23\n",
      "Train Batch 100 (every 100 batch): Loss=0.3587; accuracy=0.8642\n",
      "Train Batch 200 (every 100 batch): Loss=0.5204; accuracy=0.8670\n",
      "Train Batch 300 (every 100 batch): Loss=0.2713; accuracy=0.8643\n",
      "Epoch 23 summary: train_loss: 0.3658 | train_acc: 0.8623 | val_loss: 2.0324 | val_acc: 0.4644\n",
      "Epoch 24\n",
      "Train Batch 100 (every 100 batch): Loss=0.3340; accuracy=0.8870\n",
      "Train Batch 200 (every 100 batch): Loss=0.3422; accuracy=0.8868\n",
      "Train Batch 300 (every 100 batch): Loss=0.3352; accuracy=0.8829\n",
      "Epoch 24 summary: train_loss: 0.3120 | train_acc: 0.8819 | val_loss: 2.2825 | val_acc: 0.4742\n",
      "Epoch 25\n",
      "Train Batch 100 (every 100 batch): Loss=0.2738; accuracy=0.9006\n",
      "Train Batch 200 (every 100 batch): Loss=0.3061; accuracy=0.8976\n",
      "Train Batch 300 (every 100 batch): Loss=0.3593; accuracy=0.8975\n",
      "Epoch 25 summary: train_loss: 0.2807 | train_acc: 0.8953 | val_loss: 2.2410 | val_acc: 0.4942\n",
      "Epoch 26\n",
      "Train Batch 100 (every 100 batch): Loss=0.2559; accuracy=0.9059\n",
      "Train Batch 200 (every 100 batch): Loss=0.2732; accuracy=0.9034\n",
      "Train Batch 300 (every 100 batch): Loss=0.2452; accuracy=0.8996\n",
      "Epoch 26 summary: train_loss: 0.2729 | train_acc: 0.8971 | val_loss: 2.2917 | val_acc: 0.4862\n",
      "Epoch 27\n",
      "Train Batch 100 (every 100 batch): Loss=0.3169; accuracy=0.9013\n",
      "Train Batch 200 (every 100 batch): Loss=0.3153; accuracy=0.9006\n",
      "Train Batch 300 (every 100 batch): Loss=0.4049; accuracy=0.9012\n",
      "Epoch 27 summary: train_loss: 0.2712 | train_acc: 0.9019 | val_loss: 2.6345 | val_acc: 0.4673\n",
      "Epoch 28\n",
      "Train Batch 100 (every 100 batch): Loss=0.1499; accuracy=0.9225\n",
      "Train Batch 200 (every 100 batch): Loss=0.2323; accuracy=0.9277\n",
      "Train Batch 300 (every 100 batch): Loss=0.1931; accuracy=0.9224\n",
      "Epoch 28 summary: train_loss: 0.2183 | train_acc: 0.9209 | val_loss: 2.5748 | val_acc: 0.4826\n",
      "Epoch 29\n",
      "Train Batch 100 (every 100 batch): Loss=0.2690; accuracy=0.9342\n",
      "Train Batch 200 (every 100 batch): Loss=0.1960; accuracy=0.9279\n",
      "Train Batch 300 (every 100 batch): Loss=0.3677; accuracy=0.9217\n",
      "Epoch 29 summary: train_loss: 0.2215 | train_acc: 0.9201 | val_loss: 3.0128 | val_acc: 0.4404\n",
      "Epoch 30\n",
      "Train Batch 100 (every 100 batch): Loss=0.1038; accuracy=0.9228\n",
      "Train Batch 200 (every 100 batch): Loss=0.2134; accuracy=0.9240\n",
      "Train Batch 300 (every 100 batch): Loss=0.3087; accuracy=0.9251\n",
      "Epoch 30 summary: train_loss: 0.2124 | train_acc: 0.9235 | val_loss: 2.9000 | val_acc: 0.4393\n",
      "Epoch 31\n",
      "Train Batch 100 (every 100 batch): Loss=0.1203; accuracy=0.9452\n",
      "Train Batch 200 (every 100 batch): Loss=0.3083; accuracy=0.9428\n",
      "Train Batch 300 (every 100 batch): Loss=0.2507; accuracy=0.9369\n",
      "Epoch 31 summary: train_loss: 0.1896 | train_acc: 0.9329 | val_loss: 3.0155 | val_acc: 0.4582\n",
      "Epoch 32\n",
      "Train Batch 100 (every 100 batch): Loss=0.1813; accuracy=0.9250\n",
      "Train Batch 200 (every 100 batch): Loss=0.1150; accuracy=0.9364\n",
      "Train Batch 300 (every 100 batch): Loss=0.1433; accuracy=0.9388\n",
      "Epoch 32 summary: train_loss: 0.1653 | train_acc: 0.9406 | val_loss: 3.1839 | val_acc: 0.4677\n",
      "Epoch 33\n",
      "Train Batch 100 (every 100 batch): Loss=0.0706; accuracy=0.9578\n",
      "Train Batch 200 (every 100 batch): Loss=0.2671; accuracy=0.9537\n",
      "Train Batch 300 (every 100 batch): Loss=0.1235; accuracy=0.9496\n",
      "Epoch 33 summary: train_loss: 0.1482 | train_acc: 0.9480 | val_loss: 3.3909 | val_acc: 0.4673\n",
      "Epoch 34\n",
      "Train Batch 100 (every 100 batch): Loss=0.1767; accuracy=0.9416\n",
      "Train Batch 200 (every 100 batch): Loss=0.0940; accuracy=0.9485\n",
      "Train Batch 300 (every 100 batch): Loss=0.0970; accuracy=0.9511\n",
      "Epoch 34 summary: train_loss: 0.1425 | train_acc: 0.9512 | val_loss: 3.3274 | val_acc: 0.4557\n",
      "Epoch 35\n",
      "Train Batch 100 (every 100 batch): Loss=0.0579; accuracy=0.9645\n",
      "Train Batch 200 (every 100 batch): Loss=0.2438; accuracy=0.9625\n",
      "Train Batch 300 (every 100 batch): Loss=0.1229; accuracy=0.9591\n",
      "Epoch 35 summary: train_loss: 0.1240 | train_acc: 0.9577 | val_loss: 3.3456 | val_acc: 0.4560\n",
      "Epoch 36\n",
      "Train Batch 100 (every 100 batch): Loss=0.0677; accuracy=0.9539\n",
      "Train Batch 200 (every 100 batch): Loss=0.3460; accuracy=0.9486\n",
      "Train Batch 300 (every 100 batch): Loss=0.2249; accuracy=0.9392\n",
      "Epoch 36 summary: train_loss: 0.1669 | train_acc: 0.9398 | val_loss: 3.2579 | val_acc: 0.4869\n",
      "Epoch 37\n",
      "Train Batch 100 (every 100 batch): Loss=0.1013; accuracy=0.9539\n",
      "Train Batch 200 (every 100 batch): Loss=0.1081; accuracy=0.9593\n",
      "Train Batch 300 (every 100 batch): Loss=0.0893; accuracy=0.9577\n",
      "Epoch 37 summary: train_loss: 0.1245 | train_acc: 0.9571 | val_loss: 3.6170 | val_acc: 0.4586\n",
      "Epoch 38\n",
      "Train Batch 100 (every 100 batch): Loss=0.0516; accuracy=0.9672\n",
      "Train Batch 200 (every 100 batch): Loss=0.0531; accuracy=0.9711\n",
      "Train Batch 300 (every 100 batch): Loss=0.1275; accuracy=0.9672\n",
      "Epoch 38 summary: train_loss: 0.1058 | train_acc: 0.9654 | val_loss: 3.7340 | val_acc: 0.4727\n",
      "Epoch 39\n",
      "Train Batch 100 (every 100 batch): Loss=0.3940; accuracy=0.9723\n",
      "Train Batch 200 (every 100 batch): Loss=0.1043; accuracy=0.9604\n",
      "Train Batch 300 (every 100 batch): Loss=0.0970; accuracy=0.9551\n",
      "Epoch 39 summary: train_loss: 0.1363 | train_acc: 0.9539 | val_loss: 3.4601 | val_acc: 0.4662\n",
      "Epoch 40\n",
      "Train Batch 100 (every 100 batch): Loss=0.1238; accuracy=0.9544\n",
      "Train Batch 200 (every 100 batch): Loss=0.1400; accuracy=0.9560\n",
      "Train Batch 300 (every 100 batch): Loss=0.1570; accuracy=0.9565\n",
      "Epoch 40 summary: train_loss: 0.1298 | train_acc: 0.9555 | val_loss: 3.5754 | val_acc: 0.4568\n",
      "Epoch 41\n",
      "Train Batch 100 (every 100 batch): Loss=0.2738; accuracy=0.9666\n",
      "Train Batch 200 (every 100 batch): Loss=0.0693; accuracy=0.9632\n",
      "Train Batch 300 (every 100 batch): Loss=0.2369; accuracy=0.9564\n",
      "Epoch 41 summary: train_loss: 0.1326 | train_acc: 0.9560 | val_loss: 3.6358 | val_acc: 0.4546\n",
      "Epoch 42\n",
      "Train Batch 100 (every 100 batch): Loss=0.1349; accuracy=0.9775\n",
      "Train Batch 200 (every 100 batch): Loss=0.1443; accuracy=0.9748\n",
      "Train Batch 300 (every 100 batch): Loss=0.0820; accuracy=0.9736\n",
      "Epoch 42 summary: train_loss: 0.0823 | train_acc: 0.9732 | val_loss: 3.7973 | val_acc: 0.4560\n",
      "Epoch 43\n",
      "Train Batch 100 (every 100 batch): Loss=0.0160; accuracy=0.9850\n",
      "Train Batch 200 (every 100 batch): Loss=0.0400; accuracy=0.9846\n",
      "Train Batch 300 (every 100 batch): Loss=0.0333; accuracy=0.9837\n",
      "Epoch 43 summary: train_loss: 0.0586 | train_acc: 0.9829 | val_loss: 4.3017 | val_acc: 0.4626\n",
      "Epoch 44\n",
      "Train Batch 100 (every 100 batch): Loss=0.0422; accuracy=0.9834\n",
      "Train Batch 200 (every 100 batch): Loss=0.0336; accuracy=0.9866\n",
      "Train Batch 300 (every 100 batch): Loss=0.2472; accuracy=0.9811\n",
      "Epoch 44 summary: train_loss: 0.0680 | train_acc: 0.9784 | val_loss: 4.0570 | val_acc: 0.4571\n",
      "Epoch 45\n",
      "Train Batch 100 (every 100 batch): Loss=0.1068; accuracy=0.9500\n",
      "Train Batch 200 (every 100 batch): Loss=0.1138; accuracy=0.9508\n",
      "Train Batch 300 (every 100 batch): Loss=0.1035; accuracy=0.9442\n",
      "Epoch 45 summary: train_loss: 0.1761 | train_acc: 0.9426 | val_loss: 3.5456 | val_acc: 0.4422\n",
      "Epoch 46\n",
      "Train Batch 100 (every 100 batch): Loss=0.0789; accuracy=0.9664\n",
      "Train Batch 200 (every 100 batch): Loss=0.2064; accuracy=0.9714\n",
      "Train Batch 300 (every 100 batch): Loss=0.0921; accuracy=0.9741\n",
      "Epoch 46 summary: train_loss: 0.0825 | train_acc: 0.9743 | val_loss: 3.8131 | val_acc: 0.4618\n",
      "Epoch 47\n",
      "Train Batch 100 (every 100 batch): Loss=0.0165; accuracy=0.9803\n",
      "Train Batch 200 (every 100 batch): Loss=0.0409; accuracy=0.9770\n",
      "Train Batch 300 (every 100 batch): Loss=0.1776; accuracy=0.9777\n",
      "Epoch 47 summary: train_loss: 0.0705 | train_acc: 0.9778 | val_loss: 4.3179 | val_acc: 0.4604\n",
      "Epoch 48\n",
      "Train Batch 100 (every 100 batch): Loss=0.0187; accuracy=0.9867\n",
      "Train Batch 200 (every 100 batch): Loss=0.0260; accuracy=0.9884\n",
      "Train Batch 300 (every 100 batch): Loss=0.0838; accuracy=0.9864\n",
      "Epoch 48 summary: train_loss: 0.0520 | train_acc: 0.9844 | val_loss: 4.0627 | val_acc: 0.4662\n",
      "Epoch 49\n",
      "Train Batch 100 (every 100 batch): Loss=0.1107; accuracy=0.9609\n",
      "Train Batch 200 (every 100 batch): Loss=0.1140; accuracy=0.9412\n",
      "Train Batch 300 (every 100 batch): Loss=0.1949; accuracy=0.9416\n",
      "Epoch 49 summary: train_loss: 0.1675 | train_acc: 0.9439 | val_loss: 3.7600 | val_acc: 0.4502\n",
      "Epoch 50\n",
      "Train Batch 100 (every 100 batch): Loss=0.1254; accuracy=0.9794\n",
      "Train Batch 200 (every 100 batch): Loss=0.0642; accuracy=0.9784\n",
      "Train Batch 300 (every 100 batch): Loss=0.0862; accuracy=0.9801\n",
      "Epoch 50 summary: train_loss: 0.0630 | train_acc: 0.9808 | val_loss: 4.2457 | val_acc: 0.4553\n",
      "Epoch 51\n",
      "Train Batch 100 (every 100 batch): Loss=0.0380; accuracy=0.9861\n",
      "Train Batch 200 (every 100 batch): Loss=0.0387; accuracy=0.9855\n",
      "Train Batch 300 (every 100 batch): Loss=0.3913; accuracy=0.9783\n",
      "Epoch 51 summary: train_loss: 0.0970 | train_acc: 0.9695 | val_loss: 3.8693 | val_acc: 0.4560\n",
      "Epoch 52\n",
      "Train Batch 100 (every 100 batch): Loss=0.2227; accuracy=0.9444\n",
      "Train Batch 200 (every 100 batch): Loss=0.1420; accuracy=0.9515\n",
      "Train Batch 300 (every 100 batch): Loss=0.4952; accuracy=0.9543\n",
      "Epoch 52 summary: train_loss: 0.1736 | train_acc: 0.9442 | val_loss: 3.7839 | val_acc: 0.4419\n",
      "Epoch 53\n",
      "Train Batch 100 (every 100 batch): Loss=0.2424; accuracy=0.9142\n",
      "Train Batch 200 (every 100 batch): Loss=0.1705; accuracy=0.9314\n",
      "Train Batch 300 (every 100 batch): Loss=0.1356; accuracy=0.9370\n",
      "Epoch 53 summary: train_loss: 0.1766 | train_acc: 0.9391 | val_loss: 3.5122 | val_acc: 0.4753\n",
      "Epoch 54\n",
      "Train Batch 100 (every 100 batch): Loss=0.1512; accuracy=0.9836\n",
      "Train Batch 200 (every 100 batch): Loss=0.0758; accuracy=0.9816\n",
      "Train Batch 300 (every 100 batch): Loss=0.0099; accuracy=0.9822\n",
      "Epoch 54 summary: train_loss: 0.0627 | train_acc: 0.9814 | val_loss: 3.6776 | val_acc: 0.4840\n",
      "Epoch 55\n",
      "Train Batch 100 (every 100 batch): Loss=0.0110; accuracy=0.9855\n",
      "Train Batch 200 (every 100 batch): Loss=0.0280; accuracy=0.9879\n",
      "Train Batch 300 (every 100 batch): Loss=0.0243; accuracy=0.9898\n",
      "Epoch 55 summary: train_loss: 0.0393 | train_acc: 0.9897 | val_loss: 4.3516 | val_acc: 0.4680\n",
      "Epoch 56\n",
      "Train Batch 100 (every 100 batch): Loss=0.0268; accuracy=0.9970\n",
      "Train Batch 200 (every 100 batch): Loss=0.0161; accuracy=0.9973\n",
      "Train Batch 300 (every 100 batch): Loss=0.0281; accuracy=0.9971\n",
      "Epoch 56 summary: train_loss: 0.0179 | train_acc: 0.9965 | val_loss: 4.3527 | val_acc: 0.4684\n",
      "Epoch 57\n",
      "Train Batch 100 (every 100 batch): Loss=0.0644; accuracy=0.9973\n",
      "Train Batch 200 (every 100 batch): Loss=0.1421; accuracy=0.9880\n",
      "Train Batch 300 (every 100 batch): Loss=0.1145; accuracy=0.9823\n",
      "Epoch 57 summary: train_loss: 0.0581 | train_acc: 0.9816 | val_loss: 4.4672 | val_acc: 0.4455\n",
      "Epoch 58\n",
      "Train Batch 100 (every 100 batch): Loss=0.1900; accuracy=0.9631\n",
      "Train Batch 200 (every 100 batch): Loss=0.0741; accuracy=0.9591\n",
      "Train Batch 300 (every 100 batch): Loss=0.5881; accuracy=0.9324\n",
      "Epoch 58 summary: train_loss: 0.2380 | train_acc: 0.9260 | val_loss: 3.1253 | val_acc: 0.4604\n",
      "Epoch 59\n",
      "Train Batch 100 (every 100 batch): Loss=0.1015; accuracy=0.9372\n",
      "Train Batch 200 (every 100 batch): Loss=0.1871; accuracy=0.9420\n",
      "Train Batch 300 (every 100 batch): Loss=0.0981; accuracy=0.9469\n",
      "Epoch 59 summary: train_loss: 0.1521 | train_acc: 0.9489 | val_loss: 3.7375 | val_acc: 0.4539\n",
      "Epoch 60\n",
      "Train Batch 100 (every 100 batch): Loss=0.0265; accuracy=0.9811\n",
      "Train Batch 200 (every 100 batch): Loss=0.0702; accuracy=0.9816\n",
      "Train Batch 300 (every 100 batch): Loss=0.0311; accuracy=0.9826\n",
      "Epoch 60 summary: train_loss: 0.0609 | train_acc: 0.9826 | val_loss: 3.9431 | val_acc: 0.4495\n",
      "Epoch 61\n",
      "Train Batch 100 (every 100 batch): Loss=0.0575; accuracy=0.9663\n",
      "Train Batch 200 (every 100 batch): Loss=0.0480; accuracy=0.9678\n",
      "Train Batch 300 (every 100 batch): Loss=0.0757; accuracy=0.9723\n",
      "Epoch 61 summary: train_loss: 0.0876 | train_acc: 0.9729 | val_loss: 4.1097 | val_acc: 0.4411\n",
      "Epoch 62\n",
      "Train Batch 100 (every 100 batch): Loss=0.1185; accuracy=0.9758\n",
      "Train Batch 200 (every 100 batch): Loss=0.0530; accuracy=0.9789\n",
      "Train Batch 300 (every 100 batch): Loss=0.3241; accuracy=0.9810\n",
      "Epoch 62 summary: train_loss: 0.0875 | train_acc: 0.9737 | val_loss: 3.7014 | val_acc: 0.4448\n",
      "Epoch 63\n",
      "Train Batch 100 (every 100 batch): Loss=0.0555; accuracy=0.9680\n",
      "Train Batch 200 (every 100 batch): Loss=0.1227; accuracy=0.9680\n",
      "Train Batch 300 (every 100 batch): Loss=0.0789; accuracy=0.9705\n",
      "Epoch 63 summary: train_loss: 0.0856 | train_acc: 0.9716 | val_loss: 4.2055 | val_acc: 0.4499\n",
      "Epoch 64\n",
      "Train Batch 100 (every 100 batch): Loss=0.0167; accuracy=0.9942\n",
      "Train Batch 200 (every 100 batch): Loss=0.0095; accuracy=0.9951\n",
      "Train Batch 300 (every 100 batch): Loss=0.0231; accuracy=0.9956\n",
      "Epoch 64 summary: train_loss: 0.0209 | train_acc: 0.9958 | val_loss: 4.5964 | val_acc: 0.4622\n",
      "Epoch 65\n",
      "Train Batch 100 (every 100 batch): Loss=0.0128; accuracy=0.9992\n",
      "Train Batch 200 (every 100 batch): Loss=0.0075; accuracy=0.9993\n",
      "Train Batch 300 (every 100 batch): Loss=0.0028; accuracy=0.9991\n",
      "Epoch 65 summary: train_loss: 0.0087 | train_acc: 0.9992 | val_loss: 4.8446 | val_acc: 0.4637\n",
      "Epoch 66\n",
      "Train Batch 100 (every 100 batch): Loss=0.0017; accuracy=0.9997\n",
      "Train Batch 200 (every 100 batch): Loss=0.0029; accuracy=0.9998\n",
      "Train Batch 300 (every 100 batch): Loss=0.0031; accuracy=0.9998\n",
      "Epoch 66 summary: train_loss: 0.0036 | train_acc: 0.9999 | val_loss: 5.1567 | val_acc: 0.4597\n",
      "Epoch 67\n",
      "Train Batch 100 (every 100 batch): Loss=0.0020; accuracy=1.0000\n",
      "Train Batch 200 (every 100 batch): Loss=0.0015; accuracy=1.0000\n",
      "Train Batch 300 (every 100 batch): Loss=0.0040; accuracy=0.9999\n",
      "Epoch 67 summary: train_loss: 0.0039 | train_acc: 0.9994 | val_loss: 5.2991 | val_acc: 0.4473\n",
      "Epoch 68\n",
      "Train Batch 100 (every 100 batch): Loss=0.0041; accuracy=0.9950\n",
      "Train Batch 200 (every 100 batch): Loss=0.1298; accuracy=0.9839\n",
      "Train Batch 300 (every 100 batch): Loss=0.5568; accuracy=0.9556\n",
      "Epoch 68 summary: train_loss: 0.1700 | train_acc: 0.9487 | val_loss: 3.7492 | val_acc: 0.4509\n",
      "Epoch 69\n",
      "Train Batch 100 (every 100 batch): Loss=0.2928; accuracy=0.9177\n",
      "Train Batch 200 (every 100 batch): Loss=0.0341; accuracy=0.9319\n",
      "Train Batch 300 (every 100 batch): Loss=0.1645; accuracy=0.9413\n",
      "Epoch 69 summary: train_loss: 0.1652 | train_acc: 0.9454 | val_loss: 4.0196 | val_acc: 0.4535\n",
      "Epoch 70\n",
      "Train Batch 100 (every 100 batch): Loss=0.0661; accuracy=0.9798\n",
      "Train Batch 200 (every 100 batch): Loss=0.0307; accuracy=0.9748\n",
      "Train Batch 300 (every 100 batch): Loss=0.0661; accuracy=0.9760\n",
      "Epoch 70 summary: train_loss: 0.0716 | train_acc: 0.9770 | val_loss: 4.2040 | val_acc: 0.4611\n",
      "Epoch 71\n",
      "Train Batch 100 (every 100 batch): Loss=0.1118; accuracy=0.9914\n",
      "Train Batch 200 (every 100 batch): Loss=0.0222; accuracy=0.9810\n",
      "Train Batch 300 (every 100 batch): Loss=0.0234; accuracy=0.9742\n",
      "Epoch 71 summary: train_loss: 0.0810 | train_acc: 0.9734 | val_loss: 4.2140 | val_acc: 0.4531\n",
      "Epoch 72\n",
      "Train Batch 100 (every 100 batch): Loss=0.0393; accuracy=0.9844\n",
      "Train Batch 200 (every 100 batch): Loss=0.0226; accuracy=0.9873\n",
      "Train Batch 300 (every 100 batch): Loss=0.0327; accuracy=0.9883\n",
      "Epoch 72 summary: train_loss: 0.0397 | train_acc: 0.9884 | val_loss: 4.4693 | val_acc: 0.4549\n",
      "Epoch 73\n",
      "Train Batch 100 (every 100 batch): Loss=0.0285; accuracy=0.9833\n",
      "Train Batch 200 (every 100 batch): Loss=0.1149; accuracy=0.9850\n",
      "Train Batch 300 (every 100 batch): Loss=0.0367; accuracy=0.9860\n",
      "Epoch 73 summary: train_loss: 0.0489 | train_acc: 0.9847 | val_loss: 4.5904 | val_acc: 0.4437\n",
      "Epoch 74\n",
      "Train Batch 100 (every 100 batch): Loss=0.0222; accuracy=0.9822\n",
      "Train Batch 200 (every 100 batch): Loss=0.0218; accuracy=0.9823\n",
      "Train Batch 300 (every 100 batch): Loss=0.0424; accuracy=0.9817\n",
      "Epoch 74 summary: train_loss: 0.0601 | train_acc: 0.9811 | val_loss: 4.8031 | val_acc: 0.4451\n",
      "Epoch 75\n",
      "Train Batch 100 (every 100 batch): Loss=0.0305; accuracy=0.9817\n",
      "Train Batch 200 (every 100 batch): Loss=0.0121; accuracy=0.9843\n",
      "Train Batch 300 (every 100 batch): Loss=0.0647; accuracy=0.9841\n",
      "Epoch 75 summary: train_loss: 0.0511 | train_acc: 0.9844 | val_loss: 4.9725 | val_acc: 0.4371\n",
      "Epoch 76\n",
      "Train Batch 100 (every 100 batch): Loss=0.0225; accuracy=0.9930\n",
      "Train Batch 200 (every 100 batch): Loss=0.0314; accuracy=0.9941\n",
      "Train Batch 300 (every 100 batch): Loss=0.0143; accuracy=0.9939\n",
      "Epoch 76 summary: train_loss: 0.0225 | train_acc: 0.9938 | val_loss: 4.9270 | val_acc: 0.4582\n",
      "Epoch 77\n",
      "Train Batch 100 (every 100 batch): Loss=0.0708; accuracy=0.9859\n",
      "Train Batch 200 (every 100 batch): Loss=0.1482; accuracy=0.9839\n",
      "Train Batch 300 (every 100 batch): Loss=0.0601; accuracy=0.9822\n",
      "Epoch 77 summary: train_loss: 0.0551 | train_acc: 0.9818 | val_loss: 4.8365 | val_acc: 0.4509\n",
      "Epoch 78\n",
      "Train Batch 100 (every 100 batch): Loss=0.0323; accuracy=0.9784\n",
      "Train Batch 200 (every 100 batch): Loss=0.1442; accuracy=0.9663\n",
      "Train Batch 300 (every 100 batch): Loss=0.1800; accuracy=0.9606\n",
      "Epoch 78 summary: train_loss: 0.1218 | train_acc: 0.9602 | val_loss: 4.5215 | val_acc: 0.4462\n",
      "Epoch 79\n",
      "Train Batch 100 (every 100 batch): Loss=0.2756; accuracy=0.9497\n",
      "Train Batch 200 (every 100 batch): Loss=0.1603; accuracy=0.9380\n",
      "Train Batch 300 (every 100 batch): Loss=0.0500; accuracy=0.9466\n",
      "Epoch 79 summary: train_loss: 0.1545 | train_acc: 0.9485 | val_loss: 4.1632 | val_acc: 0.4506\n",
      "Epoch 80\n",
      "Train Batch 100 (every 100 batch): Loss=0.0191; accuracy=0.9792\n",
      "Train Batch 200 (every 100 batch): Loss=0.0371; accuracy=0.9841\n",
      "Train Batch 300 (every 100 batch): Loss=0.0167; accuracy=0.9866\n",
      "Epoch 80 summary: train_loss: 0.0430 | train_acc: 0.9873 | val_loss: 4.6998 | val_acc: 0.4662\n",
      "Epoch 81\n",
      "Train Batch 100 (every 100 batch): Loss=0.0034; accuracy=0.9978\n",
      "Train Batch 200 (every 100 batch): Loss=0.0111; accuracy=0.9973\n",
      "Train Batch 300 (every 100 batch): Loss=0.0091; accuracy=0.9977\n",
      "Epoch 81 summary: train_loss: 0.0139 | train_acc: 0.9976 | val_loss: 4.9300 | val_acc: 0.4626\n",
      "Epoch 82\n",
      "Train Batch 100 (every 100 batch): Loss=0.0037; accuracy=0.9983\n",
      "Train Batch 200 (every 100 batch): Loss=0.0137; accuracy=0.9955\n",
      "Train Batch 300 (every 100 batch): Loss=0.0466; accuracy=0.9925\n",
      "Epoch 82 summary: train_loss: 0.0343 | train_acc: 0.9906 | val_loss: 4.5290 | val_acc: 0.4648\n",
      "Epoch 83\n",
      "Train Batch 100 (every 100 batch): Loss=0.0130; accuracy=0.9809\n",
      "Train Batch 200 (every 100 batch): Loss=0.0239; accuracy=0.9839\n",
      "Train Batch 300 (every 100 batch): Loss=0.0076; accuracy=0.9848\n",
      "Epoch 83 summary: train_loss: 0.0477 | train_acc: 0.9842 | val_loss: 5.0329 | val_acc: 0.4400\n",
      "Epoch 84\n",
      "Train Batch 100 (every 100 batch): Loss=0.0098; accuracy=0.9820\n",
      "Train Batch 200 (every 100 batch): Loss=0.0062; accuracy=0.9812\n",
      "Train Batch 300 (every 100 batch): Loss=0.1449; accuracy=0.9788\n",
      "Epoch 84 summary: train_loss: 0.0706 | train_acc: 0.9786 | val_loss: 4.7014 | val_acc: 0.4549\n",
      "Epoch 85\n",
      "Train Batch 100 (every 100 batch): Loss=0.0060; accuracy=0.9845\n",
      "Train Batch 200 (every 100 batch): Loss=0.0913; accuracy=0.9786\n",
      "Train Batch 300 (every 100 batch): Loss=0.1323; accuracy=0.9742\n",
      "Epoch 85 summary: train_loss: 0.0811 | train_acc: 0.9742 | val_loss: 4.7934 | val_acc: 0.4560\n",
      "Epoch 86\n",
      "Train Batch 100 (every 100 batch): Loss=0.0666; accuracy=0.9861\n",
      "Train Batch 200 (every 100 batch): Loss=0.0070; accuracy=0.9874\n",
      "Train Batch 300 (every 100 batch): Loss=0.0118; accuracy=0.9873\n",
      "Epoch 86 summary: train_loss: 0.0452 | train_acc: 0.9856 | val_loss: 4.7746 | val_acc: 0.4400\n",
      "Epoch 87\n",
      "Train Batch 100 (every 100 batch): Loss=0.0792; accuracy=0.9809\n",
      "Train Batch 200 (every 100 batch): Loss=0.0542; accuracy=0.9782\n",
      "Train Batch 300 (every 100 batch): Loss=0.0295; accuracy=0.9782\n",
      "Epoch 87 summary: train_loss: 0.0712 | train_acc: 0.9781 | val_loss: 4.9847 | val_acc: 0.4557\n",
      "Epoch 88\n",
      "Train Batch 100 (every 100 batch): Loss=0.0157; accuracy=0.9889\n",
      "Train Batch 200 (every 100 batch): Loss=0.0675; accuracy=0.9844\n",
      "Train Batch 300 (every 100 batch): Loss=0.0814; accuracy=0.9827\n",
      "Epoch 88 summary: train_loss: 0.0594 | train_acc: 0.9818 | val_loss: 4.7111 | val_acc: 0.4419\n",
      "Epoch 89\n",
      "Train Batch 100 (every 100 batch): Loss=0.0614; accuracy=0.9820\n",
      "Train Batch 200 (every 100 batch): Loss=0.0436; accuracy=0.9865\n",
      "Train Batch 300 (every 100 batch): Loss=0.0173; accuracy=0.9881\n",
      "Epoch 89 summary: train_loss: 0.0370 | train_acc: 0.9884 | val_loss: 4.6967 | val_acc: 0.4655\n",
      "Epoch 90\n",
      "Train Batch 100 (every 100 batch): Loss=0.0080; accuracy=0.9917\n",
      "Train Batch 200 (every 100 batch): Loss=0.0017; accuracy=0.9927\n",
      "Train Batch 300 (every 100 batch): Loss=0.2127; accuracy=0.9916\n",
      "Epoch 90 summary: train_loss: 0.0283 | train_acc: 0.9917 | val_loss: 4.9488 | val_acc: 0.4564\n",
      "Epoch 91\n",
      "Train Batch 100 (every 100 batch): Loss=0.0105; accuracy=0.9881\n",
      "Train Batch 200 (every 100 batch): Loss=0.0278; accuracy=0.9763\n",
      "Train Batch 300 (every 100 batch): Loss=0.0872; accuracy=0.9732\n",
      "Epoch 91 summary: train_loss: 0.0867 | train_acc: 0.9727 | val_loss: 5.1429 | val_acc: 0.4382\n",
      "Epoch 92\n",
      "Train Batch 100 (every 100 batch): Loss=0.6175; accuracy=0.9428\n",
      "Train Batch 200 (every 100 batch): Loss=0.0449; accuracy=0.9498\n",
      "Train Batch 300 (every 100 batch): Loss=0.0779; accuracy=0.9582\n",
      "Epoch 92 summary: train_loss: 0.1218 | train_acc: 0.9597 | val_loss: 4.6240 | val_acc: 0.4564\n",
      "Epoch 93\n",
      "Train Batch 100 (every 100 batch): Loss=0.0336; accuracy=0.9828\n",
      "Train Batch 200 (every 100 batch): Loss=0.0184; accuracy=0.9853\n",
      "Train Batch 300 (every 100 batch): Loss=0.0105; accuracy=0.9867\n",
      "Epoch 93 summary: train_loss: 0.0408 | train_acc: 0.9871 | val_loss: 4.9027 | val_acc: 0.4506\n",
      "Epoch 94\n",
      "Train Batch 100 (every 100 batch): Loss=0.0108; accuracy=0.9964\n",
      "Train Batch 200 (every 100 batch): Loss=0.0287; accuracy=0.9960\n",
      "Train Batch 300 (every 100 batch): Loss=0.0093; accuracy=0.9951\n",
      "Epoch 94 summary: train_loss: 0.0201 | train_acc: 0.9947 | val_loss: 4.9479 | val_acc: 0.4658\n",
      "Epoch 95\n",
      "Train Batch 100 (every 100 batch): Loss=0.0066; accuracy=0.9973\n",
      "Train Batch 200 (every 100 batch): Loss=0.0117; accuracy=0.9970\n",
      "Train Batch 300 (every 100 batch): Loss=0.0015; accuracy=0.9977\n",
      "Epoch 95 summary: train_loss: 0.0104 | train_acc: 0.9978 | val_loss: 5.2458 | val_acc: 0.4680\n",
      "Epoch 96\n",
      "Train Batch 100 (every 100 batch): Loss=0.0038; accuracy=0.9994\n",
      "Train Batch 200 (every 100 batch): Loss=0.0016; accuracy=0.9996\n",
      "Train Batch 300 (every 100 batch): Loss=0.0048; accuracy=0.9997\n",
      "Epoch 96 summary: train_loss: 0.0030 | train_acc: 0.9998 | val_loss: 5.4911 | val_acc: 0.4629\n",
      "Epoch 97\n",
      "Train Batch 100 (every 100 batch): Loss=0.0016; accuracy=1.0000\n",
      "Train Batch 200 (every 100 batch): Loss=0.0009; accuracy=1.0000\n",
      "Train Batch 300 (every 100 batch): Loss=0.0015; accuracy=1.0000\n",
      "Epoch 97 summary: train_loss: 0.0013 | train_acc: 1.0000 | val_loss: 5.7316 | val_acc: 0.4666\n",
      "Epoch 98\n",
      "Train Batch 100 (every 100 batch): Loss=0.0006; accuracy=1.0000\n",
      "Train Batch 200 (every 100 batch): Loss=0.0005; accuracy=1.0000\n",
      "Train Batch 300 (every 100 batch): Loss=0.0006; accuracy=1.0000\n",
      "Epoch 98 summary: train_loss: 0.0009 | train_acc: 1.0000 | val_loss: 5.6595 | val_acc: 0.4717\n",
      "Epoch 99\n",
      "Train Batch 100 (every 100 batch): Loss=0.0005; accuracy=1.0000\n",
      "Train Batch 200 (every 100 batch): Loss=0.0005; accuracy=1.0000\n",
      "Train Batch 300 (every 100 batch): Loss=0.0005; accuracy=1.0000\n",
      "Epoch 99 summary: train_loss: 0.0007 | train_acc: 1.0000 | val_loss: 5.8709 | val_acc: 0.4727\n",
      "Epoch 100\n",
      "Train Batch 100 (every 100 batch): Loss=0.0003; accuracy=1.0000\n",
      "Train Batch 200 (every 100 batch): Loss=0.0002; accuracy=1.0000\n",
      "Train Batch 300 (every 100 batch): Loss=0.0006; accuracy=1.0000\n",
      "Epoch 100 summary: train_loss: 0.0005 | train_acc: 1.0000 | val_loss: 5.9836 | val_acc: 0.4680\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m non_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mkind\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom-scratch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     loss_history, accuracy_val, accuracy_test \u001b[38;5;241m=\u001b[39m net_trainer(\n\u001b[1;32m      5\u001b[0m             net,\n\u001b[1;32m      6\u001b[0m             loaders,\n\u001b[1;32m      7\u001b[0m             opt,\n\u001b[1;32m      8\u001b[0m             channel_idx,\n\u001b[1;32m      9\u001b[0m             nonclasses,\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m             model_path)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "channel_idx=None\n",
    "non_classes=None\n",
    "if opt.kind==\"from-scratch\":\n",
    "    loss_history, accuracy_val, accuracy_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0199dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val =accuracy_val\n",
    "# test = accuracy_test\n",
    "\n",
    "# print(\"Validation accuracy: \", val)\n",
    "# print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f370e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a7d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2334ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b77fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080e706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17823cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b650c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb911b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b43930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28237288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ded073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcbdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fb11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b75470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8939417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5c258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597563e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d74a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db30ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1544e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
