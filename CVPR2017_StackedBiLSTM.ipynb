{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea7f6401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from analysis import *\n",
    "import argparse\n",
    "from sys import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c192d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(12)\n",
    "torch.cuda.manual_seed(12)\n",
    "np.random.seed(12)\n",
    "torch.backends.cudnn.deterministics = True\n",
    "torch.set_num_threads(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "daf1a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "2\n",
      "0\n",
      "<torch.cuda.device object at 0x7f49e433dd20>\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.current_device())\n",
    "\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff733115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv: image option\n",
    "length = 440\n",
    "channel = 128\n",
    "min_CNN = 200\n",
    "n_classes = 40\n",
    "classes = range(n_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b68db2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagenet_full', 'eeg_heatmaps_55_95.pth', 'block_splits_by_image_all.pth', 'eeg_heatmaps_14_70.pth', 'splits_by_subject.pth', 'eeg_raw.pth', 'splits_by_subject_1.pth', 'splits_by_image_removed_33.pth', 'imagenet_augmented', 'eeg_55_95_std_downsampled_128Hz_resample.pth', 'eeg_14_70_std.pth', 'imagenet_noeeg_40.zip', 'splits_by_subject_2.pth', 'eeg_55_95_std_downsampled_128Hz.pth', 'eeg_55_95_std.pth', 'eeg_heatmaps_5_95.pth', 'eeg_5_95_std.pth', 'imagenet_full_40_semantic_cls']\n"
     ]
    }
   ],
   "source": [
    "if platform == \"linux\" or platform == \"linux2\":\n",
    "    torch_models_dir = r\"/media/mountHDD1/LanxHuyen/CVPR2017\"\n",
    "elif platform == \"win32\":\n",
    "    torch_models_dir = r\"D:\\Data\\CVPR2021-02785\\CVPR2021-02785\\preprocessed\\torch_models\"\n",
    "# block_splits_all, block_splits_single, eeg_14_70, eeg_55_95, eeg_5_95, eeg_raw = os.listdir(torch_models_dir)\n",
    "print(os.listdir(torch_models_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3ad4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/mountHDD1/LanxHuyen/CVPR2017/eeg_5_95_std.pth \n",
      " /media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth \n",
      "\n"
     ]
    }
   ],
   "source": [
    "eeg_dataset = '/media/mountHDD1/LanxHuyen/CVPR2017/eeg_5_95_std.pth'\n",
    "splits_all_path = '/media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth'\n",
    "# splits_single_path = os.path.join(torch_models_dir, block_splits_single)\n",
    "# splits_path = os.path.join(torch_models_dir, splits_shuffled_path)\n",
    "print(eeg_dataset,'\\n', splits_all_path, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "659d4a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_all = torch.load(splits_all_path)\n",
    "# splits_single = torch.load(splits_single_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f3ef344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "3\n",
      "7984\n",
      "1996\n",
      "1985\n",
      "[0, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 27, 29, 33, 35, 36, 37, 38, 39, 42, 43, 44, 45, 46, 47, 48, 51, 52, 54, 55]\n",
      "[1, 2, 3, 4, 6, 8, 9, 12, 13, 20, 25, 26, 27, 28, 30, 32, 33, 35, 37, 38, 39, 40, 44, 45, 46, 50, 52, 54, 56, 58, 59, 60, 62, 65, 68, 72, 73, 74, 76, 81]\n",
      "[2, 3, 4, 5, 6, 7, 8, 10, 11, 13]\n",
      "[1, 2, 4, 7, 9, 10, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "print(len(splits_all['splits']))\n",
    "print(len(splits_all['splits'][0]))\n",
    "\n",
    "print(len(splits_all['splits'][5]['train']))\n",
    "print(len(splits_all['splits'][5]['val']))\n",
    "print(len(splits_all['splits'][5]['test']))\n",
    "print(splits_all['splits'][0]['train'][:40])\n",
    "print(splits_all['splits'][1]['train'][:40])\n",
    "print(splits_all['splits'][2]['train'][:10])\n",
    "print(splits_all['splits'][3]['train'][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b27b3181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(splits_single)\n",
    "# print(len(splits_single['splits'][0]['train']))\n",
    "# print(len(splits_single['splits'][0]['val']))\n",
    "# print(len(splits_single['splits'][0]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed58c00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_loaded = torch.load(eeg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89460bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "dict_keys(['dataset', 'labels', 'images'])\n",
      "40\n",
      "1996\n",
      "11965\n",
      "['n02389026', 'n03888257', 'n03584829', 'n02607072', 'n03297495', 'n03063599', 'n03792782', 'n04086273', 'n02510455', 'n11939491', 'n02951358', 'n02281787', 'n02106662', 'n04120489', 'n03590841', 'n02992529', 'n03445777', 'n03180011', 'n02906734', 'n07873807', 'n03773504', 'n02492035', 'n03982430', 'n03709823', 'n03100240', 'n03376595', 'n03877472', 'n03775071', 'n03272010', 'n04069434', 'n03452741', 'n03792972', 'n07753592', 'n13054560', 'n03197337', 'n02504458', 'n02690373', 'n03272562', 'n04044716', 'n02124075']\n",
      "n02951358_31190\n",
      "torch.Size([128, 500])\n",
      "{'eeg': tensor([[-0.0098,  0.0195,  0.0620,  ...,  0.0638,  0.0120, -0.0118],\n",
      "        [-0.0045,  0.1303,  0.2673,  ...,  0.0894,  0.0342, -0.0082],\n",
      "        [ 0.0215, -0.2017, -0.4305,  ..., -0.2022, -0.0940,  0.0188],\n",
      "        ...,\n",
      "        [ 0.0160,  0.0707,  0.1005,  ...,  0.2066,  0.1156,  0.0036],\n",
      "        [-0.0046, -0.0084, -0.0119,  ...,  0.0007, -0.0026, -0.0053],\n",
      "        [ 0.0040,  0.0419,  0.0665,  ...,  0.0765,  0.0309, -0.0063]]), 'image': 0, 'label': 10, 'subject': 4}\n"
     ]
    }
   ],
   "source": [
    "print(len(eeg_loaded))\n",
    "print(eeg_loaded.keys())\n",
    "dataset, labels, images = [eeg_loaded[k] for k in eeg_loaded.keys()]\n",
    "print(len(labels))\n",
    "print(len(images))\n",
    "print(len(dataset))\n",
    "\n",
    "print(labels)\n",
    "print(images[0])\n",
    "print(dataset[0]['eeg'].shape)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d20c958c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "opt = {\n",
    "    # Dataset options\n",
    "#     \"iv\": \"image\",\n",
    "#     \"offset\": None,\n",
    "    \"results_file\": \"results.pkl\",\n",
    "    \"subject\": 0,\n",
    "    \"time_low\": 20,\n",
    "    \"time_high\": 460,\n",
    "#     \"run\": \"none\",\n",
    "    \"eeg_dataset\": eeg_dataset,\n",
    "    \"model_type\": \"model10\",\n",
    "    \"splits_path\": splits_all_path,\n",
    "    \"split_num\": 0,\n",
    "    \"split_name\": \"train\",\n",
    "#     \"fold\": 5,\n",
    "    #Training options\n",
    "    \"batch_size\": 16,\n",
    "    \"optim\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"learning_rate_decay_by\": 0.5,\n",
    "    \"learning_rate_decay_every\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"GPUindex\": 0,\n",
    "    \"kind\":\"from-scratch\",\n",
    "    #Backend options\n",
    "    \"no_cuda\": False,\n",
    "    \"classifier\": None\n",
    "}\n",
    "opt = argparse.Namespace(**opt)\n",
    "print(opt.time_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce8d6e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from torch.utils.data import DataLoader\n",
    "# from data_loader import EEGDataset, Splitter, SplitterWithData\n",
    "from data_loader_CVPR2017 import EEGDataset, Splitter\n",
    "from EEG_Encoder.LSTM import classifier_LSTM\n",
    "from EEG_Encoder.CNN import classifier_CNN\n",
    "from EEG_Encoder.EEGNet import classifier_EEGNet\n",
    "from EEG_Encoder.SyncNet import classifier_SyncNet\n",
    "from EEG_Encoder.EEGChannelNet import classifier_EEGChannelNet\n",
    "from EEG_Encoder.net_generator import Classifier\n",
    "from EEG_Encoder.net_trainer import net_trainer\n",
    "from p_values import *\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a5b475c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(\n",
    "#              offset,\n",
    "             eeg_dataset,\n",
    "             splits_path,\n",
    "             split_num, # (0-5) - 6 fold cross validation\n",
    "             split_name,\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             kind=\"from-scratch\"):        \n",
    "    # Load dataset\n",
    "    dataset = EEGDataset(opt, eeg_dataset)\n",
    "    print(\"DONE: LOAD DATASET\")\n",
    "#     # Create loaders for LSTM/MLP/CNN/SCNN/EEGNet/SyncNet/EEGChannelNet\n",
    "#     if kind==\"from-scratch\":\n",
    "#         relabel = False\n",
    "#     if kind==\"incremental\":\n",
    "#         relabel = False\n",
    "#     if kind==\"no-model-file\":\n",
    "#         relabel = True\n",
    "    splitter = {split: Splitter(dataset,\n",
    "                    splits_path,\n",
    "                    split_num,\n",
    "                    split_name = split) for split in [\"train\", \"val\", \"test\"]}\n",
    "    loaders = {split: DataLoader(\n",
    "                        splitter[split],\n",
    "                        batch_size = batch_size,\n",
    "                        drop_last = False,\n",
    "                        shuffle = True)\n",
    "                    for split in [\"train\", \"val\", \"test\"]}\n",
    "    channel_idx = None    \n",
    "    print(\"DONE: Create loaders for model\")            \n",
    "    return dataset, loaders, splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a242cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Options\n",
    "opt.classifier = \"Stacked_BiLSTM\"\n",
    "opt.batch_size = 64\n",
    "# opt.kind = \"from-scratch\"\n",
    "# opt.run = \"imagenet40-1000\"\n",
    "# opt.fold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "633488a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: LOAD DATASET\n",
      "DONE: Create loaders for model\n"
     ]
    }
   ],
   "source": [
    "dataset, loaders, splitter = load_dataset(\n",
    "#              offset,\n",
    "             opt.eeg_dataset,\n",
    "             opt.splits_path,\n",
    "             opt.split_num, # (0-5) - 6 fold cross validation\n",
    "             opt.split_name,\n",
    "#              total, \n",
    "#              classes,\n",
    "#              classifier,\n",
    "             opt.batch_size,\n",
    "#              GPUindex,\n",
    "#              length, # 500\n",
    "#              channel, # 128\n",
    "#              min_CNN,\n",
    "             opt,\n",
    "             opt.kind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e99fc973",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'data_loader_CVPR2017.EEGDataset'>\n",
      "<class 'dict'>\n",
      "3 [125, 32, 32]\n",
      "1: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "2: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "3: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "4: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "5: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "6: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "7: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "8: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "9: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "10: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "11: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "12: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "13: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "14: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "15: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "16: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "17: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "18: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "19: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n",
      "20: Target size: torch.Size([64]); input size: torch.Size([64, 128, 440])\n"
     ]
    }
   ],
   "source": [
    "# loaders: divide the splits data in each fold with batch_size\n",
    "# Each fold has {train: 8000 idx, val: 2000 idx, test: 2000 idx}\n",
    "# Each loader batch has {train: 2000 idx, val: 250 idx, test: 250 idx}\n",
    "print(type(dataset))\n",
    "print(type(loaders))\n",
    "print(len(loaders), [len(loaders[name]) for name in [\"train\", \"val\", \"test\"] ])\n",
    "for i, (input, target) in enumerate(loaders[\"train\"]):\n",
    "    if i<20:\n",
    "        print(f\"{i+1}: Target size: {target.size()}; input size: {input.size()}\")\n",
    "# for i in range(0, 40):\n",
    "#     eeg, label_val = splitter[\"val\"][i]\n",
    "#     eeg, label_train = splitter[\"train\"][i]\n",
    "#     print(f\"{i+1}: Label val: {label_val}; label train: {label_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39a07cc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE: CREATE TORCH CLASSIFIER\n",
      "classifier_Stacked_BiLSTM(\n",
      "  (stacked_bilstm): LSTM(128, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (output1): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (output2): Linear(in_features=128, out_features=40, bias=True)\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "classifier_Stacked_BiLSTM                [1, 40]                   --\n",
       "├─LSTM: 1-1                              [1, 440, 256]             659,456\n",
       "├─Linear: 1-2                            [1, 128]                  32,896\n",
       "├─ReLU: 1-3                              [1, 128]                  --\n",
       "├─Linear: 1-4                            [1, 40]                   5,160\n",
       "==========================================================================================\n",
       "Total params: 697,512\n",
       "Trainable params: 697,512\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 290.20\n",
       "==========================================================================================\n",
       "Input size (MB): 0.23\n",
       "Forward/backward pass size (MB): 0.90\n",
       "Params size (MB): 2.79\n",
       "Estimated Total Size (MB): 3.92\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net, nonclasses = Classifier(\n",
    "                 n_classes,\n",
    "                 classes,\n",
    "                 opt.classifier,\n",
    "                 opt.GPUindex,\n",
    "                 length,\n",
    "                 channel,\n",
    "                 min_CNN,\n",
    "                 opt.kind)\n",
    "# print(len(nonclasses))\n",
    "summary(net, input_size=(1,128, 440))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a8d6995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacked_BiLSTM-440-128\n"
     ]
    }
   ],
   "source": [
    "model_path = (   opt.classifier+\n",
    "                  \"-\"+\n",
    "                  str(length)+\n",
    "                  \"-\"+\n",
    "                  str(channel) )\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b753db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(results_file='results.pkl', subject=0, time_low=20, time_high=460, eeg_dataset='/media/mountHDD1/LanxHuyen/CVPR2017/eeg_5_95_std.pth', model_type='model10', splits_path='/media/mountHDD1/LanxHuyen/CVPR2017/block_splits_by_image_all.pth', split_num=0, split_name='train', batch_size=64, optim='Adam', learning_rate=0.001, learning_rate_decay_by=0.5, learning_rate_decay_every=10, epochs=100, GPUindex=0, kind='from-scratch', no_cuda=False, classifier='Stacked_BiLSTM')\n"
     ]
    }
   ],
   "source": [
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5334cb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train Batch 100 (every 100 batch): Loss=3.6134; accuracy=0.0330\n",
      "Epoch 1 summary: train_loss: 3.6531 | train_acc: 0.0347 | val_loss: 3.5278 | val_acc: 0.0358\n",
      "Epoch 2\n",
      "Train Batch 100 (every 100 batch): Loss=3.3174; accuracy=0.0614\n",
      "Epoch 2 summary: train_loss: 3.3159 | train_acc: 0.0647 | val_loss: 3.2483 | val_acc: 0.0684\n",
      "Epoch 3\n",
      "Train Batch 100 (every 100 batch): Loss=2.8873; accuracy=0.0966\n",
      "Epoch 3 summary: train_loss: 3.0271 | train_acc: 0.0964 | val_loss: 2.9716 | val_acc: 0.0951\n",
      "Epoch 4\n",
      "Train Batch 100 (every 100 batch): Loss=2.7735; accuracy=0.1252\n",
      "Epoch 4 summary: train_loss: 2.8564 | train_acc: 0.1226 | val_loss: 2.9638 | val_acc: 0.0925\n",
      "Epoch 5\n",
      "Train Batch 100 (every 100 batch): Loss=2.7719; accuracy=0.1517\n",
      "Epoch 5 summary: train_loss: 2.6555 | train_acc: 0.1542 | val_loss: 2.6680 | val_acc: 0.1298\n",
      "Epoch 6\n",
      "Train Batch 100 (every 100 batch): Loss=2.6258; accuracy=0.1642\n",
      "Epoch 6 summary: train_loss: 2.5631 | train_acc: 0.1650 | val_loss: 2.6955 | val_acc: 0.1269\n",
      "Epoch 7\n",
      "Train Batch 100 (every 100 batch): Loss=2.4748; accuracy=0.1920\n",
      "Epoch 7 summary: train_loss: 2.4269 | train_acc: 0.1955 | val_loss: 2.5912 | val_acc: 0.1196\n",
      "Epoch 8\n",
      "Train Batch 100 (every 100 batch): Loss=2.3962; accuracy=0.2123\n",
      "Epoch 8 summary: train_loss: 2.3571 | train_acc: 0.2184 | val_loss: 2.5367 | val_acc: 0.1525\n",
      "Epoch 9\n",
      "Train Batch 100 (every 100 batch): Loss=2.2817; accuracy=0.2408\n",
      "Epoch 9 summary: train_loss: 2.2666 | train_acc: 0.2410 | val_loss: 2.5663 | val_acc: 0.1638\n",
      "Epoch 10\n",
      "Train Batch 100 (every 100 batch): Loss=2.0222; accuracy=0.2700\n",
      "Epoch 10 summary: train_loss: 2.1534 | train_acc: 0.2673 | val_loss: 2.6251 | val_acc: 0.1411\n",
      "Epoch 11\n",
      "Train Batch 100 (every 100 batch): Loss=2.2681; accuracy=0.3016\n",
      "Epoch 11 summary: train_loss: 2.0527 | train_acc: 0.2998 | val_loss: 2.6226 | val_acc: 0.1718\n",
      "Epoch 12\n",
      "Train Batch 100 (every 100 batch): Loss=1.8204; accuracy=0.3247\n",
      "Epoch 12 summary: train_loss: 1.9852 | train_acc: 0.3212 | val_loss: 2.5410 | val_acc: 0.1796\n",
      "Epoch 13\n",
      "Train Batch 100 (every 100 batch): Loss=2.0635; accuracy=0.3231\n",
      "Epoch 13 summary: train_loss: 2.0538 | train_acc: 0.3186 | val_loss: 2.5494 | val_acc: 0.1840\n",
      "Epoch 14\n",
      "Train Batch 100 (every 100 batch): Loss=1.7342; accuracy=0.3730\n",
      "Epoch 14 summary: train_loss: 1.8453 | train_acc: 0.3708 | val_loss: 2.5494 | val_acc: 0.1866\n",
      "Epoch 15\n",
      "Train Batch 100 (every 100 batch): Loss=1.7790; accuracy=0.4323\n",
      "Epoch 15 summary: train_loss: 1.6780 | train_acc: 0.4179 | val_loss: 2.6384 | val_acc: 0.1765\n",
      "Epoch 16\n",
      "Train Batch 100 (every 100 batch): Loss=1.5830; accuracy=0.4431\n",
      "Epoch 16 summary: train_loss: 1.5996 | train_acc: 0.4437 | val_loss: 2.6916 | val_acc: 0.1959\n",
      "Epoch 17\n",
      "Train Batch 100 (every 100 batch): Loss=1.4192; accuracy=0.4841\n",
      "Epoch 17 summary: train_loss: 1.4925 | train_acc: 0.4826 | val_loss: 2.7308 | val_acc: 0.1860\n",
      "Epoch 18\n",
      "Train Batch 100 (every 100 batch): Loss=1.4084; accuracy=0.5234\n",
      "Epoch 18 summary: train_loss: 1.3630 | train_acc: 0.5233 | val_loss: 2.8399 | val_acc: 0.1906\n",
      "Epoch 19\n",
      "Train Batch 100 (every 100 batch): Loss=1.2559; accuracy=0.5637\n",
      "Epoch 19 summary: train_loss: 1.2944 | train_acc: 0.5549 | val_loss: 2.8502 | val_acc: 0.1947\n",
      "Epoch 20\n",
      "Train Batch 100 (every 100 batch): Loss=0.9775; accuracy=0.5911\n",
      "Epoch 20 summary: train_loss: 1.2078 | train_acc: 0.5912 | val_loss: 2.8493 | val_acc: 0.1981\n",
      "Epoch 21\n",
      "Train Batch 100 (every 100 batch): Loss=2.1391; accuracy=0.5798\n",
      "Epoch 21 summary: train_loss: 1.4762 | train_acc: 0.5498 | val_loss: 3.0460 | val_acc: 0.1620\n",
      "Epoch 22\n",
      "Train Batch 100 (every 100 batch): Loss=1.3654; accuracy=0.5788\n",
      "Epoch 22 summary: train_loss: 1.3097 | train_acc: 0.5785 | val_loss: 2.9861 | val_acc: 0.1885\n",
      "Epoch 23\n",
      "Train Batch 100 (every 100 batch): Loss=0.9276; accuracy=0.6706\n",
      "Epoch 23 summary: train_loss: 1.0387 | train_acc: 0.6615 | val_loss: 3.1429 | val_acc: 0.1869\n",
      "Epoch 24\n",
      "Train Batch 100 (every 100 batch): Loss=0.7929; accuracy=0.7027\n",
      "Epoch 24 summary: train_loss: 0.9085 | train_acc: 0.7005 | val_loss: 3.1959 | val_acc: 0.2027\n",
      "Epoch 25\n",
      "Train Batch 100 (every 100 batch): Loss=0.7144; accuracy=0.7325\n",
      "Epoch 25 summary: train_loss: 0.7993 | train_acc: 0.7370 | val_loss: 3.4133 | val_acc: 0.2016\n",
      "Epoch 26\n",
      "Train Batch 100 (every 100 batch): Loss=0.8391; accuracy=0.7836\n",
      "Epoch 26 summary: train_loss: 0.6832 | train_acc: 0.7782 | val_loss: 3.6202 | val_acc: 0.1988\n",
      "Epoch 27\n",
      "Train Batch 100 (every 100 batch): Loss=0.5249; accuracy=0.7906\n",
      "Epoch 27 summary: train_loss: 0.6533 | train_acc: 0.7885 | val_loss: 3.5862 | val_acc: 0.2010\n",
      "Epoch 28\n",
      "Train Batch 100 (every 100 batch): Loss=0.6505; accuracy=0.8152\n",
      "Epoch 28 summary: train_loss: 0.5819 | train_acc: 0.8075 | val_loss: 3.7605 | val_acc: 0.2028\n",
      "Epoch 29\n",
      "Train Batch 100 (every 100 batch): Loss=0.5475; accuracy=0.8386\n",
      "Epoch 29 summary: train_loss: 0.5294 | train_acc: 0.8337 | val_loss: 3.9414 | val_acc: 0.1955\n",
      "Epoch 30\n",
      "Train Batch 100 (every 100 batch): Loss=0.6577; accuracy=0.8494\n",
      "Epoch 30 summary: train_loss: 0.5033 | train_acc: 0.8446 | val_loss: 3.9953 | val_acc: 0.1975\n",
      "Epoch 31\n",
      "Train Batch 100 (every 100 batch): Loss=0.3861; accuracy=0.8578\n",
      "Epoch 31 summary: train_loss: 0.4818 | train_acc: 0.8556 | val_loss: 4.2683 | val_acc: 0.1972\n",
      "Epoch 32\n",
      "Train Batch 100 (every 100 batch): Loss=0.3391; accuracy=0.8969\n",
      "Epoch 32 summary: train_loss: 0.3593 | train_acc: 0.8940 | val_loss: 4.4000 | val_acc: 0.1831\n",
      "Epoch 33\n",
      "Train Batch 100 (every 100 batch): Loss=0.6514; accuracy=0.8920\n",
      "Epoch 33 summary: train_loss: 0.3805 | train_acc: 0.8822 | val_loss: 4.5925 | val_acc: 0.1912\n",
      "Epoch 34\n",
      "Train Batch 100 (every 100 batch): Loss=0.2761; accuracy=0.8878\n",
      "Epoch 34 summary: train_loss: 0.3569 | train_acc: 0.8874 | val_loss: 5.1236 | val_acc: 0.1709\n",
      "Epoch 35\n",
      "Train Batch 100 (every 100 batch): Loss=0.2669; accuracy=0.8841\n",
      "Epoch 35 summary: train_loss: 0.3869 | train_acc: 0.8851 | val_loss: 4.7561 | val_acc: 0.1850\n",
      "Epoch 36\n",
      "Train Batch 100 (every 100 batch): Loss=0.4173; accuracy=0.9359\n",
      "Epoch 36 summary: train_loss: 0.2598 | train_acc: 0.9270 | val_loss: 4.9813 | val_acc: 0.1935\n",
      "Epoch 37\n",
      "Train Batch 100 (every 100 batch): Loss=0.2289; accuracy=0.9397\n",
      "Epoch 37 summary: train_loss: 0.2220 | train_acc: 0.9391 | val_loss: 4.9597 | val_acc: 0.1959\n",
      "Epoch 38\n",
      "Train Batch 100 (every 100 batch): Loss=0.1504; accuracy=0.9373\n",
      "Epoch 38 summary: train_loss: 0.2154 | train_acc: 0.9362 | val_loss: 5.1619 | val_acc: 0.1848\n",
      "Epoch 39\n",
      "Train Batch 100 (every 100 batch): Loss=0.0824; accuracy=0.9623\n",
      "Epoch 39 summary: train_loss: 0.1503 | train_acc: 0.9624 | val_loss: 5.2993 | val_acc: 0.1944\n",
      "Epoch 40\n",
      "Train Batch 100 (every 100 batch): Loss=0.0762; accuracy=0.9664\n",
      "Epoch 40 summary: train_loss: 0.1343 | train_acc: 0.9628 | val_loss: 5.4543 | val_acc: 0.1816\n",
      "Epoch 41\n",
      "Train Batch 100 (every 100 batch): Loss=0.3092; accuracy=0.9084\n",
      "Epoch 41 summary: train_loss: 0.3521 | train_acc: 0.8959 | val_loss: 5.4980 | val_acc: 0.1801\n",
      "Epoch 42\n",
      "Train Batch 100 (every 100 batch): Loss=0.3200; accuracy=0.8681\n",
      "Epoch 42 summary: train_loss: 0.4079 | train_acc: 0.8710 | val_loss: 5.3477 | val_acc: 0.1894\n",
      "Epoch 43\n",
      "Train Batch 100 (every 100 batch): Loss=0.2126; accuracy=0.9400\n",
      "Epoch 43 summary: train_loss: 0.2370 | train_acc: 0.9336 | val_loss: 5.5048 | val_acc: 0.1753\n",
      "Epoch 44\n",
      "Train Batch 100 (every 100 batch): Loss=0.0987; accuracy=0.9342\n",
      "Epoch 44 summary: train_loss: 0.2174 | train_acc: 0.9368 | val_loss: 5.4360 | val_acc: 0.1903\n",
      "Epoch 45\n",
      "Train Batch 100 (every 100 batch): Loss=0.0576; accuracy=0.9695\n",
      "Epoch 45 summary: train_loss: 0.1219 | train_acc: 0.9686 | val_loss: 5.5937 | val_acc: 0.1937\n",
      "Epoch 46\n",
      "Train Batch 100 (every 100 batch): Loss=0.0350; accuracy=0.9837\n",
      "Epoch 46 summary: train_loss: 0.0719 | train_acc: 0.9840 | val_loss: 5.6935 | val_acc: 0.1977\n",
      "Epoch 47\n",
      "Train Batch 100 (every 100 batch): Loss=0.0172; accuracy=0.9947\n",
      "Epoch 47 summary: train_loss: 0.0342 | train_acc: 0.9943 | val_loss: 5.7864 | val_acc: 0.1940\n",
      "Epoch 48\n",
      "Train Batch 100 (every 100 batch): Loss=0.0054; accuracy=0.9972\n",
      "Epoch 48 summary: train_loss: 0.0234 | train_acc: 0.9965 | val_loss: 5.9572 | val_acc: 0.1958\n",
      "Epoch 49\n",
      "Train Batch 100 (every 100 batch): Loss=0.0150; accuracy=0.9970\n",
      "Epoch 49 summary: train_loss: 0.0168 | train_acc: 0.9973 | val_loss: 6.0348 | val_acc: 0.1940\n",
      "Epoch 50\n",
      "Train Batch 100 (every 100 batch): Loss=0.0047; accuracy=0.9959\n",
      "Epoch 50 summary: train_loss: 0.0183 | train_acc: 0.9959 | val_loss: 5.9962 | val_acc: 0.2001\n",
      "Epoch 51\n",
      "Train Batch 100 (every 100 batch): Loss=0.0348; accuracy=0.9970\n",
      "Epoch 51 summary: train_loss: 0.0157 | train_acc: 0.9966 | val_loss: 6.1213 | val_acc: 0.1950\n",
      "Epoch 52\n",
      "Train Batch 100 (every 100 batch): Loss=0.0456; accuracy=0.9977\n",
      "Epoch 52 summary: train_loss: 0.0132 | train_acc: 0.9976 | val_loss: 6.1661 | val_acc: 0.1973\n",
      "Epoch 53\n",
      "Train Batch 100 (every 100 batch): Loss=0.0399; accuracy=0.9975\n",
      "Epoch 53 summary: train_loss: 0.0138 | train_acc: 0.9971 | val_loss: 6.3278 | val_acc: 0.1975\n",
      "Epoch 54\n",
      "Train Batch 100 (every 100 batch): Loss=0.0199; accuracy=0.9944\n",
      "Epoch 54 summary: train_loss: 0.0215 | train_acc: 0.9944 | val_loss: 6.2679 | val_acc: 0.2006\n",
      "Epoch 55\n",
      "Train Batch 100 (every 100 batch): Loss=0.0380; accuracy=0.9923\n",
      "Epoch 55 summary: train_loss: 0.0382 | train_acc: 0.9907 | val_loss: 6.6373 | val_acc: 0.1809\n",
      "Epoch 56\n",
      "Train Batch 100 (every 100 batch): Loss=1.4169; accuracy=0.8434\n",
      "Epoch 56 summary: train_loss: 0.7151 | train_acc: 0.8059 | val_loss: 5.7715 | val_acc: 0.1521\n",
      "Epoch 57\n",
      "Train Batch 100 (every 100 batch): Loss=0.4292; accuracy=0.7714\n",
      "Epoch 57 summary: train_loss: 0.6750 | train_acc: 0.7848 | val_loss: 5.3255 | val_acc: 0.1693\n",
      "Epoch 58\n",
      "Train Batch 100 (every 100 batch): Loss=0.2137; accuracy=0.9216\n",
      "Epoch 58 summary: train_loss: 0.2540 | train_acc: 0.9249 | val_loss: 5.3809 | val_acc: 0.1787\n",
      "Epoch 59\n",
      "Train Batch 100 (every 100 batch): Loss=0.1407; accuracy=0.9627\n",
      "Epoch 59 summary: train_loss: 0.1374 | train_acc: 0.9641 | val_loss: 5.5077 | val_acc: 0.1860\n",
      "Epoch 60\n",
      "Train Batch 100 (every 100 batch): Loss=0.0588; accuracy=0.9872\n",
      "Epoch 60 summary: train_loss: 0.0592 | train_acc: 0.9879 | val_loss: 5.7352 | val_acc: 0.1926\n",
      "Epoch 61\n",
      "Train Batch 100 (every 100 batch): Loss=0.0212; accuracy=0.9969\n",
      "Epoch 61 summary: train_loss: 0.0276 | train_acc: 0.9969 | val_loss: 5.8063 | val_acc: 0.1928\n",
      "Epoch 62\n",
      "Train Batch 100 (every 100 batch): Loss=0.0079; accuracy=0.9978\n",
      "Epoch 62 summary: train_loss: 0.0186 | train_acc: 0.9978 | val_loss: 5.9043 | val_acc: 0.1981\n",
      "Epoch 63\n",
      "Train Batch 100 (every 100 batch): Loss=0.0075; accuracy=0.9998\n",
      "Epoch 63 summary: train_loss: 0.0087 | train_acc: 0.9999 | val_loss: 5.9320 | val_acc: 0.2023\n",
      "Epoch 64\n",
      "Train Batch 100 (every 100 batch): Loss=0.0049; accuracy=1.0000\n",
      "Epoch 64 summary: train_loss: 0.0055 | train_acc: 1.0000 | val_loss: 6.0513 | val_acc: 0.2081\n",
      "Epoch 65\n",
      "Train Batch 100 (every 100 batch): Loss=0.0066; accuracy=0.9995\n",
      "Epoch 65 summary: train_loss: 0.0053 | train_acc: 0.9996 | val_loss: 6.1487 | val_acc: 0.2091\n",
      "Epoch 66\n",
      "Train Batch 100 (every 100 batch): Loss=0.0066; accuracy=1.0000\n",
      "Epoch 66 summary: train_loss: 0.0037 | train_acc: 1.0000 | val_loss: 6.2274 | val_acc: 0.2033\n",
      "Epoch 67\n",
      "Train Batch 100 (every 100 batch): Loss=0.0022; accuracy=1.0000\n",
      "Epoch 67 summary: train_loss: 0.0033 | train_acc: 1.0000 | val_loss: 6.2228 | val_acc: 0.2009\n",
      "Epoch 68\n",
      "Train Batch 100 (every 100 batch): Loss=0.0025; accuracy=1.0000\n",
      "Epoch 68 summary: train_loss: 0.0028 | train_acc: 1.0000 | val_loss: 6.2737 | val_acc: 0.1992\n",
      "Epoch 69\n",
      "Train Batch 100 (every 100 batch): Loss=0.0031; accuracy=1.0000\n",
      "Epoch 69 summary: train_loss: 0.0025 | train_acc: 1.0000 | val_loss: 6.2739 | val_acc: 0.2107\n",
      "Epoch 70\n",
      "Train Batch 100 (every 100 batch): Loss=0.0030; accuracy=1.0000\n",
      "Epoch 70 summary: train_loss: 0.0023 | train_acc: 1.0000 | val_loss: 6.3918 | val_acc: 0.2004\n",
      "Epoch 71\n",
      "Train Batch 100 (every 100 batch): Loss=0.0012; accuracy=1.0000\n",
      "Epoch 71 summary: train_loss: 0.0020 | train_acc: 1.0000 | val_loss: 6.3895 | val_acc: 0.2055\n",
      "Epoch 72\n",
      "Train Batch 100 (every 100 batch): Loss=0.0017; accuracy=1.0000\n",
      "Epoch 72 summary: train_loss: 0.0018 | train_acc: 1.0000 | val_loss: 6.4399 | val_acc: 0.2014\n",
      "Epoch 73\n",
      "Train Batch 100 (every 100 batch): Loss=0.0021; accuracy=1.0000\n",
      "Epoch 73 summary: train_loss: 0.0017 | train_acc: 1.0000 | val_loss: 6.4842 | val_acc: 0.2030\n",
      "Epoch 74\n",
      "Train Batch 100 (every 100 batch): Loss=0.0013; accuracy=1.0000\n",
      "Epoch 74 summary: train_loss: 0.0015 | train_acc: 1.0000 | val_loss: 6.5860 | val_acc: 0.1999\n",
      "Epoch 75\n",
      "Train Batch 100 (every 100 batch): Loss=0.0014; accuracy=1.0000\n",
      "Epoch 75 summary: train_loss: 0.0014 | train_acc: 1.0000 | val_loss: 6.6914 | val_acc: 0.2004\n",
      "Epoch 76\n",
      "Train Batch 100 (every 100 batch): Loss=0.0012; accuracy=1.0000\n",
      "Epoch 76 summary: train_loss: 0.0013 | train_acc: 1.0000 | val_loss: 6.6676 | val_acc: 0.2009\n",
      "Epoch 77\n",
      "Train Batch 100 (every 100 batch): Loss=0.0016; accuracy=1.0000\n",
      "Epoch 77 summary: train_loss: 0.0012 | train_acc: 1.0000 | val_loss: 6.6449 | val_acc: 0.2014\n",
      "Epoch 78\n",
      "Train Batch 100 (every 100 batch): Loss=0.0010; accuracy=1.0000\n",
      "Epoch 78 summary: train_loss: 0.0011 | train_acc: 1.0000 | val_loss: 6.7120 | val_acc: 0.2047\n",
      "Epoch 79\n",
      "Train Batch 100 (every 100 batch): Loss=0.0009; accuracy=1.0000\n",
      "Epoch 79 summary: train_loss: 0.0010 | train_acc: 1.0000 | val_loss: 6.8105 | val_acc: 0.2016\n",
      "Epoch 80\n",
      "Train Batch 100 (every 100 batch): Loss=0.0010; accuracy=1.0000\n",
      "Epoch 80 summary: train_loss: 0.0009 | train_acc: 1.0000 | val_loss: 6.8070 | val_acc: 0.2062\n",
      "Epoch 81\n",
      "Train Batch 100 (every 100 batch): Loss=0.0007; accuracy=1.0000\n",
      "Epoch 81 summary: train_loss: 0.0008 | train_acc: 1.0000 | val_loss: 6.8533 | val_acc: 0.2009\n",
      "Epoch 82\n",
      "Train Batch 100 (every 100 batch): Loss=0.0005; accuracy=1.0000\n",
      "Epoch 82 summary: train_loss: 0.0008 | train_acc: 1.0000 | val_loss: 6.7977 | val_acc: 0.2126\n",
      "Epoch 83\n",
      "Train Batch 100 (every 100 batch): Loss=0.0007; accuracy=1.0000\n",
      "Epoch 83 summary: train_loss: 0.0007 | train_acc: 1.0000 | val_loss: 6.8846 | val_acc: 0.1994\n",
      "Epoch 84\n",
      "Train Batch 100 (every 100 batch): Loss=0.0005; accuracy=1.0000\n",
      "Epoch 84 summary: train_loss: 0.0007 | train_acc: 1.0000 | val_loss: 6.9761 | val_acc: 0.2059\n",
      "Epoch 85\n",
      "Train Batch 100 (every 100 batch): Loss=0.0006; accuracy=1.0000\n",
      "Epoch 85 summary: train_loss: 0.0006 | train_acc: 1.0000 | val_loss: 6.9788 | val_acc: 0.2047\n",
      "Epoch 86\n",
      "Train Batch 100 (every 100 batch): Loss=0.0006; accuracy=1.0000\n",
      "Epoch 86 summary: train_loss: 0.0006 | train_acc: 1.0000 | val_loss: 7.0338 | val_acc: 0.2093\n",
      "Epoch 87\n",
      "Train Batch 100 (every 100 batch): Loss=0.0004; accuracy=1.0000\n",
      "Epoch 87 summary: train_loss: 0.0005 | train_acc: 1.0000 | val_loss: 7.1094 | val_acc: 0.1979\n",
      "Epoch 88\n",
      "Train Batch 100 (every 100 batch): Loss=0.0005; accuracy=1.0000\n",
      "Epoch 88 summary: train_loss: 0.0005 | train_acc: 1.0000 | val_loss: 7.1979 | val_acc: 0.1953\n",
      "Epoch 89\n",
      "Train Batch 100 (every 100 batch): Loss=0.0006; accuracy=1.0000\n",
      "Epoch 89 summary: train_loss: 0.0005 | train_acc: 1.0000 | val_loss: 7.2536 | val_acc: 0.2016\n",
      "Epoch 90\n",
      "Train Batch 100 (every 100 batch): Loss=0.0004; accuracy=1.0000\n",
      "Epoch 90 summary: train_loss: 0.0004 | train_acc: 1.0000 | val_loss: 7.2739 | val_acc: 0.1963\n",
      "Epoch 91\n",
      "Train Batch 100 (every 100 batch): Loss=0.0004; accuracy=1.0000\n",
      "Epoch 91 summary: train_loss: 0.0004 | train_acc: 1.0000 | val_loss: 7.2182 | val_acc: 0.1994\n",
      "Epoch 92\n",
      "Train Batch 100 (every 100 batch): Loss=0.0005; accuracy=1.0000\n",
      "Epoch 92 summary: train_loss: 0.0004 | train_acc: 1.0000 | val_loss: 7.2974 | val_acc: 0.2011\n",
      "Epoch 93\n",
      "Train Batch 100 (every 100 batch): Loss=0.0002; accuracy=1.0000\n",
      "Epoch 93 summary: train_loss: 0.0003 | train_acc: 1.0000 | val_loss: 7.3412 | val_acc: 0.1996\n",
      "Epoch 94\n",
      "Train Batch 100 (every 100 batch): Loss=0.0004; accuracy=1.0000\n",
      "Epoch 94 summary: train_loss: 0.0003 | train_acc: 1.0000 | val_loss: 7.3578 | val_acc: 0.2025\n",
      "Epoch 95\n",
      "Train Batch 100 (every 100 batch): Loss=0.0003; accuracy=1.0000\n",
      "Epoch 95 summary: train_loss: 0.0003 | train_acc: 1.0000 | val_loss: 7.4380 | val_acc: 0.2042\n",
      "Epoch 96\n",
      "Train Batch 100 (every 100 batch): Loss=0.0002; accuracy=1.0000\n",
      "Epoch 96 summary: train_loss: 0.0003 | train_acc: 1.0000 | val_loss: 7.4418 | val_acc: 0.2047\n",
      "Epoch 97\n",
      "Train Batch 100 (every 100 batch): Loss=0.0002; accuracy=1.0000\n",
      "Epoch 97 summary: train_loss: 0.0003 | train_acc: 1.0000 | val_loss: 7.5690 | val_acc: 0.1968\n",
      "Epoch 98\n",
      "Train Batch 100 (every 100 batch): Loss=0.0002; accuracy=1.0000\n",
      "Epoch 98 summary: train_loss: 0.0002 | train_acc: 1.0000 | val_loss: 7.5468 | val_acc: 0.2025\n",
      "Epoch 99\n",
      "Train Batch 100 (every 100 batch): Loss=0.0003; accuracy=1.0000\n",
      "Epoch 99 summary: train_loss: 0.0002 | train_acc: 1.0000 | val_loss: 7.6349 | val_acc: 0.2042\n",
      "Epoch 100\n",
      "Train Batch 100 (every 100 batch): Loss=0.0002; accuracy=1.0000\n",
      "Epoch 100 summary: train_loss: 0.0002 | train_acc: 1.0000 | val_loss: 7.5947 | val_acc: 0.2030\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m non_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mkind\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom-scratch\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     loss_history, accuracy_val, accuracy_test \u001b[38;5;241m=\u001b[39m net_trainer(\n\u001b[1;32m      5\u001b[0m             net,\n\u001b[1;32m      6\u001b[0m             loaders,\n\u001b[1;32m      7\u001b[0m             opt,\n\u001b[1;32m      8\u001b[0m             channel_idx,\n\u001b[1;32m      9\u001b[0m             nonclasses,\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     11\u001b[0m             \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m             model_path)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "channel_idx=None\n",
    "non_classes=None\n",
    "if opt.kind==\"from-scratch\":\n",
    "    loss_history, accuracy_val, accuracy_test = net_trainer(\n",
    "            net,\n",
    "            loaders,\n",
    "            opt,\n",
    "            channel_idx,\n",
    "            nonclasses,\n",
    "            None,\n",
    "            True,\n",
    "            model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0199dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val =accuracy_val\n",
    "# test = accuracy_test\n",
    "\n",
    "# print(\"Validation accuracy: \", val)\n",
    "# print(\"Test accuracy: \", test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56b086",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913f370e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9a7d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2334ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b77fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3080e706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17823cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b650c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb911b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b43930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28237288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ded073",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfcbdda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fb11a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b75470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8939417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5c258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e7de01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597563e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d74a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db30ed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1544e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
